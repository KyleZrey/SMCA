{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install transformers pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import torch\n",
    "\n",
    "# Initialize BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased')\n",
    "model = BertModel.from_pretrained('bert-large-uncased')\n",
    "\n",
    "# Function to extract features from transcript using BERT\n",
    "def extract_features(transcript):\n",
    "    inputs = tokenizer(transcript, return_tensors='pt')\n",
    "    outputs = model(**inputs)\n",
    "    last_hidden_states = outputs.last_hidden_state\n",
    "    mean_last_hidden_states = torch.mean(last_hidden_states, dim=1).squeeze().detach().numpy()\n",
    "    return mean_last_hidden_states\n",
    "\n",
    "# Read CSV file\n",
    "df = pd.read_csv('transcriptions (1353).csv')\n",
    "\n",
    "# Create an empty list to store feature vectors and identifiers\n",
    "feature_vectors = []\n",
    "identifiers = []\n",
    "\n",
    "# Iterate through each transcript in the DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    identifier = row['Video File'] \n",
    "    transcript = row['Transcription']  \n",
    "    \n",
    "    # Extract features for the current transcript\n",
    "    feature_vector = extract_features(transcript)\n",
    "    \n",
    "    # Save the feature vector as a NumPy array\n",
    "    np.save(f'feature_vectors/{identifier}.npy', feature_vector)\n",
    "    \n",
    "    # keep track of identifiers for reference\n",
    "    identifiers.append(identifier)\n",
    "\n",
    "# Save identifiers to a text file (will remove this later)\n",
    "with open('identifiers.txt', 'w') as f:\n",
    "    for identifier in identifiers:\n",
    "        f.write(f'{identifier}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ver2: With Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "\n",
    "# Set up logging for tracking purposes \n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Initialize BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased')\n",
    "model = BertModel.from_pretrained('bert-large-uncased')\n",
    "\n",
    "# Function to extract features from transcript using BERT\n",
    "def extract_features(transcript):\n",
    "    inputs = tokenizer(transcript, return_tensors='pt')\n",
    "    outputs = model(**inputs)\n",
    "    last_hidden_states = outputs.last_hidden_state\n",
    "    mean_last_hidden_states = torch.mean(last_hidden_states, dim=1).squeeze().detach().numpy()\n",
    "    return mean_last_hidden_states\n",
    "\n",
    "# Ensure the feature_vectors directory exists\n",
    "output_dir = 'feature_vectors'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Read CSV file\n",
    "csv_file = 'transcriptions (1353).csv'\n",
    "try:\n",
    "    df = pd.read_csv(csv_file)\n",
    "    logging.info(f\"Successfully read {csv_file}\")\n",
    "except FileNotFoundError:\n",
    "    logging.error(f\"The file {csv_file} was not found.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    logging.error(f\"An error occurred while reading {csv_file}: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Check if required columns exist\n",
    "required_columns = ['Video File', 'Transcription']\n",
    "if not all(col in df.columns for col in required_columns):\n",
    "    logging.error(f\"The file {csv_file} does not contain the required columns: {required_columns}\")\n",
    "    exit()\n",
    "\n",
    "# Create an empty list to store identifiers\n",
    "identifiers = []\n",
    "\n",
    "# Iterate through each transcript in the DataFrame\n",
    "for index, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Processing transcripts\"):\n",
    "    identifier = row['Video File']\n",
    "    transcript = row['Transcription']\n",
    "    \n",
    "    try:\n",
    "        # Extract features for the current transcript\n",
    "        feature_vector = extract_features(transcript)\n",
    "        \n",
    "        # Save the feature vector as a NumPy array\n",
    "        np.save(os.path.join(output_dir, f'{identifier}.npy'), feature_vector)\n",
    "        \n",
    "        # Optionally, keep track of identifiers for reference\n",
    "        identifiers.append(identifier)\n",
    "        logging.info(f\"Processed and saved features for {identifier}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred while processing {identifier}: {e}\")\n",
    "\n",
    "# Save identifiers to a text file (optional)\n",
    "identifiers_file = 'identifiers.txt'\n",
    "try:\n",
    "    with open(identifiers_file, 'w') as f:\n",
    "        for identifier in identifiers:\n",
    "            f.write(f'{identifier}\\n')\n",
    "    logging.info(f\"Identifiers saved to {identifiers_file}\")\n",
    "    logging.info(\"Feature extraction and saving completed.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"An error occurred while saving identifiers to {identifiers_file}: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
