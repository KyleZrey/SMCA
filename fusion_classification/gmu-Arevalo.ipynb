{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "from torcheval.metrics import BinaryPrecision, BinaryRecall, BinaryF1Score\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "from modules.classifier import DenseLayer, BCELoss\n",
    "from modules.dataloader import load_npy_files\n",
    "from modules.linear_transformation import LinearTransformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultimodalDataset(Dataset):\n",
    "    def __init__(self, id_label_df, text_features, audio_features, video_features):\n",
    "        self.id_label_df = id_label_df\n",
    "        \n",
    "        # Convert feature lists to dictionaries for fast lookup\n",
    "        self.text_features = {os.path.basename(file).split('.')[0]: tensor for file, tensor in text_features}\n",
    "        self.audio_features = {os.path.basename(file).split('_')[1].split('.')[0]: tensor for file, tensor in audio_features}\n",
    "        self.video_features = {os.path.basename(file).split('_')[0]: tensor for file, tensor in video_features}\n",
    "\n",
    "        # List to store missing files\n",
    "        self.missing_files = []\n",
    "\n",
    "        # Filter out entries with missing files\n",
    "        self.valid_files = self._filter_valid_files()\n",
    "\n",
    "\n",
    "    def _filter_valid_files(self):\n",
    "        valid_files = []\n",
    "        for idx in range(len(self.id_label_df)):\n",
    "            imdbid = self.id_label_df.iloc[idx]['IMDBid']\n",
    "\n",
    "            # Check if the IMDBid exists in each modality's features\n",
    "            if imdbid in self.text_features and imdbid in self.audio_features and imdbid in self.video_features:\n",
    "                valid_files.append(idx)\n",
    "            else:\n",
    "                self.missing_files.append({'IMDBid': imdbid})\n",
    "\n",
    "        # Print missing files after checking all\n",
    "        if self.missing_files:\n",
    "            print(\"Missing files:\")\n",
    "            for item in self.missing_files:\n",
    "                print(f\"IMDBid: {item['IMDBid']}\")\n",
    "            print(f\"Total IMDB IDs with missing files: {len(self.missing_files)}\")\n",
    "        else:\n",
    "            print(\"No missing files.\")\n",
    "\n",
    "        return valid_files\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.valid_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get the original index from the filtered valid files\n",
    "        original_idx = self.valid_files[idx]\n",
    "        imdbid = self.id_label_df.iloc[original_idx]['IMDBid']\n",
    "        label = self.id_label_df.iloc[original_idx]['Label']\n",
    "\n",
    "        # Retrieve data from the loaded features\n",
    "        text_data = self.text_features.get(imdbid, torch.zeros((1024,)))\n",
    "        audio_data = self.audio_features.get(imdbid, torch.zeros((1, 197, 768)))\n",
    "        video_data = self.video_features.get(imdbid, torch.zeros((95, 768)))\n",
    "        \n",
    "        # Define label mapping\n",
    "        label_map = {'red': 1, 'green': 0} \n",
    "        \n",
    "        # Convert labels to tensor using label_map\n",
    "        try:\n",
    "            label_data = torch.tensor([label_map[label]], dtype=torch.float32)  # Ensure labels are integers\n",
    "        except KeyError as e:\n",
    "            print(f\"Error: Label '{e}' not found in label_map.\")\n",
    "            raise\n",
    "\n",
    "        return text_data, audio_data, video_data, label_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def collate_fn(batch):\n",
    "    text_data, audio_data, video_data, label_data = zip(*batch)\n",
    "\n",
    "    # Convert lists to tensors\n",
    "    text_data = torch.stack(text_data)\n",
    "    audio_data = torch.stack(audio_data)\n",
    "\n",
    "    # Padding for video data\n",
    "    # Determine maximum length of video sequences in the batch\n",
    "    video_lengths = [v.size(0) for v in video_data]\n",
    "    max_length = max(video_lengths)\n",
    "\n",
    "    # Pad video sequences to the maximum length\n",
    "    video_data_padded = torch.stack([\n",
    "        F.pad(v, (0, 0, 0, max_length - v.size(0)), \"constant\", 0)\n",
    "        for v in video_data\n",
    "    ])\n",
    "\n",
    "    # Convert labels to tensor and ensure the shape [batch_size, 1]\n",
    "    label_data = torch.stack(label_data)  # Convert list of tensors to a single tensor\n",
    "\n",
    "    return text_data, audio_data, video_data_padded, label_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing files:\n",
      "IMDBid: tt2494280\n",
      "IMDBid: tt1724962\n",
      "IMDBid: tt1152836\n",
      "IMDBid: tt0389790\n",
      "IMDBid: tt3053228\n",
      "IMDBid: tt1045778\n",
      "IMDBid: tt1758795\n",
      "IMDBid: tt0099385\n",
      "IMDBid: tt2917484\n",
      "IMDBid: tt4769836\n",
      "IMDBid: tt0089652\n",
      "IMDBid: tt0465494\n",
      "IMDBid: tt3675748\n",
      "IMDBid: tt2126362\n",
      "IMDBid: tt0988083\n",
      "IMDBid: tt2101341\n",
      "IMDBid: tt0401997\n",
      "IMDBid: tt1661461\n",
      "IMDBid: tt1313139\n",
      "IMDBid: tt1094661\n",
      "IMDBid: tt5162658\n",
      "IMDBid: tt0104839\n",
      "IMDBid: tt1288558\n",
      "IMDBid: tt5962210\n",
      "IMDBid: tt2937696\n",
      "IMDBid: tt0284363\n",
      "IMDBid: tt5580390\n",
      "IMDBid: tt2293750\n",
      "IMDBid: tt2980472\n",
      "IMDBid: tt0082186\n",
      "IMDBid: tt0924129\n",
      "IMDBid: tt0988595\n",
      "IMDBid: tt1349482\n",
      "IMDBid: tt4158096\n",
      "IMDBid: tt1403241\n",
      "IMDBid: tt2713642\n",
      "IMDBid: tt1682940\n",
      "IMDBid: tt10327354\n",
      "IMDBid: tt1087842\n",
      "IMDBid: tt1800302\n",
      "IMDBid: tt0113855\n",
      "IMDBid: tt2504022\n",
      "IMDBid: tt7248248\n",
      "IMDBid: tt1720164\n",
      "IMDBid: tt1336621\n",
      "IMDBid: tt0266987\n",
      "IMDBid: tt0859635\n",
      "Total IMDB IDs with missing files: 47\n",
      "Missing files:\n",
      "IMDBid: tt2437712\n",
      "IMDBid: tt0099371\n",
      "IMDBid: tt2935564\n",
      "IMDBid: tt0140336\n",
      "IMDBid: tt4687276\n",
      "IMDBid: tt0367085\n",
      "IMDBid: tt0220827\n",
      "IMDBid: tt0465602\n",
      "IMDBid: tt2350496\n",
      "IMDBid: tt1084950\n",
      "IMDBid: tt0110093\n",
      "IMDBid: tt1273235\n",
      "IMDBid: tt4503510\n",
      "IMDBid: tt1772925\n",
      "IMDBid: tt2180411\n",
      "IMDBid: tt0181865\n",
      "IMDBid: tt0200469\n",
      "IMDBid: tt0259288\n",
      "Total IMDB IDs with missing files: 18\n",
      "Missing files:\n",
      "IMDBid: tt0190590\n",
      "IMDBid: tt2383068\n",
      "IMDBid: tt1488555\n",
      "IMDBid: tt0758730\n",
      "IMDBid: tt0389557\n",
      "IMDBid: tt0498353\n",
      "IMDBid: tt5084170\n",
      "IMDBid: tt0405052\n",
      "IMDBid: tt1104733\n",
      "IMDBid: tt1924429\n",
      "IMDBid: tt5027774\n",
      "IMDBid: tt0990413\n",
      "IMDBid: tt5580036\n",
      "IMDBid: tt2524674\n",
      "Total IMDB IDs with missing files: 14\n",
      "Missing files:\n",
      "IMDBid: tt0988595\n",
      "IMDBid: tt1724962\n",
      "IMDBid: tt0758730\n",
      "IMDBid: tt0200469\n",
      "IMDBid: tt0389790\n",
      "IMDBid: tt4503510\n",
      "IMDBid: tt0401997\n",
      "IMDBid: tt1349482\n",
      "IMDBid: tt0082186\n",
      "IMDBid: tt1094661\n",
      "IMDBid: tt0924129\n",
      "IMDBid: tt2437712\n",
      "IMDBid: tt2917484\n",
      "IMDBid: tt3053228\n",
      "IMDBid: tt0099371\n",
      "IMDBid: tt2101341\n",
      "IMDBid: tt0099385\n",
      "IMDBid: tt0259288\n",
      "IMDBid: tt1336621\n",
      "IMDBid: tt1087842\n",
      "IMDBid: tt2937696\n",
      "IMDBid: tt1288558\n",
      "IMDBid: tt2524674\n",
      "IMDBid: tt4158096\n",
      "IMDBid: tt3675748\n",
      "IMDBid: tt1800302\n",
      "IMDBid: tt1104733\n",
      "IMDBid: tt0465494\n",
      "IMDBid: tt0498353\n",
      "IMDBid: tt0110093\n",
      "IMDBid: tt5580036\n",
      "IMDBid: tt5962210\n",
      "IMDBid: tt2180411\n",
      "IMDBid: tt0405052\n",
      "IMDBid: tt2713642\n",
      "IMDBid: tt1772925\n",
      "IMDBid: tt2980472\n",
      "IMDBid: tt0988083\n",
      "IMDBid: tt2935564\n",
      "IMDBid: tt0140336\n",
      "IMDBid: tt7248248\n",
      "IMDBid: tt0104839\n",
      "IMDBid: tt1720164\n",
      "IMDBid: tt0113855\n",
      "IMDBid: tt5084170\n",
      "IMDBid: tt0089652\n",
      "IMDBid: tt2504022\n",
      "IMDBid: tt0220827\n",
      "IMDBid: tt0190590\n",
      "IMDBid: tt0284363\n",
      "IMDBid: tt5162658\n",
      "IMDBid: tt1682940\n",
      "IMDBid: tt10327354\n",
      "IMDBid: tt1152836\n",
      "IMDBid: tt1084950\n",
      "IMDBid: tt4687276\n",
      "IMDBid: tt2293750\n",
      "IMDBid: tt0465602\n",
      "IMDBid: tt0367085\n",
      "IMDBid: tt0266987\n",
      "IMDBid: tt1273235\n",
      "IMDBid: tt2126362\n",
      "IMDBid: tt2494280\n",
      "IMDBid: tt0990413\n",
      "IMDBid: tt0859635\n",
      "IMDBid: tt1488555\n",
      "IMDBid: tt4769836\n",
      "IMDBid: tt2350496\n",
      "IMDBid: tt1313139\n",
      "IMDBid: tt2383068\n",
      "IMDBid: tt5580390\n",
      "IMDBid: tt1758795\n",
      "IMDBid: tt5027774\n",
      "IMDBid: tt0181865\n",
      "IMDBid: tt1924429\n",
      "IMDBid: tt1661461\n",
      "IMDBid: tt1403241\n",
      "IMDBid: tt1045778\n",
      "IMDBid: tt0389557\n",
      "Total IMDB IDs with missing files: 79\n"
     ]
    }
   ],
   "source": [
    "# Load the labels DataFrame\n",
    "id_label_df = pd.read_excel('../../misc/MM-Trailer_dataset.xlsx')\n",
    "\n",
    "# Define the directories\n",
    "text_features_dir = '../../misc/text_features'\n",
    "audio_features_dir = '../../misc/audio_features'\n",
    "video_features_dir = '../../misc/video_features'\n",
    "\n",
    "# Load the feature vectors from each directory\n",
    "text_features = load_npy_files(text_features_dir)\n",
    "audio_features = load_npy_files(audio_features_dir)\n",
    "video_features = load_npy_files(video_features_dir)\n",
    "\n",
    "# Splitting data for training, validation, and testing\n",
    "train_df, val_test_df = train_test_split(id_label_df, test_size=0.3, random_state=42)\n",
    "\n",
    "# Further splitting remaining set into validation and test sets\n",
    "val_df, test_df = train_test_split(val_test_df, test_size=0.5, random_state=42)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = MultimodalDataset(train_df, text_features, audio_features, video_features)\n",
    "val_dataset = MultimodalDataset(val_df, text_features, audio_features, video_features)\n",
    "test_dataset = MultimodalDataset(test_df, text_features, audio_features, video_features)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=0, collate_fn=collate_fn)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=0, collate_fn=collate_fn)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=0, collate_fn=collate_fn)\n",
    "\n",
    "# Combine all data for K-fold cross-validation\n",
    "full_dataset = MultimodalDataset(id_label_df, text_features, audio_features, video_features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Dataloader (for debugging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for text, audio, video, labels in train_dataloader:\n",
    "    # print(f\"Text Shape: {text.shape}\")\n",
    "    # print(f\"Audio Shape: {audio.shape}\")\n",
    "    # print(f\"Video Shape: {video.shape}\")\n",
    "    # print(f\"Labels Shape: {labels.shape}\")\n",
    "    print('---')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Features Shape: torch.Size([8, 1024])\n",
      "Audio Features Shape: torch.Size([8, 1, 197, 768])\n",
      "Video Features Shape: torch.Size([8, 185, 768])\n",
      "Labels shape: torch.Size([8, 1])\n"
     ]
    }
   ],
   "source": [
    "for text_features, audio_features, video_features, targets in train_dataloader:\n",
    "    print(\"Text Features Shape:\", text_features.shape)\n",
    "    print(\"Audio Features Shape:\", audio_features.shape)\n",
    "    print(\"Video Features Shape:\", video_features.shape)\n",
    "    print(\"Labels shape:\", targets.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Sample:\n",
      "Sample 1:\n",
      "------------------------------\n",
      "Text Data Shape: torch.Size([1024])\n",
      "Audio Data Shape: torch.Size([1, 197, 768])\n",
      "Video Data Shape: torch.Size([89, 768])\n",
      "Label: tensor([1.])\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Function to print a sample from the dataset\n",
    "def print_sample(dataset, index):\n",
    "    text_data, audio_data, video_data, label_data = dataset[index]\n",
    "    print(f\"Sample {index}:\")\n",
    "    # print(\"Text Data:\", text_data)\n",
    "    # print(\"Audio Data:\", audio_data)\n",
    "    # print(\"Video Data:\", video_data)\n",
    "    print(\"-\" * 30)\n",
    "    print(\"Text Data Shape:\", text_data.shape)\n",
    "    print(\"Audio Data Shape:\", audio_data.shape)\n",
    "    print(\"Video Data Shape:\", video_data.shape)\n",
    "    print(\"Label:\", label_data)\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "# Print a sample from each dataset\n",
    "print(\"Training Dataset Sample:\")\n",
    "print_sample(train_dataset, 1)  # Change 5 to any index to view different samples\n",
    "\n",
    "# print(\"Validation Dataset Sample:\")\n",
    "# print_sample(val_dataset, 0)  # Change 5 to any index to view different samples\n",
    "\n",
    "# print(\"Test Dataset Sample:\")\n",
    "# print_sample(test_dataset, 0)  # Change 5 to any index to view different samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training DataLoader Samples:\n",
      "Batch 0:\n",
      "Text Data Shape: torch.Size([8, 1024])\n",
      "Audio Data Shape: torch.Size([8, 1, 197, 768])\n",
      "Video Data Shape: torch.Size([8, 146, 768])\n",
      "Labels: torch.Size([8, 1])\n",
      "------------------------------\n",
      "Batch 1:\n",
      "Text Data Shape: torch.Size([8, 1024])\n",
      "Audio Data Shape: torch.Size([8, 1, 197, 768])\n",
      "Video Data Shape: torch.Size([8, 144, 768])\n",
      "Labels: torch.Size([8, 1])\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "def print_dataloader_samples(dataloader, num_batches=1):\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        if i >= num_batches:\n",
    "            break\n",
    "        \n",
    "        text_data, audio_data, video_data, labels_data = batch\n",
    "\n",
    "        # # Convert labels to a list of integers if they are tensors\n",
    "        # if isinstance(labels, torch.Tensor):\n",
    "        #     labels = labels.tolist()\n",
    "\n",
    "        print(f\"Batch {i}:\")\n",
    "        print(\"Text Data Shape:\", text_data.shape)\n",
    "        print(\"Audio Data Shape:\", audio_data.shape)\n",
    "        print(\"Video Data Shape:\", video_data.shape)\n",
    "        print(\"Labels:\", labels_data.shape)\n",
    "        print(\"-\" * 30)\n",
    "\n",
    "# Print a few batches from the training DataLoader\n",
    "print(\"Training DataLoader Samples:\")\n",
    "print_dataloader_samples(train_dataloader, num_batches=2)\n",
    "\n",
    "# # Print a few batches from the validation DataLoader\n",
    "# print(\"Validation DataLoader Samples:\")\n",
    "# print_dataloader_samples(val_dataloader, num_batches=5)\n",
    "\n",
    "# # Print a few batches from the validation DataLoader\n",
    "# print(\"Validation DataLoader Samples:\")\n",
    "# print_dataloader_samples(test_dataloader, num_batches=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GMU Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class for Gated Multimodal Unit of Arevalo et al. (2017)\n",
    "class GatedMultimodalUnit(torch.nn.Module):\n",
    "    def __init__(self, text_dim, audio_dim, video_dim, output_dim):\n",
    "        super(GatedMultimodalUnit, self).__init__()\n",
    "        \n",
    "        # Linear transformation for text\n",
    "        self.text_linear = LinearTransformations(text_dim, output_dim)\n",
    "        \n",
    "        # Convolutional layers for audio and video features\n",
    "        self.audio_conv = nn.Conv1d(audio_dim, output_dim, kernel_size=1)\n",
    "        self.video_conv = nn.Conv1d(video_dim, output_dim, kernel_size=1)\n",
    "        \n",
    "        self.output_dim = output_dim \n",
    "        \n",
    "        # Activation functions\n",
    "        self.activation = nn.Tanh()\n",
    "        self.gate_activation = nn.Sigmoid()\n",
    "        \n",
    "        # Weight matrices for each modality\n",
    "        self.W1 = nn.Parameter(torch.Tensor(output_dim, output_dim))\n",
    "        self.W2 = nn.Parameter(torch.Tensor(output_dim, output_dim))\n",
    "        self.W3 = nn.Parameter(torch.Tensor(output_dim, output_dim))\n",
    "        \n",
    "        # Gating matrices\n",
    "        self.Y1 = nn.Parameter(torch.Tensor(output_dim, output_dim))\n",
    "        self.Y2 = nn.Parameter(torch.Tensor(output_dim, output_dim))\n",
    "        self.Y3 = nn.Parameter(torch.Tensor(output_dim, output_dim))\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._initialize_weights()\n",
    "        \n",
    "    def _initialize_weights(self):\n",
    "        \n",
    "        # Initialize weight matrices\n",
    "        init.xavier_uniform_(self.W1)\n",
    "        init.xavier_uniform_(self.W2)\n",
    "        init.xavier_uniform_(self.W3)\n",
    "        \n",
    "        # Initialize gating matrices\n",
    "        init.xavier_uniform_(self.Y1)\n",
    "        init.xavier_uniform_(self.Y2)\n",
    "        init.xavier_uniform_(self.Y3)\n",
    "        \n",
    "        \n",
    "    def forward(self, text_features, audio_features, video_features):\n",
    "\n",
    "        # Process text features to match shape\n",
    "        x_t = self.text_linear(text_features)              # Shape: [batch_size, output_dim]\n",
    "\n",
    "        # Process audio features to match shape\n",
    "        audio_features = audio_features.squeeze(1).permute(0, 2, 1)               # Shape: [batch_size, audio_dim, sequence_length] \n",
    "        x_a = self.audio_conv(audio_features).mean(dim=-1)              # Shape: [batch_size, output_dim]\n",
    "\n",
    "        # Process video features to match shape\n",
    "        video_features = video_features.permute(0, 2, 1)   # Shape: [batch_size, video_dim, sequence_length]\n",
    "        x_v = self.video_conv(video_features).mean(dim=-1)              # Shape: [batch_size, output_dim]\n",
    " \n",
    "        h1 = self.activation(torch.matmul(x_t, self.W1))        # Shape: [batch_size, output_dim]\n",
    "        h2 = self.activation(torch.matmul(x_a, self.W2))        # Shape: [batch_size, output_dim]\n",
    "        h3 = self.activation(torch.matmul(x_v, self.W3))        # Shape: [batch_size, output_dim]\n",
    "        \n",
    "        # Compute modality-specific gating weights\n",
    "        z1 = self.gate_activation(torch.matmul(x_t, self.Y1))  # Shape: [batch_size, output_dim]\n",
    "        z2 = self.gate_activation(torch.matmul(x_a, self.Y2))  # Shape: [batch_size, output_dim]\n",
    "        z3 = self.gate_activation(torch.matmul(x_v, self.Y3))  # Shape: [batch_size, output_dim]\n",
    "        \n",
    "        # Calculate final output\n",
    "        h = z1 * h1 + z2 * h2 + z3 * h3         \n",
    "\n",
    "        return h\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model (for debugging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "GMU Output Shape: torch.Size([8, 512])\n",
      "GMU Output:  tensor([[-0.0038,  0.1910,  0.1111,  ...,  0.0087,  0.1819,  0.1141],\n",
      "        [-0.0044,  0.0162,  0.2544,  ...,  0.2737,  0.0663,  0.2049],\n",
      "        [ 0.0756,  0.0695,  0.1365,  ...,  0.1385, -0.0628,  0.1549],\n",
      "        ...,\n",
      "        [ 0.1110,  0.1560,  0.0137,  ...,  0.0556, -0.0376,  0.3730],\n",
      "        [-0.0155, -0.0034,  0.1696,  ...,  0.2945, -0.0514,  0.2381],\n",
      "        [-0.1074, -0.0131,  0.1898,  ...,  0.0238, -0.0554,  0.2082]])\n"
     ]
    }
   ],
   "source": [
    "# Test the GMU model using the items from dataloader as input\n",
    "\n",
    "# Define dimensions\n",
    "text_dim = 1024\n",
    "audio_dim = 768  # Number of channels in audio data\n",
    "video_dim = 768  # Number of channels in video data\n",
    "output_dim = 512  # You can set this to any value, depending on your requirements\n",
    "\n",
    "# Instantiate the GMU model\n",
    "gmu = GatedMultimodalUnit(text_dim, audio_dim, video_dim, output_dim)\n",
    "\n",
    "# Use DataLoader to get a batch of data\n",
    "for batch in train_dataloader:  # You can use any DataLoader (train_dataloader, val_dataloader, etc.)\n",
    "    text_data, audio_data, video_data, labels = batch\n",
    "    \n",
    "   \n",
    "    # Feed the entire batch to the GMU model\n",
    "    with torch.no_grad():\n",
    "        output = gmu(text_data, audio_data, video_data)\n",
    "    \n",
    "    # Print the output shape\n",
    "    print('-'*50)\n",
    "    print(\"GMU Output Shape:\", output.shape)\n",
    "    print(\"GMU Output: \", output)\n",
    "    \n",
    "    # Break after the first batch for testing purposes\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected File:\n",
      "Text file: tt2381335.npy\n",
      "Audio file: feature_tt1741243.npy\n",
      "Video file: tt0443453_features.npy\n",
      "--------------------------------------------------\n",
      "Text Feature Shape: torch.Size([1024])\n",
      "Audio Feature Shape: torch.Size([1, 197, 768])\n",
      "Video Feature Shape torch.Size([79, 768])\n",
      "--------------------------------------------------\n",
      "Model output shape: torch.Size([1, 768]) ###[batch_size, output_dim]\n",
      "--------------------------------------------------\n",
      "Model output: tensor([[-2.5238e-01,  7.9541e-02,  3.7040e-01,  1.0298e-01,  8.7948e-02,\n",
      "         -8.1107e-02, -1.4414e-01, -1.4601e-01, -8.6355e-02,  1.6799e-01,\n",
      "          2.7540e-01,  4.0523e-01, -1.4785e-01,  1.0707e-01,  1.3213e-01,\n",
      "         -1.1718e-01,  7.8220e-03, -1.0956e-01, -4.6226e-02, -2.1644e-02,\n",
      "         -1.5270e-01,  3.1718e-01, -2.6788e-01,  2.0977e-01,  2.0672e-01,\n",
      "         -1.3995e-01,  7.3574e-02, -3.1293e-01,  1.9473e-02, -3.2938e-03,\n",
      "          3.3725e-01, -2.1112e-01, -1.5969e-01,  5.2099e-02,  2.2123e-01,\n",
      "         -7.4757e-02, -3.2151e-02,  4.1708e-02, -1.7621e-01,  6.9896e-02,\n",
      "          1.1967e-01, -1.4099e-01,  1.0837e-01,  1.5271e-01,  5.6842e-02,\n",
      "         -4.4073e-02, -3.7940e-02, -3.7420e-01,  2.4433e-01,  6.3164e-02,\n",
      "         -9.9835e-02, -1.6761e-01, -3.4100e-01,  8.2121e-02,  1.4140e-01,\n",
      "         -3.9887e-02,  1.9913e-01,  3.1458e-01,  2.0758e-01,  1.5180e-02,\n",
      "          4.7124e-02,  2.0078e-02,  1.6601e-01, -5.1453e-02, -5.3747e-02,\n",
      "         -2.7411e-01,  2.6459e-01, -3.1728e-01,  1.6923e-01,  1.8640e-01,\n",
      "          1.1905e-01,  1.9367e-01, -1.4528e-01,  3.3905e-02, -2.3457e-01,\n",
      "         -2.2979e-01, -2.3550e-01,  2.8892e-01,  1.2340e-01, -1.6155e-01,\n",
      "          5.9532e-03,  7.9127e-02, -2.1129e-02, -1.1766e-01,  2.1315e-01,\n",
      "         -3.0477e-02,  2.7667e-01, -2.2315e-01, -1.4021e-01, -2.8157e-01,\n",
      "          2.2871e-01,  1.4671e-01, -9.8865e-02,  2.2094e-01,  4.4049e-02,\n",
      "          2.4274e-02,  9.9268e-02, -3.2708e-01,  2.6044e-01, -2.4708e-01,\n",
      "         -6.1903e-03, -4.0866e-02, -1.0112e-01,  2.1834e-01, -2.8152e-01,\n",
      "          1.8347e-01, -3.4281e-02,  2.6831e-01,  5.1848e-03, -9.5060e-02,\n",
      "         -2.8507e-01,  1.3115e-01, -2.6566e-01, -1.8274e-01, -1.1440e-01,\n",
      "         -1.4879e-01, -2.5574e-01, -7.2092e-02,  7.2413e-02,  3.2411e-02,\n",
      "          2.4597e-01,  1.3218e-01, -4.2865e-03, -8.1749e-02, -3.8003e-01,\n",
      "         -6.5884e-02,  2.6245e-02,  3.4793e-02, -1.6681e-01, -1.3195e-01,\n",
      "         -1.4454e-01,  1.1461e-01,  4.4702e-02,  3.3200e-01,  1.1481e-01,\n",
      "          2.2653e-01, -1.0245e-01, -2.7856e-02,  1.2352e-02,  1.6896e-01,\n",
      "          3.9611e-02, -2.1415e-01, -7.7923e-03, -3.3695e-01, -1.5933e-01,\n",
      "         -2.2983e-02, -1.8280e-01,  6.6225e-02, -2.3532e-01, -2.1704e-01,\n",
      "         -1.5262e-01,  1.3457e-01, -9.5969e-02, -2.6586e-01,  1.2602e-01,\n",
      "         -5.8460e-03, -2.7495e-01,  5.2830e-02,  1.5478e-01,  2.8092e-01,\n",
      "         -1.7829e-01, -6.9535e-03, -1.9039e-01,  2.5399e-02, -2.0932e-01,\n",
      "         -8.0851e-02, -2.1654e-01,  3.3658e-02, -5.2687e-02,  6.8328e-02,\n",
      "         -1.2291e-01, -1.3618e-01, -2.3521e-01, -1.2176e-01, -7.7345e-02,\n",
      "          9.3869e-02, -1.1648e-01,  1.5186e-01,  1.8643e-01,  1.7234e-01,\n",
      "         -3.6060e-02, -7.4023e-02, -2.9361e-03,  3.6323e-02, -7.8973e-02,\n",
      "          5.1525e-02,  5.3001e-02, -1.6407e-01, -4.3750e-02, -1.9971e-01,\n",
      "          1.1262e-01, -7.1435e-02,  1.4933e-01, -7.0192e-02,  1.9383e-01,\n",
      "          1.1033e-01,  1.6160e-01, -1.1324e-01, -9.9460e-02,  2.0435e-01,\n",
      "          4.4136e-02,  4.4800e-01,  1.1258e-01,  3.3245e-01, -1.6728e-01,\n",
      "          6.8595e-02,  2.0163e-01,  1.1001e-01,  2.3658e-01,  7.0582e-02,\n",
      "         -1.7772e-01,  1.2876e-01,  4.3555e-02,  3.9757e-01, -1.8227e-01,\n",
      "          3.3144e-01, -3.9602e-01, -3.4326e-01,  3.0039e-01, -2.5089e-01,\n",
      "         -1.2852e-02, -5.6294e-02, -2.0755e-01,  7.3551e-02, -3.1966e-01,\n",
      "          4.6015e-02,  3.0443e-02,  3.1728e-02, -1.0336e-01,  1.1131e-01,\n",
      "          1.5369e-01,  1.4618e-01,  3.8914e-01, -2.9325e-02, -6.8582e-02,\n",
      "          1.0279e-01,  6.1966e-02,  4.2021e-02, -5.7278e-02,  3.0075e-03,\n",
      "         -1.5961e-01,  1.0181e-01, -4.9336e-02,  1.3353e-01,  1.5061e-01,\n",
      "          4.2764e-02,  8.0771e-02, -2.1717e-01,  2.9678e-01, -5.3384e-02,\n",
      "         -2.3354e-01,  1.7238e-01, -5.9087e-02,  2.4427e-02, -7.2703e-02,\n",
      "         -1.6247e-01, -1.7277e-01,  1.2364e-01,  2.2108e-01, -2.3508e-01,\n",
      "          2.7604e-01,  2.9182e-01,  1.0714e-01,  3.1659e-01, -2.1221e-01,\n",
      "         -2.4795e-02, -1.4630e-01, -7.6075e-02,  3.2920e-02, -1.2966e-01,\n",
      "         -1.6559e-02,  1.4893e-02, -3.0810e-01, -3.8118e-01,  1.0475e-01,\n",
      "          1.7641e-01,  8.1184e-02,  4.1387e-01,  7.9400e-02,  5.5618e-02,\n",
      "         -7.3396e-02,  2.7829e-02,  2.2480e-01, -1.1952e-01,  5.5506e-02,\n",
      "         -2.2710e-01,  3.6993e-02, -2.2020e-01, -1.5702e-01, -1.3839e-01,\n",
      "         -9.8354e-02,  4.0730e-02,  1.3971e-01, -1.5345e-01,  2.8566e-01,\n",
      "          3.7634e-01,  8.1154e-02, -1.7664e-01, -1.5373e-01, -1.9601e-01,\n",
      "          1.7202e-01, -1.0471e-01,  1.3717e-01,  4.7503e-02, -6.3037e-02,\n",
      "          3.6490e-01,  1.2894e-02, -4.8618e-02, -2.8127e-01,  2.3724e-01,\n",
      "         -2.5590e-01, -5.3359e-03, -1.1996e-01, -1.5436e-01, -3.0318e-01,\n",
      "          6.7262e-02,  2.8654e-01, -1.6670e-01, -1.4602e-01, -1.2984e-01,\n",
      "          7.2451e-03,  1.6574e-02, -3.9510e-01, -1.0843e-02, -6.4482e-03,\n",
      "         -5.9093e-02, -2.0008e-01,  2.2783e-01,  1.8324e-01,  2.8489e-03,\n",
      "          2.5648e-01, -6.8205e-02,  2.7419e-01,  5.7134e-03, -1.0525e-01,\n",
      "          1.0599e-01, -2.4981e-02,  2.5739e-02,  1.2030e-01,  3.2756e-02,\n",
      "          1.3635e-01,  1.9694e-01,  1.3632e-01, -2.0173e-01, -1.7146e-01,\n",
      "          7.4054e-03,  5.0323e-02, -1.1312e-01, -1.7693e-01, -2.2156e-01,\n",
      "          5.4012e-02, -2.3616e-01, -1.0854e-01, -2.0041e-01, -1.1379e-01,\n",
      "          1.1140e-01, -3.3264e-02,  3.7833e-03,  2.5632e-01, -2.7505e-01,\n",
      "          1.9889e-01, -5.2666e-02, -1.1341e-01, -3.2147e-02,  1.2847e-02,\n",
      "         -6.2820e-02, -2.9156e-01, -5.3914e-02, -2.2014e-01, -8.3206e-02,\n",
      "         -1.2645e-01, -8.4709e-02, -4.1157e-02,  2.4631e-01,  3.4063e-01,\n",
      "          2.0624e-01, -3.1431e-01,  2.2538e-01,  2.9303e-01, -3.1743e-01,\n",
      "          1.8923e-01,  2.2730e-01, -2.6048e-01,  2.1736e-01,  9.2348e-02,\n",
      "         -1.4470e-01, -4.6032e-02, -8.5575e-02, -6.6513e-02, -5.0282e-01,\n",
      "         -7.4347e-02, -2.1454e-01, -2.5923e-02, -1.0857e-01, -2.5710e-01,\n",
      "          1.7106e-01,  2.1617e-02,  4.5395e-02,  2.7502e-01, -2.8117e-01,\n",
      "          2.5249e-01, -1.7343e-01, -1.0925e-01, -1.0750e-01,  2.2293e-01,\n",
      "         -4.3661e-02, -2.6526e-01,  1.5246e-02, -8.5144e-02,  1.5357e-01,\n",
      "          1.1274e-01,  1.0033e-01,  1.0341e-02, -9.2095e-03,  2.1758e-01,\n",
      "         -1.0417e-01,  3.6205e-02,  6.1783e-02,  1.7624e-01,  1.9699e-01,\n",
      "         -9.5694e-02, -5.6690e-02,  2.7491e-01, -1.5288e-01,  7.1110e-03,\n",
      "         -2.7527e-02,  3.0674e-01, -1.4280e-01,  1.3959e-02,  1.7349e-02,\n",
      "          5.7812e-02,  3.1459e-02, -1.5583e-01,  1.2995e-01, -2.8696e-01,\n",
      "          1.5309e-01,  2.3528e-01, -1.5505e-01, -5.2475e-02,  1.4030e-01,\n",
      "         -2.2531e-01, -2.2503e-01, -7.9339e-02, -4.9448e-02,  1.6063e-01,\n",
      "         -2.1571e-01,  1.1580e-02,  8.4666e-02,  9.4534e-02, -1.7779e-01,\n",
      "          2.3372e-01, -1.6354e-01,  1.4099e-01, -3.5298e-02,  3.3291e-01,\n",
      "         -1.7593e-01, -1.2537e-01,  4.0931e-02, -2.1103e-02, -1.1051e-01,\n",
      "         -8.5189e-02, -1.7205e-01,  4.6437e-02,  1.2370e-01,  2.5205e-01,\n",
      "         -2.1971e-01, -3.9159e-01,  4.3224e-02,  3.9112e-02, -4.2609e-02,\n",
      "          2.4770e-01,  1.1153e-01, -1.2243e-01,  2.2220e-02, -3.5997e-01,\n",
      "         -1.6839e-01, -4.1578e-01, -5.0636e-02,  5.7204e-02, -3.5380e-02,\n",
      "          1.7169e-01, -2.4474e-01, -1.3396e-01, -1.8194e-01,  4.9333e-02,\n",
      "          7.6351e-02, -1.1041e-01, -6.2990e-02,  3.2242e-02, -1.7102e-02,\n",
      "          2.3312e-01, -6.5354e-02,  1.5997e-01, -4.2784e-01, -8.3176e-02,\n",
      "         -2.0695e-02,  7.7469e-02,  2.9163e-01, -3.4167e-01,  2.1718e-01,\n",
      "         -1.0583e-02, -2.2211e-01,  7.7847e-02,  2.1837e-01, -3.0749e-01,\n",
      "          1.2688e-01, -3.1101e-01,  3.2026e-01,  1.3275e-01, -2.3313e-01,\n",
      "          1.0919e-02, -2.9581e-01,  2.8477e-02,  4.0838e-03,  1.3192e-01,\n",
      "         -2.0922e-01, -1.5793e-01,  4.4326e-02, -8.3604e-02,  1.4659e-01,\n",
      "          3.8170e-02, -2.1896e-01,  1.9144e-01, -6.5283e-02, -2.6654e-02,\n",
      "         -1.2149e-01, -1.5552e-02, -9.1212e-02, -1.5273e-01,  1.4070e-01,\n",
      "         -4.6104e-02,  1.8777e-01,  1.6695e-01,  1.0835e-01,  1.3461e-01,\n",
      "         -1.7313e-01,  6.8287e-02,  2.0338e-03, -1.3172e-01, -1.3003e-01,\n",
      "          2.1958e-02,  2.8474e-01, -1.3923e-01,  2.0791e-01, -1.4095e-02,\n",
      "         -2.2975e-01,  1.8529e-01, -3.8574e-01, -1.4611e-01,  1.8224e-01,\n",
      "          1.2789e-01, -1.0158e-01, -1.3390e-01, -4.3509e-02, -1.1027e-01,\n",
      "         -6.3630e-02, -2.3250e-01, -2.4000e-01,  1.0881e-01, -1.3055e-01,\n",
      "          1.5912e-04,  2.9105e-02, -1.6695e-01, -3.9232e-01, -4.3973e-01,\n",
      "          1.8535e-01,  2.2775e-01,  8.4392e-02, -1.6448e-01,  4.9296e-01,\n",
      "          1.9873e-01, -2.8257e-01, -2.2885e-01, -6.0122e-02, -3.2716e-01,\n",
      "         -7.3288e-02, -4.4252e-02,  6.0263e-02,  8.1500e-03, -9.0520e-02,\n",
      "         -6.3952e-02, -3.3164e-01,  3.0820e-02,  5.5832e-02, -3.8669e-01,\n",
      "         -1.8103e-01, -1.3703e-01, -1.1693e-02, -2.1916e-01,  2.5625e-01,\n",
      "         -9.3200e-02,  8.0585e-02, -8.3492e-02, -1.2483e-01, -1.6627e-01,\n",
      "         -2.2420e-01,  1.0542e-01,  2.0858e-01, -1.1401e-01,  9.0700e-03,\n",
      "         -3.1215e-01, -1.2482e-01, -1.6118e-01,  2.6701e-01, -3.9661e-02,\n",
      "          2.1181e-02, -1.0047e-01, -4.6006e-02,  1.0471e-01,  1.7436e-02,\n",
      "          7.0653e-02,  1.0844e-01, -2.0441e-01, -1.0451e-01,  8.0188e-02,\n",
      "          1.1775e-01,  1.6747e-01,  1.9713e-01,  5.0234e-02, -3.7130e-02,\n",
      "         -1.2598e-01, -5.2955e-02, -1.9077e-01,  1.3200e-01,  3.0607e-02,\n",
      "          9.5169e-02, -1.5024e-01,  3.0437e-01, -3.7381e-01, -1.5178e-01,\n",
      "          7.7336e-02, -2.9944e-01,  6.1677e-02,  3.7919e-03, -4.7241e-02,\n",
      "         -2.3270e-01, -1.5023e-01,  1.8738e-01,  1.2500e-01, -7.4890e-02,\n",
      "         -2.0038e-01, -2.9187e-01,  1.9283e-01,  2.1350e-01, -2.8813e-01,\n",
      "         -1.2870e-01,  2.0444e-01, -8.1974e-02,  2.8616e-01, -1.6311e-01,\n",
      "          1.1851e-01,  8.1501e-03, -1.8934e-01, -1.9849e-01,  3.4119e-02,\n",
      "         -7.0428e-02,  5.7179e-03, -3.7464e-02, -2.3700e-01,  3.6779e-02,\n",
      "         -1.5561e-01,  2.6507e-02, -1.8029e-01, -2.6829e-01, -2.1050e-01,\n",
      "          2.1307e-01, -2.2176e-02, -1.6587e-01,  1.4821e-01, -2.3370e-01,\n",
      "         -1.4503e-01,  4.1951e-02,  2.9564e-01,  5.4811e-02, -7.3717e-02,\n",
      "          1.6931e-01, -1.8680e-01,  1.1396e-01, -1.4918e-01,  6.5037e-02,\n",
      "         -1.5374e-01,  1.4649e-01, -1.4852e-01, -2.1631e-01, -8.8104e-02,\n",
      "         -1.9980e-01,  1.6654e-01, -7.6510e-03,  3.5343e-01,  1.7337e-01,\n",
      "         -1.0046e-01,  2.6233e-02, -1.4397e-01, -2.1205e-01, -1.0866e-01,\n",
      "          2.1862e-01, -2.7225e-01,  3.6946e-01,  3.4821e-02, -1.0588e-01,\n",
      "         -1.7880e-01,  1.0597e-01, -1.5210e-01,  5.0950e-02,  1.1425e-01,\n",
      "          2.5103e-01,  2.2548e-01, -4.4474e-01, -1.8392e-01, -1.4826e-02,\n",
      "          1.0972e-01, -8.1690e-03,  1.0754e-01,  2.2839e-01,  7.4842e-02,\n",
      "         -1.0327e-01, -5.6234e-02, -1.0914e-01,  5.7950e-02, -6.9247e-02,\n",
      "          2.4012e-01, -2.5528e-01,  3.4046e-01,  2.8555e-01, -3.3870e-01,\n",
      "         -1.2906e-01,  3.6421e-01, -2.4956e-01,  8.8694e-02,  1.7209e-01,\n",
      "          1.9060e-01,  1.4517e-01,  5.2541e-02, -9.6355e-02,  9.2691e-02,\n",
      "          8.3305e-02, -8.3645e-02, -9.4997e-02, -1.6074e-01,  3.7913e-01,\n",
      "         -4.0493e-01, -1.5073e-01,  1.6086e-01, -9.8181e-02,  2.9573e-01,\n",
      "         -2.3576e-01,  1.7418e-03, -1.6531e-01,  7.5751e-02,  1.3244e-01,\n",
      "          3.4167e-01, -1.3926e-02, -1.5238e-01,  1.9716e-01, -3.3382e-01,\n",
      "          1.1837e-01,  3.1485e-01,  8.5036e-02,  7.0903e-02, -9.4579e-02,\n",
      "         -1.9131e-01, -1.7885e-01, -1.5877e-01,  1.3657e-01,  5.7703e-02,\n",
      "          1.2065e-01,  5.6962e-02, -5.1403e-02]])\n"
     ]
    }
   ],
   "source": [
    "from modules.dataloader import load_npy_files\n",
    "\n",
    "# Define the directories\n",
    "text_features_dir = '../../misc/text_features'\n",
    "audio_features_dir = '../../misc/audio_features'\n",
    "video_features_dir = '../../misc/video_features'\n",
    "\n",
    "# Load the feature vectors from each directory\n",
    "text_features = load_npy_files(text_features_dir)\n",
    "audio_features = load_npy_files(audio_features_dir)\n",
    "video_features = load_npy_files(video_features_dir)\n",
    "\n",
    "# Select the first file from each modality directories (for testing) [insert index]\n",
    "text_file_name, text_features = text_features[0]\n",
    "audio_file_name, audio_features = audio_features[0]\n",
    "video_file_name, video_features = video_features[0]\n",
    "\n",
    "print(\"Selected File:\")\n",
    "print(\"Text file:\", os.path.basename(text_file_name))\n",
    "print(\"Audio file:\", os.path.basename(audio_file_name))\n",
    "print(\"Video file:\", os.path.basename(video_file_name))\n",
    "print(\"-\"*50)\n",
    "\n",
    "\n",
    "# Define dimensions (make sure these match your model's expected input sizes)\n",
    "text_dim = 1024\n",
    "audio_dim = 768  # Number of channels in audio data\n",
    "video_dim = 768  # Number of channels in video data\n",
    "output_dim = 768  # You can set this to any value, depending on your requirements\n",
    "\n",
    "# Initialize the GMU model\n",
    "model = GatedMultimodalUnit(text_dim, audio_dim, video_dim, output_dim)\n",
    "\n",
    "# Move model to the same device as your data (e.g., GPU if available)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Prepare the selected data samples\n",
    "text_features = text_features.to(device)  # Convert to tensor and move to device\n",
    "audio_features = audio_features.to(device)  # Convert to tensor and move to device\n",
    "video_features = video_features.to(device)  # Convert to tensor and move to device\n",
    "\n",
    "print(\"Text Feature Shape:\", text_features.shape)\n",
    "print(\"Audio Feature Shape:\", audio_features.shape)\n",
    "print(\"Video Feature Shape\", video_features.shape)\n",
    "print(\"-\"*50)\n",
    "\n",
    "# Pass the data through the GMU model\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "with torch.no_grad():  # No need to compute gradients\n",
    "    output = model(text_features.unsqueeze(0), audio_features, video_features.unsqueeze(0))\n",
    "\n",
    "# Print the output shape\n",
    "print(\"Model output shape:\", output.shape, \"###[batch_size, output_dim]\")\n",
    "print(\"-\"*50)\n",
    "print(\"Model output:\", output) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(parameters, lr=1e-3):\n",
    "    # Create an optimizer, for example, Adam\n",
    "    return optim.Adam(parameters, lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dense_layer, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    dense_layer.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for text_features, audio_features, video_features, targets in dataloader:\n",
    "        text_features, audio_features, video_features, targets = (\n",
    "            text_features.to(device),\n",
    "            audio_features.to(device),\n",
    "            video_features.to(device),\n",
    "            targets.to(device)\n",
    "        )\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Pass inputs through GMU model\n",
    "        outputs = model(text_features, audio_features, video_features)\n",
    "        \n",
    "        # Pass the GMU outputs through the dense layer to get final predictions\n",
    "        predictions = dense_layer(outputs)  # Shape: [batch_size, 1]\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(predictions, targets)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    average_loss = total_loss / len(dataloader)\n",
    "    print(f\"Training Loss: {average_loss:.4f}\")\n",
    "    return average_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dense_layer, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    dense_layer.eval()\n",
    "    total_loss = 0\n",
    "\n",
    "    # Initialize the metrics for binary classification\n",
    "    precision_metric = BinaryPrecision().to(device)\n",
    "    recall_metric = BinaryRecall().to(device)\n",
    "    f1_metric = BinaryF1Score().to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for text_features, audio_features, video_features, targets in dataloader:\n",
    "            text_features, audio_features, video_features, targets = (\n",
    "                text_features.to(device),\n",
    "                audio_features.to(device),\n",
    "                video_features.to(device),\n",
    "                targets.to(device).squeeze()\n",
    "            )\n",
    "\n",
    "            # Pass inputs through GMU model\n",
    "            outputs = model(text_features, audio_features, video_features)\n",
    "            \n",
    "            # Pass the GMU outputs through the dense layer to get final predictions\n",
    "            predictions = dense_layer(outputs).squeeze()  \n",
    "            \n",
    "            # Compute loss\n",
    "            loss = criterion(predictions, targets)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Apply threshold to get binary predictions\n",
    "            preds = (predictions > 0.5).float()\n",
    "            \n",
    "            # Update the precision, recall, and F1 score metrics\n",
    "            precision_metric.update(preds.long(), targets.long())\n",
    "            recall_metric.update(preds.long(), targets.long())\n",
    "            f1_metric.update(preds.long(), targets.long())\n",
    "\n",
    "    # Compute precision, recall, and F1 score\n",
    "    precision = precision_metric.compute().item()\n",
    "    recall = recall_metric.compute().item()\n",
    "    f1_score = f1_metric.compute().item()\n",
    "\n",
    "    average_loss = total_loss / len(dataloader)\n",
    "\n",
    "    print(f\"Evaluation Loss: {average_loss:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1_score:.4f}\")\n",
    "    \n",
    "    return average_loss, precision, recall, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_model(text_dim, audio_dim, video_dim, output_dim, model_class,  dense_layer_class, dataset, criterion, optimizer_class, device, n_splits, collate_fn):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True)\n",
    "    \n",
    "    total_loss = 0\n",
    "    total_precision = 0\n",
    "    total_recall = 0\n",
    "    total_f1 = 0\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(dataset), 1):\n",
    "        print(\"-\"*50)\n",
    "        print(f\"Fold {fold}/{n_splits}\")\n",
    "\n",
    "        # Create subsets for training and validation\n",
    "        train_subset = Subset(dataset, train_index)\n",
    "        val_subset = Subset(dataset, val_index)\n",
    "        \n",
    "        # DataLoaders with batch size 8 and collate function\n",
    "        train_loader = DataLoader(train_subset, batch_size=8, shuffle=True, num_workers=0, collate_fn=collate_fn)\n",
    "        val_loader = DataLoader(val_subset, batch_size=8, shuffle=False, num_workers=0, collate_fn=collate_fn)\n",
    "        \n",
    "        # Initialize the model and dense layer for the current fold\n",
    "        model = model_class(text_dim=text_dim, audio_dim=audio_dim, video_dim=video_dim, output_dim=output_dim).to(device)\n",
    "        dense_layer = dense_layer_class(input_size=output_dim).to(device)\n",
    "        \n",
    "        # Combine parameters of GMU model and DenseLayer for the optimizer\n",
    "        optimizer = optimizer_class(list(model.parameters()) + list(dense_layer.parameters()))\n",
    "        \n",
    "        print(f\"Training model for fold {fold}\")\n",
    "        train_loss = train_model(model, dense_layer, train_loader, criterion, optimizer, device)\n",
    "        \n",
    "        print(f\"Evaluating model for fold {fold}\")\n",
    "        val_loss, precision, recall, f1_score = evaluate_model(model, dense_layer, val_loader, criterion, device)\n",
    "        \n",
    "        total_loss += val_loss\n",
    "        total_precision += precision\n",
    "        total_recall += recall\n",
    "        total_f1 += f1_score\n",
    "    \n",
    "    average_cv_loss = total_loss / n_splits\n",
    "    average_cv_precision = total_precision / n_splits\n",
    "    average_cv_recall = total_recall / n_splits\n",
    "    average_cv_f1 = total_f1 / n_splits\n",
    "    \n",
    "    print(f\"Average Cross-Validation Loss: {average_cv_loss:.4f}\")\n",
    "    print(f\"Average Cross-Validation Precision: {average_cv_precision:.4f}\")\n",
    "    print(f\"Average Cross-Validation Recall: {average_cv_recall:.4f}\")\n",
    "    print(f\"Average Cross-Validation F1 Score: {average_cv_f1:.4f}\")\n",
    "    \n",
    "    return average_cv_loss, average_cv_precision, average_cv_recall, average_cv_f1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Fold 1/50\n",
      "Training model for fold 1\n",
      "Training Loss: 0.4277\n",
      "Evaluating model for fold 1\n",
      "Evaluation Loss: 0.3460\n",
      "Precision: 0.8182\n",
      "Recall: 0.9000\n",
      "F1 Score: 0.8571\n",
      "--------------------------------------------------\n",
      "Fold 2/50\n",
      "Training model for fold 2\n",
      "Training Loss: 0.4470\n",
      "Evaluating model for fold 2\n",
      "Evaluation Loss: 0.2563\n",
      "Precision: 0.8889\n",
      "Recall: 0.8889\n",
      "F1 Score: 0.8889\n",
      "--------------------------------------------------\n",
      "Fold 3/50\n",
      "Training model for fold 3\n",
      "Training Loss: 0.4719\n",
      "Evaluating model for fold 3\n",
      "Evaluation Loss: 0.3358\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "--------------------------------------------------\n",
      "Fold 4/50\n",
      "Training model for fold 4\n",
      "Training Loss: 0.4669\n",
      "Evaluating model for fold 4\n",
      "Evaluation Loss: 0.3792\n",
      "Precision: 0.8000\n",
      "Recall: 0.5714\n",
      "F1 Score: 0.6667\n",
      "--------------------------------------------------\n",
      "Fold 5/50\n",
      "Training model for fold 5\n",
      "Training Loss: 0.4713\n",
      "Evaluating model for fold 5\n",
      "Evaluation Loss: 0.5878\n",
      "Precision: 0.5833\n",
      "Recall: 0.8750\n",
      "F1 Score: 0.7000\n",
      "--------------------------------------------------\n",
      "Fold 6/50\n",
      "Training model for fold 6\n",
      "Training Loss: 0.4492\n",
      "Evaluating model for fold 6\n",
      "Evaluation Loss: 0.6159\n",
      "Precision: 0.6667\n",
      "Recall: 0.5714\n",
      "F1 Score: 0.6154\n",
      "--------------------------------------------------\n",
      "Fold 7/50\n",
      "Training model for fold 7\n",
      "Training Loss: 0.4476\n",
      "Evaluating model for fold 7\n",
      "Evaluation Loss: 0.6468\n",
      "Precision: 0.5000\n",
      "Recall: 0.1667\n",
      "F1 Score: 0.2500\n",
      "--------------------------------------------------\n",
      "Fold 8/50\n",
      "Training model for fold 8\n",
      "Training Loss: 0.4500\n",
      "Evaluating model for fold 8\n",
      "Evaluation Loss: 0.2060\n",
      "Precision: 1.0000\n",
      "Recall: 0.2000\n",
      "F1 Score: 0.3333\n",
      "--------------------------------------------------\n",
      "Fold 9/50\n",
      "Training model for fold 9\n",
      "Training Loss: 0.4486\n",
      "Evaluating model for fold 9\n",
      "Evaluation Loss: 0.2864\n",
      "Precision: 0.8000\n",
      "Recall: 0.6667\n",
      "F1 Score: 0.7273\n",
      "--------------------------------------------------\n",
      "Fold 10/50\n",
      "Training model for fold 10\n",
      "Training Loss: 0.4525\n",
      "Evaluating model for fold 10\n",
      "Evaluation Loss: 0.3927\n",
      "Precision: 0.4286\n",
      "Recall: 1.0000\n",
      "F1 Score: 0.6000\n",
      "--------------------------------------------------\n",
      "Fold 11/50\n",
      "Training model for fold 11\n",
      "Training Loss: 0.4502\n",
      "Evaluating model for fold 11\n",
      "Evaluation Loss: 0.7453\n",
      "Precision: 1.0000\n",
      "Recall: 0.5000\n",
      "F1 Score: 0.6667\n",
      "--------------------------------------------------\n",
      "Fold 12/50\n",
      "Training model for fold 12\n",
      "Training Loss: 0.4400\n",
      "Evaluating model for fold 12\n",
      "Evaluation Loss: 0.2301\n",
      "Precision: 1.0000\n",
      "Recall: 0.7500\n",
      "F1 Score: 0.8571\n",
      "--------------------------------------------------\n",
      "Fold 13/50\n",
      "Training model for fold 13\n",
      "Training Loss: 0.4475\n",
      "Evaluating model for fold 13\n",
      "Evaluation Loss: 0.3284\n",
      "Precision: 0.5000\n",
      "Recall: 0.2000\n",
      "F1 Score: 0.2857\n",
      "--------------------------------------------------\n",
      "Fold 14/50\n",
      "Training model for fold 14\n",
      "Training Loss: 0.4259\n",
      "Evaluating model for fold 14\n",
      "Evaluation Loss: 0.4960\n",
      "Precision: 0.4000\n",
      "Recall: 1.0000\n",
      "F1 Score: 0.5714\n",
      "--------------------------------------------------\n",
      "Fold 15/50\n",
      "Training model for fold 15\n",
      "Training Loss: 0.4279\n",
      "Evaluating model for fold 15\n",
      "Evaluation Loss: 0.2577\n",
      "Precision: 1.0000\n",
      "Recall: 0.5556\n",
      "F1 Score: 0.7143\n",
      "--------------------------------------------------\n",
      "Fold 16/50\n",
      "Training model for fold 16\n",
      "Training Loss: 0.3921\n",
      "Evaluating model for fold 16\n",
      "Evaluation Loss: 0.2856\n",
      "Precision: 0.5000\n",
      "Recall: 0.2000\n",
      "F1 Score: 0.2857\n",
      "--------------------------------------------------\n",
      "Fold 17/50\n",
      "Training model for fold 17\n",
      "Training Loss: 0.4205\n",
      "Evaluating model for fold 17\n",
      "Evaluation Loss: 0.4057\n",
      "Precision: 1.0000\n",
      "Recall: 0.5000\n",
      "F1 Score: 0.6667\n",
      "--------------------------------------------------\n",
      "Fold 18/50\n",
      "Training model for fold 18\n",
      "Training Loss: 0.4141\n",
      "Evaluating model for fold 18\n",
      "Evaluation Loss: 0.4032\n",
      "Precision: 0.7500\n",
      "Recall: 0.3750\n",
      "F1 Score: 0.5000\n",
      "--------------------------------------------------\n",
      "Fold 19/50\n",
      "Training model for fold 19\n",
      "Training Loss: 0.4483\n",
      "Evaluating model for fold 19\n",
      "Evaluation Loss: 0.3024\n",
      "Precision: 0.7778\n",
      "Recall: 0.7778\n",
      "F1 Score: 0.7778\n",
      "--------------------------------------------------\n",
      "Fold 20/50\n",
      "Training model for fold 20\n",
      "Training Loss: 0.4504\n",
      "Evaluating model for fold 20\n",
      "Evaluation Loss: 0.5743\n",
      "Precision: 0.8000\n",
      "Recall: 0.5714\n",
      "F1 Score: 0.6667\n",
      "--------------------------------------------------\n",
      "Fold 21/50\n",
      "Training model for fold 21\n",
      "Training Loss: 0.4310\n",
      "Evaluating model for fold 21\n",
      "Evaluation Loss: 0.0983\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "F1 Score: 1.0000\n",
      "--------------------------------------------------\n",
      "Fold 22/50\n",
      "Training model for fold 22\n",
      "Training Loss: 0.4421\n",
      "Evaluating model for fold 22\n",
      "Evaluation Loss: 0.2147\n",
      "Precision: 0.8333\n",
      "Recall: 0.8333\n",
      "F1 Score: 0.8333\n",
      "--------------------------------------------------\n",
      "Fold 23/50\n",
      "Training model for fold 23\n",
      "Training Loss: 0.4318\n",
      "Evaluating model for fold 23\n",
      "Evaluation Loss: 0.2710\n",
      "Precision: 0.8333\n",
      "Recall: 0.6250\n",
      "F1 Score: 0.7143\n",
      "--------------------------------------------------\n",
      "Fold 24/50\n",
      "Training model for fold 24\n",
      "Training Loss: 0.4040\n",
      "Evaluating model for fold 24\n",
      "Evaluation Loss: 0.3693\n",
      "Precision: 1.0000\n",
      "Recall: 0.7500\n",
      "F1 Score: 0.8571\n",
      "--------------------------------------------------\n",
      "Fold 25/50\n",
      "Training model for fold 25\n",
      "Training Loss: 0.4722\n",
      "Evaluating model for fold 25\n",
      "Evaluation Loss: 0.1903\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "--------------------------------------------------\n",
      "Fold 26/50\n",
      "Training model for fold 26\n",
      "Training Loss: 0.4317\n",
      "Evaluating model for fold 26\n",
      "Evaluation Loss: 0.5265\n",
      "Precision: 0.6000\n",
      "Recall: 0.6000\n",
      "F1 Score: 0.6000\n",
      "--------------------------------------------------\n",
      "Fold 27/50\n",
      "Training model for fold 27\n",
      "Training Loss: 0.4650\n",
      "Evaluating model for fold 27\n",
      "Evaluation Loss: 0.2109\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "--------------------------------------------------\n",
      "Fold 28/50\n",
      "Training model for fold 28\n",
      "Training Loss: 0.4411\n",
      "Evaluating model for fold 28\n",
      "Evaluation Loss: 0.2167\n",
      "Precision: 1.0000\n",
      "Recall: 0.8000\n",
      "F1 Score: 0.8889\n",
      "--------------------------------------------------\n",
      "Fold 29/50\n",
      "Training model for fold 29\n",
      "Training Loss: 0.4533\n",
      "Evaluating model for fold 29\n",
      "Evaluation Loss: 0.4266\n",
      "Precision: 1.0000\n",
      "Recall: 0.5000\n",
      "F1 Score: 0.6667\n",
      "--------------------------------------------------\n",
      "Fold 30/50\n",
      "Training model for fold 30\n",
      "Training Loss: 0.4795\n",
      "Evaluating model for fold 30\n",
      "Evaluation Loss: 0.2770\n",
      "Precision: 1.0000\n",
      "Recall: 0.4000\n",
      "F1 Score: 0.5714\n",
      "--------------------------------------------------\n",
      "Fold 31/50\n",
      "Training model for fold 31\n",
      "Training Loss: 0.4233\n",
      "Evaluating model for fold 31\n",
      "Evaluation Loss: 0.4094\n",
      "Precision: 1.0000\n",
      "Recall: 0.2500\n",
      "F1 Score: 0.4000\n",
      "--------------------------------------------------\n",
      "Fold 32/50\n",
      "Training model for fold 32\n",
      "Training Loss: 0.4238\n",
      "Evaluating model for fold 32\n",
      "Evaluation Loss: 0.4044\n",
      "Precision: 0.3333\n",
      "Recall: 0.6000\n",
      "F1 Score: 0.4286\n",
      "--------------------------------------------------\n",
      "Fold 33/50\n",
      "Training model for fold 33\n",
      "Training Loss: 0.4343\n",
      "Evaluating model for fold 33\n",
      "Evaluation Loss: 0.3128\n",
      "Precision: 1.0000\n",
      "Recall: 0.2000\n",
      "F1 Score: 0.3333\n",
      "--------------------------------------------------\n",
      "Fold 34/50\n",
      "Training model for fold 34\n",
      "Training Loss: 0.4730\n",
      "Evaluating model for fold 34\n",
      "Evaluation Loss: 0.2197\n",
      "Precision: 1.0000\n",
      "Recall: 0.8750\n",
      "F1 Score: 0.9333\n",
      "--------------------------------------------------\n",
      "Fold 35/50\n",
      "Training model for fold 35\n",
      "Training Loss: 0.4541\n",
      "Evaluating model for fold 35\n",
      "Evaluation Loss: 0.4259\n",
      "Precision: 0.6667\n",
      "Recall: 0.8000\n",
      "F1 Score: 0.7273\n",
      "--------------------------------------------------\n",
      "Fold 36/50\n",
      "Training model for fold 36\n",
      "Training Loss: 0.4475\n",
      "Evaluating model for fold 36\n",
      "Evaluation Loss: 0.2481\n",
      "Precision: 1.0000\n",
      "Recall: 0.3333\n",
      "F1 Score: 0.5000\n",
      "--------------------------------------------------\n",
      "Fold 37/50\n",
      "Training model for fold 37\n",
      "Training Loss: 0.4317\n",
      "Evaluating model for fold 37\n",
      "Evaluation Loss: 0.1641\n",
      "Precision: 1.0000\n",
      "Recall: 0.8000\n",
      "F1 Score: 0.8889\n",
      "--------------------------------------------------\n",
      "Fold 38/50\n",
      "Training model for fold 38\n",
      "Training Loss: 0.4746\n",
      "Evaluating model for fold 38\n",
      "Evaluation Loss: 0.5256\n",
      "Precision: 1.0000\n",
      "Recall: 0.4667\n",
      "F1 Score: 0.6364\n",
      "--------------------------------------------------\n",
      "Fold 39/50\n",
      "Training model for fold 39\n",
      "Training Loss: 0.4592\n",
      "Evaluating model for fold 39\n",
      "Evaluation Loss: 0.1613\n",
      "Precision: 1.0000\n",
      "Recall: 0.7500\n",
      "F1 Score: 0.8571\n",
      "--------------------------------------------------\n",
      "Fold 40/50\n",
      "Training model for fold 40\n",
      "Training Loss: 0.4282\n",
      "Evaluating model for fold 40\n",
      "Evaluation Loss: 0.8211\n",
      "Precision: 1.0000\n",
      "Recall: 0.3333\n",
      "F1 Score: 0.5000\n",
      "--------------------------------------------------\n",
      "Fold 41/50\n",
      "Training model for fold 41\n",
      "Training Loss: 0.4321\n",
      "Evaluating model for fold 41\n",
      "Evaluation Loss: 0.6195\n",
      "Precision: 0.6000\n",
      "Recall: 0.3750\n",
      "F1 Score: 0.4615\n",
      "--------------------------------------------------\n",
      "Fold 42/50\n",
      "Training model for fold 42\n",
      "Training Loss: 0.4367\n",
      "Evaluating model for fold 42\n",
      "Evaluation Loss: 0.3406\n",
      "Precision: 0.5000\n",
      "Recall: 0.3333\n",
      "F1 Score: 0.4000\n",
      "--------------------------------------------------\n",
      "Fold 43/50\n",
      "Training model for fold 43\n",
      "Training Loss: 0.4635\n",
      "Evaluating model for fold 43\n",
      "Evaluation Loss: 0.2823\n",
      "Precision: 0.7500\n",
      "Recall: 0.3750\n",
      "F1 Score: 0.5000\n",
      "--------------------------------------------------\n",
      "Fold 44/50\n",
      "Training model for fold 44\n",
      "Training Loss: 0.4535\n",
      "Evaluating model for fold 44\n",
      "Evaluation Loss: 0.3928\n",
      "Precision: 0.7500\n",
      "Recall: 0.5000\n",
      "F1 Score: 0.6000\n",
      "--------------------------------------------------\n",
      "Fold 45/50\n",
      "Training model for fold 45\n",
      "Training Loss: 0.4540\n",
      "Evaluating model for fold 45\n",
      "Evaluation Loss: 0.2997\n",
      "Precision: 1.0000\n",
      "Recall: 0.6250\n",
      "F1 Score: 0.7692\n",
      "--------------------------------------------------\n",
      "Fold 46/50\n",
      "Training model for fold 46\n",
      "Training Loss: 0.4244\n",
      "Evaluating model for fold 46\n",
      "Evaluation Loss: 0.3200\n",
      "Precision: 0.7500\n",
      "Recall: 0.8571\n",
      "F1 Score: 0.8000\n",
      "--------------------------------------------------\n",
      "Fold 47/50\n",
      "Training model for fold 47\n",
      "Training Loss: 0.4363\n",
      "Evaluating model for fold 47\n",
      "Evaluation Loss: 0.7753\n",
      "Precision: 1.0000\n",
      "Recall: 0.1667\n",
      "F1 Score: 0.2857\n",
      "--------------------------------------------------\n",
      "Fold 48/50\n",
      "Training model for fold 48\n",
      "Training Loss: 0.4531\n",
      "Evaluating model for fold 48\n",
      "Evaluation Loss: 0.5693\n",
      "Precision: 1.0000\n",
      "Recall: 0.5000\n",
      "F1 Score: 0.6667\n",
      "--------------------------------------------------\n",
      "Fold 49/50\n",
      "Training model for fold 49\n",
      "Training Loss: 0.4559\n",
      "Evaluating model for fold 49\n",
      "Evaluation Loss: 0.5212\n",
      "Precision: 1.0000\n",
      "Recall: 0.4000\n",
      "F1 Score: 0.5714\n",
      "--------------------------------------------------\n",
      "Fold 50/50\n",
      "Training model for fold 50\n",
      "Training Loss: 0.4498\n",
      "Evaluating model for fold 50\n",
      "Evaluation Loss: 0.3650\n",
      "Precision: 1.0000\n",
      "Recall: 0.3333\n",
      "F1 Score: 0.5000\n",
      "Average Cross-Validation Loss: 0.3812\n",
      "Average Cross-Validation Precision: 0.7766\n",
      "Average Cross-Validation Recall: 0.5330\n",
      "Average Cross-Validation F1 Score: 0.5904\n"
     ]
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define the dimensions\n",
    "text_dim = 1024  \n",
    "audio_dim = 768 \n",
    "video_dim = 768  \n",
    "output_dim = 512 \n",
    "\n",
    "# Cross-validation\n",
    "average_cv_loss = cross_validate_model(\n",
    "    text_dim=text_dim,\n",
    "    audio_dim=audio_dim,\n",
    "    video_dim=video_dim,\n",
    "    output_dim=output_dim,\n",
    "    model_class=GatedMultimodalUnit,\n",
    "    dense_layer_class=DenseLayer,\n",
    "    dataset=full_dataset,  # Use your complete dataset for cross-validation\n",
    "    criterion=BCELoss(),\n",
    "    optimizer_class=get_optimizer,  # Pass optimizer class, not the instantiated optimizer\n",
    "    device=device,\n",
    "    n_splits=50,\n",
    "    collate_fn=collate_fn\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
