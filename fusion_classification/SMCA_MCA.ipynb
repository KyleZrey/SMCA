{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisite Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler\n",
    "from torcheval.metrics import BinaryAccuracy, BinaryPrecision, BinaryRecall, BinaryF1Score\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../')\n",
    "\n",
    "from modules.cross_attentionb import CrossAttentionB\n",
    "from modules.dataloader import load_npy_files\n",
    "from modules.classifier import DenseLayer, BCELoss, CustomLoss, BCEWithLogits, FocalLoss\n",
    "from modules.linear_transformation import LinearTransformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model and Hyperparameter Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Define all possible modality assignments\n",
    "modality_configurations = {\n",
    "    'ATV': {\n",
    "        'modalityAlpha': 'audio_features',\n",
    "        'modalityBeta': 'text_features',\n",
    "        'modalityGamma': 'video_features'\n",
    "    },\n",
    "    'AVT': {\n",
    "        'modalityAlpha': 'audio_features',\n",
    "        'modalityBeta': 'video_features',\n",
    "        'modalityGamma': 'text_features'\n",
    "    },\n",
    "    'TVA': {\n",
    "        'modalityAlpha': 'text_features',\n",
    "        'modalityBeta': 'video_features',\n",
    "        'modalityGamma': 'audio_features'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Function to get the modality assignments by configuration name\n",
    "def get_modality_assignments(config_name):\n",
    "    if config_name in modality_configurations:\n",
    "        return modality_configurations[config_name]\n",
    "    else:\n",
    "        raise ValueError(f\"Configuration '{config_name}' not found.\")\n",
    "    \n",
    "    \n",
    "# Define possible configurations for audio feature directories\n",
    "audio_feature_paths = {\n",
    "    'logmel': '../misc/audio_features/logmel',\n",
    "    'mfcc': '../misc/audio_features/mfcc'\n",
    "}\n",
    "\n",
    "# Function to get the audio feature path based on the selected configuration\n",
    "def get_audio_feature_path(config_name):\n",
    "    if config_name in audio_feature_paths:\n",
    "        return audio_feature_paths[config_name]\n",
    "    else:\n",
    "        raise ValueError(f\"Configuration '{config_name}' not found. Available options: logmel, mfcc.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "### Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "### Modality Assignment: 'ATV', 'AVT', 'TVA'\n",
    "selected_config = 'AVT'\n",
    "modality_assignments = get_modality_assignments(selected_config)\n",
    "\n",
    "### Audio Feature selection: 'logmel' or 'mfcc'\n",
    "selected_config = 'logmel'\n",
    "audio_features_dir = get_audio_feature_path(selected_config)\n",
    "\n",
    "#### Data Configuration: 8 16 32 64 128\n",
    "train_batch_size = 32   # Set the batch size for training data\n",
    "val_batch_size = 16     # Set the batch size for validation data\n",
    "test_batch_size= 16     # Set the batch size for testing data\n",
    "\n",
    "#FIXED CONSTANT\n",
    "max_pad = 197\n",
    "\n",
    "### Hyperparameters\n",
    "threshold = 0.5              # for predictions\n",
    "learning_rate = 1e-5         # For optimizer\n",
    "cl_dropout_rate = 0.4        # for FinalClassifier\n",
    "att_dropout_rate = 0.4       # for MutualCrossAttention\n",
    "num_epochs = 10              # for model training\n",
    "\n",
    "### Classifier Configuration\n",
    "isBCELoss = True                          # !!! SET ACCORDINGLY !!!\n",
    "criterion = BCELoss()\n",
    "# criterion = BCEWithLogits().to(device)\n",
    "# criterion = CustomLoss(pos_weight=2.94)\n",
    "# criterion = FocalLoss(alpha=0.25, gamma=2, pos_weight=0.34)\n",
    "\n",
    "# !!! Choose Classifier !!! False = Dense Layer, True = Final Classifier\n",
    "isFinalClassifier = True\n",
    "\n",
    "### For cross validation\n",
    "num_folds = 5          # Set the number of folds for cross-validation\n",
    "num_epochs_cv = 10     # Set the number of epochs for cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultimodalDataset(Dataset):\n",
    "    def __init__(self, id_label_df, text_features, audio_features, video_features):\n",
    "        self.id_label_df = id_label_df\n",
    "        \n",
    "        # Convert feature lists to dictionaries for fast lookup\n",
    "        self.text_features = {os.path.basename(file).split('.')[0]: tensor for file, tensor in text_features}\n",
    "        self.audio_features = {os.path.basename(file).split('_')[1].split('.')[0]: tensor for file, tensor in audio_features}\n",
    "        self.video_features = {os.path.basename(file).split('_')[0]: tensor for file, tensor in video_features}\n",
    "\n",
    "        # List to store missing files\n",
    "        self.missing_files = []\n",
    "\n",
    "        # Filter out entries with missing files\n",
    "        self.valid_files = self._filter_valid_files()\n",
    "\n",
    "    def _filter_valid_files(self):\n",
    "        valid_indices = []\n",
    "        missing_files = []\n",
    "\n",
    "        for idx in range(len(self.id_label_df)):\n",
    "            imdbid = self.id_label_df.iloc[idx]['IMDBid']\n",
    "\n",
    "            # Check if the IMDBid exists in each modality's features\n",
    "            if imdbid in self.text_features and imdbid in self.audio_features and imdbid in self.video_features:\n",
    "                valid_indices.append(idx)\n",
    "            else:\n",
    "                missing_files.append({'IMDBid': imdbid})\n",
    "\n",
    "        # Filter id_label_df to only include valid rows\n",
    "        self.id_label_df = self.id_label_df.iloc[valid_indices].reset_index(drop=True)\n",
    "        self.missing_files = missing_files\n",
    "        \n",
    "        # Update valid_indices to reflect the new indices after resetting\n",
    "        valid_indices = list(range(len(self.id_label_df)))\n",
    "\n",
    "        # Return valid indices\n",
    "        return valid_indices\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.valid_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get the original index from the filtered valid files\n",
    "        original_idx = self.valid_files[idx]\n",
    "        imdbid = self.id_label_df.iloc[original_idx]['IMDBid']\n",
    "        label = self.id_label_df.iloc[original_idx]['Label']\n",
    "\n",
    "        # Retrieve data from the loaded features\n",
    "        text_data = self.text_features.get(imdbid, torch.zeros((1024,)))\n",
    "        audio_data = self.audio_features.get(imdbid, torch.zeros((1, 197, 768)))\n",
    "        video_data = self.video_features.get(imdbid, torch.zeros((95, 768)))\n",
    "        \n",
    "        # Define label mapping\n",
    "        label_map = {'red': 1, 'green': 0} \n",
    "        \n",
    "        # Convert labels to tensor using label_map\n",
    "        try:\n",
    "            label_data = torch.tensor([label_map[label]], dtype=torch.float32)\n",
    "        except KeyError as e:\n",
    "            print(f\"Error: Label '{e}' not found in label_map.\")\n",
    "            raise\n",
    "\n",
    "        return imdbid, text_data, audio_data, video_data, label_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    # Unpack batch elements\n",
    "    imdbids, text_data, audio_data, video_data, label_data = zip(*batch)\n",
    "\n",
    "    # Convert lists to tensors\n",
    "    text_data = torch.stack(text_data)\n",
    "    audio_data = torch.stack(audio_data)\n",
    "\n",
    "    # Padding for video data\n",
    "    # Determine maximum length of video sequences in the batch\n",
    "    video_lengths = [v.size(0) for v in video_data]\n",
    "    max_length = max(video_lengths)\n",
    "\n",
    "    # Pad video sequences to the maximum length\n",
    "    video_data_padded = torch.stack([\n",
    "        F.pad(v, (0, 0, 0, max_length - v.size(0)), \"constant\", 0)\n",
    "        for v in video_data\n",
    "    ])\n",
    "\n",
    "    # Convert labels to tensor and ensure the shape [batch_size, 1]\n",
    "    label_data = torch.stack(label_data)  # Convert list of tensors to a single tensor\n",
    "\n",
    "    return imdbids, text_data, audio_data, video_data_padded, label_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_video_features(video_features, lower_bound=35, upper_bound=197):\n",
    "    # Assuming video_features is a list of tuples where the second element is the numpy array\n",
    "    filtered_video_features = [v for v in video_features if lower_bound <= v[1].shape[0] <= upper_bound]\n",
    "    return filtered_video_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of text feature vectors loaded: 1353\n",
      "Number of audio feature vectors loaded: 1353\n",
      "Number of video feature vectors loaded: 1325\n",
      "train_df shape: (927, 2)\n",
      "val_df shape: (199, 2)\n",
      "test_df shape: (199, 2)\n",
      "Train label distribution: Label\n",
      "green    693\n",
      "red      234\n",
      "Name: count, dtype: int64\n",
      "Validation label distribution: Label\n",
      "green    149\n",
      "red       50\n",
      "Name: count, dtype: int64\n",
      "Test label distribution: Label\n",
      "green    149\n",
      "red       50\n",
      "Name: count, dtype: int64\n",
      "----------------------------------------\n",
      "Train DataLoader: Total Samples = 927, Number of Batches = 29\n",
      "Validation DataLoader: Total Samples = 199, Number of Batches = 13\n",
      "Test DataLoader: Total Samples = 199, Number of Batches = 13\n"
     ]
    }
   ],
   "source": [
    "# Load the labels DataFrame\n",
    "id_label_df = pd.read_excel('../misc/MM-Trailer_dataset.xlsx')\n",
    "\n",
    "# Define the directories\n",
    "text_features_dir = '../misc/text_features'\n",
    "audio_features_dir = audio_features_dir\n",
    "video_features_dir = '../misc/video_features'\n",
    "\n",
    "# Load the feature vectors from each directory\n",
    "text_features = load_npy_files(text_features_dir)\n",
    "audio_features = load_npy_files(audio_features_dir)\n",
    "video_features = load_npy_files(video_features_dir)\n",
    "\n",
    "video_features = filter_video_features(video_features)\n",
    "\n",
    "print(f\"Number of text feature vectors loaded: {len(text_features)}\")\n",
    "print(f\"Number of audio feature vectors loaded: {len(audio_features)}\")\n",
    "print(f\"Number of video feature vectors loaded: {len(video_features)}\")\n",
    "\n",
    "# Drop unnecessary columns\n",
    "id_label_df = id_label_df.drop(columns=['Movie Title', 'URL'])\n",
    "\n",
    "full_dataset = MultimodalDataset(id_label_df, text_features, audio_features, video_features)\n",
    "\n",
    "# perform train-test split on the filtered DataFrame\n",
    "train_df, val_test_df = train_test_split(\n",
    "    full_dataset.id_label_df, test_size=0.3, random_state=42, stratify=full_dataset.id_label_df['Label'])\n",
    "\n",
    "# Further splitting remaining set into validation and test sets\n",
    "val_df, test_df = train_test_split(\n",
    "    val_test_df, test_size=0.5, random_state=42, stratify=val_test_df['Label'])\n",
    "\n",
    "print(\"train_df shape:\", train_df.shape)\n",
    "print(\"val_df shape:\", val_df.shape)\n",
    "print(\"test_df shape:\", test_df.shape)\n",
    "\n",
    "print(\"Train label distribution:\", train_df['Label'].value_counts())\n",
    "print(\"Validation label distribution:\", val_df['Label'].value_counts())\n",
    "print(\"Test label distribution:\", test_df['Label'].value_counts())\n",
    "\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# create datasets based on these splits\n",
    "train_dataset = MultimodalDataset(train_df, text_features, audio_features, video_features)\n",
    "val_dataset = MultimodalDataset(val_df, text_features, audio_features, video_features)\n",
    "test_dataset = MultimodalDataset(test_df, text_features, audio_features, video_features)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True, num_workers=0, collate_fn=collate_fn, generator=torch.Generator().manual_seed(42))\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=val_batch_size, shuffle=True, num_workers=0, collate_fn=collate_fn, generator=torch.Generator().manual_seed(42))\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False, num_workers=0, collate_fn=collate_fn, generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "# Function to calculate and print the size of each DataLoader\n",
    "def print_dataloader_sizes(dataloader, name):\n",
    "    total_samples = len(dataloader.dataset)  # Get the size of the dataset\n",
    "    num_batches = len(dataloader)  # Get the number of batches\n",
    "    print(f\"{name} DataLoader: Total Samples = {total_samples}, Number of Batches = {num_batches}\")\n",
    "\n",
    "# Print sizes of each DataLoader\n",
    "print_dataloader_sizes(train_dataloader, \"Train\")\n",
    "print_dataloader_sizes(val_dataloader, \"Validation\")\n",
    "print_dataloader_sizes(test_dataloader, \"Test\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers:\n",
      "Lower Bound: 30\n",
      "Uppder Bound: 197\n",
      "Number of outliers: 0\n"
     ]
    }
   ],
   "source": [
    "# Calculate the Q1 (25th percentile) and Q3 (75th percentile) for sequence lengths\n",
    "sequence_lengths = [tensor.size(0) for _, tensor in video_features]  # Extract sequence lengths\n",
    "\n",
    "Q1 = np.percentile(sequence_lengths, 25)\n",
    "Q3 = np.percentile(sequence_lengths, 75)\n",
    "\n",
    "# Calculate the Interquartile Range (IQR)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define the lower and upper bounds for outliers\n",
    "# lower_bound = Q1 - 1.5 * IQR\n",
    "# upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "lower_bound = 30\n",
    "upper_bound = 197\n",
    "\n",
    "# Find the outliers\n",
    "outliers = []\n",
    "\n",
    "for file, video_tensor in video_features:\n",
    "    imdbid = os.path.basename(file).split('_')[0]  # Extract IMDB ID from the file name\n",
    "    seq_length = video_tensor.size(0)\n",
    "    \n",
    "    # Check if the sequence length is an outlier\n",
    "    if seq_length < lower_bound or seq_length > upper_bound:\n",
    "        outliers.append((imdbid, seq_length))\n",
    "\n",
    "# Print outliers\n",
    "print(\"Outliers:\")\n",
    "for imdbid, seq_length in outliers:\n",
    "    print(f\"IMDB ID: {imdbid}, Sequence Length: {seq_length}\")\n",
    "\n",
    "print(\"Lower Bound:\", lower_bound)\n",
    "print(\"Uppder Bound:\", upper_bound)\n",
    "print(\"Number of outliers:\", len(outliers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MCA Class\n",
    "class MutualCrossAttention(nn.Module):\n",
    "    def __init__(self, dropout):\n",
    "        super(MutualCrossAttention, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.layer_norm = nn.LayerNorm(768).to(device)\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        # Move x1 and x2 to the correct device\n",
    "        x1, x2 = x1.to(self.device), x2.to(self.device)\n",
    "\n",
    "        # Assign x1 and x2 to query and key\n",
    "        query = x1\n",
    "        key = x2\n",
    "        d = query.shape[-1]\n",
    "\n",
    "        # Basic attention mechanism formula to get intermediate output A\n",
    "        scores = torch.bmm(query, key.transpose(1, 2)) / math.sqrt(d)\n",
    "        output_A = torch.bmm(self.dropout(F.softmax(scores, dim=-1)), x2)\n",
    "        # Basic attention mechanism formula to get intermediate output B\n",
    "        scores = torch.bmm(key, query.transpose(1, 2)) / math.sqrt(d)\n",
    "        output_B = torch.bmm(self.dropout(F.softmax(scores, dim=-1)), x1)\n",
    "\n",
    "        # Make the summation of the two intermediate outputs\n",
    "        output = output_A + output_B  # shape (1280, 32, 60)\n",
    "\n",
    "        output = self.layer_norm(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMCA Functions and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SMCAStage1(modalityAlpha, modalityBeta, d_out_kq, d_out_v, device):\n",
    "    \n",
    "    cross_attn = MutualCrossAttention(att_dropout_rate)\n",
    "\n",
    "    # Cross-attention: Alpha + Beta\n",
    "    alphaBeta = cross_attn(modalityAlpha, modalityBeta)  # Shape: (batch_size, num_queries, d_out_v)\n",
    "\n",
    "    # Concatenate cross-attention outputs along the feature dimension (-1)\n",
    "    return alphaBeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SMCAStage2(modalityAlphaBeta, modalityGamma, d_out_kq, d_out_v, device):\n",
    "    # modalityAlphaBeta: (batch_size, seq_len, 2 * d_out_v) [output of Stage 1]\n",
    "\n",
    "    cross_attn = MutualCrossAttention(att_dropout_rate)\n",
    "\n",
    "    alphaBetaGamma = cross_attn(modalityAlphaBeta, modalityGamma)  # Shape: (batch_size, seq_len_alphaBeta, d_out_v)\n",
    "\n",
    "    return alphaBetaGamma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SMCAModel(nn.Module):\n",
    "    def __init__(self, d_out_kq, d_out_v, device):\n",
    "        super(SMCAModel, self).__init__()\n",
    "        self.d_out_kq = d_out_kq\n",
    "        self.d_out_v = d_out_v\n",
    "        self.device = device\n",
    "    \n",
    "    def forward(self, modalityAlpha, modalityBeta, modalityGamma):\n",
    "        # Stage 1: Cross attention between modalityAlpha and modalityBeta\n",
    "        modalityAlphaBeta = SMCAStage1(modalityAlpha, modalityBeta, self.d_out_kq, self.d_out_v, self.device)\n",
    "\n",
    "        # Stage 2: Cross attention with modalityAlphaBeta (as query) and modalityGamma (as key-value)\n",
    "        multimodal_representation = SMCAStage2(modalityAlphaBeta, modalityGamma, self.d_out_kq, self.d_out_v, self.device)\n",
    "\n",
    "        return multimodal_representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_features(features, max_pad=max_pad):\n",
    "    # Pad or trim the sequence dimension to `max_pad`\n",
    "    if features.size(1) < max_pad:\n",
    "        # Pad to the right along the sequence dimension\n",
    "        features = F.pad(features, (0, 0, 0, max_pad - features.size(1)))\n",
    "    elif features.size(1) == max_pad:\n",
    "        pass\n",
    "    else:\n",
    "        # Trim if the sequence is longer than `max_pad`\n",
    "        features = features[:, :max_pad, :]\n",
    "        print(\"VIDEO TRIMMED SOMETHING MAY MALI\")\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinalClassifier(nn.Module):\n",
    "    def __init__(self, input_size, dropout_rate=cl_dropout_rate):\n",
    "        super(FinalClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 3072)  # First fully connected layer\n",
    "        self.fc2 = nn.Linear(3072, 768)          # Second fully connected layer\n",
    "        # self.fc3 = nn.Linear(768, 128)          # Third fully connected layer\n",
    "        # self.fc4 = nn.Linear(128, 64)          # Second fully connected layer\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_rate) # Dropout layer\n",
    "        self.dense = nn.Linear(768, 1)          # Final dense layer for binary classification\n",
    "        self.relu = nn.ReLU()                    # ReLU activation\n",
    "        self.sigmoid = nn.Sigmoid()              # Sigmoid activation for final output\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)                         # First fully connected layer\n",
    "        x = self.relu(x)                        # Apply ReLU activation\n",
    "\n",
    "        x = self.fc2(x)                         # second fully connected layer\n",
    "        x = self.relu(x)                        # Apply ReLU activation\n",
    "        x = self.dropout(x)                     # Apply dropout\n",
    "        \n",
    "        # x = self.fc3(x)                         # third fully connected layer\n",
    "        # x = self.relu(x)                        # Apply ReLU activation\n",
    "\n",
    "        # x = self.fc4(x)                         # fourth fully connected layer\n",
    "        # x = self.relu(x)                        # Apply ReLU activation\n",
    "        # x = self.dropout(x)                     # Apply dropout\n",
    "        \n",
    "        x = self.dense(x)                       # Final dense layer\n",
    "        if isBCELoss:\n",
    "            x = self.sigmoid(x)                  # Apply sigmoid activation\n",
    "        return x                                 # Output probabilities for BCELoss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model, \n",
    "    dense_layer, \n",
    "    dataloader, \n",
    "    criterion, \n",
    "    optimizer, \n",
    "    device,\n",
    "    output_dir='results/', \n",
    "    output_filename='train_predictions.csv',\n",
    "    output_dim=768\n",
    "):\n",
    "    # model.train()\n",
    "    dense_layer.train()\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    # Create the output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Initialize metrics for binary classification\n",
    "    precision_metric = BinaryPrecision().to(device)\n",
    "    recall_metric = BinaryRecall().to(device)\n",
    "    f1_metric = BinaryF1Score().to(device)\n",
    "    accuracy_metric = BinaryAccuracy().to(device) \n",
    "    \n",
    "    # Reset metrics at the start of training\n",
    "    precision_metric.reset()\n",
    "    recall_metric.reset()\n",
    "    f1_metric.reset()\n",
    "    accuracy_metric.reset()\n",
    "    \n",
    "    # List to collect results for CSV\n",
    "    results = []\n",
    "    \n",
    "\n",
    "\n",
    "    for imdbids, text_features, audio_features, video_features, targets in dataloader:\n",
    "        text_features, audio_features, video_features, targets = (\n",
    "            text_features.to(device),\n",
    "            audio_features.to(device),\n",
    "            video_features.to(device),\n",
    "            targets.to(device).view(-1)\n",
    "        )\n",
    "                \n",
    "        # Squeeze the audio features to remove the extra dimension\n",
    "        audio_features = audio_features.squeeze(1).to(device) \n",
    "        text_features = text_features.unsqueeze(1).to(device) \n",
    "\n",
    "        # Apply linear transformations to match dimensions\n",
    "        linear_transform_text = LinearTransformations(text_features.shape[-1], 768).to(device)    \n",
    "        text_features = linear_transform_text(text_features).to(device) \n",
    "        \n",
    "        audio_features = audio_features[:, -1, :].unsqueeze(1).to(device)   # Resulting shape: [batch_size, 1, 768]\n",
    "\n",
    "        video_features = pad_features(video_features).to(device)   # Shape will be [batch_size, max_pad, 768]\n",
    "\n",
    "        transformed_features = {\n",
    "            'audio_features': audio_features,\n",
    "            'text_features': text_features,\n",
    "            'video_features': video_features\n",
    "        }\n",
    "\n",
    "        outputs = model(\n",
    "            modalityAlpha=transformed_features[modality_assignments['modalityAlpha']].to(device) ,  # Use the dictionary for modality assignment\n",
    "            modalityBeta=transformed_features[modality_assignments['modalityBeta']].to(device) ,\n",
    "            modalityGamma=transformed_features[modality_assignments['modalityGamma']].to(device) \n",
    "        ).to(device)\n",
    "\n",
    "        outputs = outputs.view(outputs.size(0), -1)  # Shape will be [batch_size, 153600]\n",
    "\n",
    "        # Pass the fused features through the dense layer\n",
    "        predictions = dense_layer(outputs).view(-1)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(predictions, targets)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # !!!Apply if BCEWithLogits or CustomLoss!!!\n",
    "        if not isBCELoss:\n",
    "            predictions = torch.sigmoid(predictions)\n",
    "\n",
    "        # Apply threshold to get binary predictions\n",
    "        preds = (predictions >= threshold).float()\n",
    "        \n",
    "        # Collect results for each sample\n",
    "        for i in range(len(imdbids)):\n",
    "            results.append({\n",
    "                'IMDBid': imdbids[i],\n",
    "                'Raw Prediction': predictions[i].item(),\n",
    "                'Binary Prediction': preds[i].item(),\n",
    "                'Target': targets[i].item()\n",
    "            })\n",
    "        \n",
    "        # Update metrics for binary classification\n",
    "        precision_metric.update(preds.long(), targets.long())\n",
    "        recall_metric.update(preds.long(), targets.long())\n",
    "        f1_metric.update(preds.long(), targets.long())\n",
    "        accuracy_metric.update(preds.long(), targets.long()) \n",
    "\n",
    "    # Compute average precision, recall, F1 score, and accuracy\n",
    "    train_precision = precision_metric.compute().item()\n",
    "    train_recall = recall_metric.compute().item()\n",
    "    train_f1_score = f1_metric.compute().item()\n",
    "    train_accuracy = accuracy_metric.compute().item()  # Compute accuracy\n",
    "    \n",
    "    train_average_loss = total_loss / len(dataloader)\n",
    "    \n",
    "\n",
    "    # Create DataFrame and save to CSV\n",
    "    results_df = pd.DataFrame(results)\n",
    "    output_filepath = os.path.join(output_dir, output_filename)\n",
    "    results_df.to_csv(output_filepath, index=False, header=True)\n",
    "\n",
    "    return train_average_loss, train_accuracy, train_precision, train_recall, train_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(\n",
    "    model, \n",
    "    dense_layer, \n",
    "    dataloader, \n",
    "    criterion, \n",
    "    device,\n",
    "    output_dir='results/', \n",
    "    output_filename='val_predictions.csv',\n",
    "    output_dim=768\n",
    "):\n",
    "    model.eval()\n",
    "    dense_layer.eval()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    # Create the output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Initialize metrics for binary classification\n",
    "    precision_metric = BinaryPrecision().to(device)\n",
    "    recall_metric = BinaryRecall().to(device)\n",
    "    f1_metric = BinaryF1Score().to(device)\n",
    "    accuracy_metric = BinaryAccuracy().to(device) \n",
    "    \n",
    "    # Reset metrics at the start of training\n",
    "    precision_metric.reset()\n",
    "    recall_metric.reset()\n",
    "    f1_metric.reset()\n",
    "    accuracy_metric.reset()\n",
    "    \n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    \n",
    "    # List to collect results for CSV\n",
    "    results = []\n",
    "    \n",
    "\n",
    "    \n",
    "    with torch.no_grad():\n",
    "         for imdbids, text_features, audio_features, video_features, targets in dataloader:\n",
    "            text_features, audio_features, video_features, targets = (\n",
    "                text_features.to(device),\n",
    "                audio_features.to(device),\n",
    "                video_features.to(device),\n",
    "                targets.to(device).view(-1)\n",
    "            )\n",
    "        \n",
    "            # Squeeze the audio features to remove the extra dimension\n",
    "            audio_features = audio_features.squeeze(1).to(device)\n",
    "            text_features = text_features.unsqueeze(1).to(device)\n",
    "\n",
    "            # Apply linear transformations to match dimensions\n",
    "            linear_transform_text = LinearTransformations(text_features.shape[-1], 768).to(device)   \n",
    "            text_features = linear_transform_text(text_features).to(device)\n",
    "            \n",
    "            audio_features = audio_features[:, -1, :].unsqueeze(1).to(device)  # Resulting shape: [batch_size, 1, 768]\n",
    "    \n",
    "            video_features = pad_features(video_features).to(device)  # Shape will be [batch_size, max_pad, 768]\n",
    "                    \n",
    "            transformed_features = {\n",
    "                'audio_features': audio_features,\n",
    "                'text_features': text_features,\n",
    "                'video_features': video_features\n",
    "            }\n",
    "\n",
    "            outputs = model(\n",
    "                modalityAlpha=transformed_features[modality_assignments['modalityAlpha']].to(device),  # Use the dictionary for modality assignment\n",
    "                modalityBeta=transformed_features[modality_assignments['modalityBeta']].to(device),\n",
    "                modalityGamma=transformed_features[modality_assignments['modalityGamma']].to(device)\n",
    "            )\n",
    "\n",
    "            outputs = outputs.view(outputs.size(0), -1)  # Shape will be [batch_size, 153600]\n",
    "\n",
    "            # Pass the fused features through the dense layer\n",
    "            predictions = dense_layer(outputs).view(-1)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = criterion(predictions, targets)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # !!!Apply if BCEWithLogits or CustomLoss!!!\n",
    "            if not isBCELoss:\n",
    "                predictions = torch.sigmoid(predictions)\n",
    "\n",
    "            # Apply threshold to get binary predictions\n",
    "            preds = (predictions >= threshold).float()\n",
    "            \n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "            \n",
    "            # Collect results for each sample\n",
    "            for i in range(len(imdbids)):\n",
    "                results.append({\n",
    "                    'IMDBid': imdbids[i],\n",
    "                    'Raw Prediction': predictions[i].item(),\n",
    "                    'Binary Prediction': preds[i].item(),\n",
    "                    'Target': targets[i].item()\n",
    "                })\n",
    "            \n",
    "            # Update metrics for binary classification\n",
    "            precision_metric.update(preds.long(), targets.long())\n",
    "            recall_metric.update(preds.long(), targets.long())\n",
    "            f1_metric.update(preds.long(), targets.long())\n",
    "            accuracy_metric.update(preds.long(), targets.long()) \n",
    "\n",
    "    # Compute average precision, recall, F1 score, and accuracy\n",
    "    val_precision = precision_metric.compute().item()\n",
    "    val_recall = recall_metric.compute().item()\n",
    "    val_f1_score = f1_metric.compute().item()\n",
    "    val_accuracy = accuracy_metric.compute().item() \n",
    "    \n",
    "    # Calculate confusion matrix\n",
    "    val_conf_matrix = confusion_matrix(all_targets, np.round(all_predictions))\n",
    "\n",
    "    val_average_loss = total_loss / len(dataloader)\n",
    "    \n",
    "    # Create DataFrame and save to CSV\n",
    "    results_df = pd.DataFrame(results)\n",
    "    output_filepath = os.path.join(output_dir, output_filename)\n",
    "    results_df.to_csv(output_filepath, index=False, header=True)\n",
    "    \n",
    "    return val_average_loss, val_accuracy, val_precision, val_recall, val_f1_score, val_conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(\n",
    "    model, \n",
    "    dense_layer, \n",
    "    dataloader, \n",
    "    criterion, \n",
    "    device,\n",
    "    output_dir='results/', \n",
    "    output_filename='test_predictions.csv',\n",
    "    output_dim=768\n",
    "):\n",
    "    model.eval()\n",
    "    dense_layer.eval()\n",
    "    total_loss = 0\n",
    "\n",
    "    # Create the output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Initialize metrics for binary classification\n",
    "    precision_metric = BinaryPrecision().to(device)\n",
    "    recall_metric = BinaryRecall().to(device)\n",
    "    f1_metric = BinaryF1Score().to(device)\n",
    "    accuracy_metric = BinaryAccuracy().to(device) \n",
    "\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    \n",
    "    # List to collect results for CSV\n",
    "    results = []\n",
    "    \n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imdbids, text_features, audio_features, video_features, targets in dataloader:\n",
    "            text_features, audio_features, video_features, targets = (\n",
    "                text_features.to(device),\n",
    "                audio_features.to(device),\n",
    "                video_features.to(device),\n",
    "                targets.to(device).view(-1)\n",
    "            )\n",
    "            \n",
    "            # Squeeze the audio features to remove the extra dimension\n",
    "            audio_features = audio_features.squeeze(1).to(device) \n",
    "            text_features = text_features.unsqueeze(1).to(device) \n",
    "\n",
    "            # Apply linear transformations to match dimensions\n",
    "            linear_transform_text = LinearTransformations(text_features.shape[-1], 768).to(device)    \n",
    "            text_features = linear_transform_text(text_features).to(device) \n",
    "            \n",
    "            audio_features = audio_features[:, -1, :].unsqueeze(1).to(device)   # Resulting shape: [batch_size, 1, 768]\n",
    "    \n",
    "            video_features = pad_features(video_features).to(device)   # Shape will be [batch_size, max_pad, 768]\n",
    "\n",
    "            transformed_features = {\n",
    "                'audio_features': audio_features,\n",
    "                'text_features': text_features,\n",
    "                'video_features': video_features\n",
    "            }\n",
    "\n",
    "            outputs = model(\n",
    "                modalityAlpha=transformed_features[modality_assignments['modalityAlpha']].to(device) ,  # Use the dictionary for modality assignment\n",
    "                modalityBeta=transformed_features[modality_assignments['modalityBeta']].to(device) ,\n",
    "                modalityGamma=transformed_features[modality_assignments['modalityGamma']].to(device) \n",
    "            )\n",
    "    \n",
    "            outputs = outputs.view(outputs.size(0), -1)  # Shape will be [batch_size, 153600]\n",
    "\n",
    "            # Pass the fused features through the dense layer\n",
    "            predictions = dense_layer(outputs).view(-1)\n",
    "                \n",
    "            # Compute loss\n",
    "            loss = criterion(predictions, targets)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # !!!Apply if BCEWithLogits or CustomLoss!!!\n",
    "            if not isBCELoss:\n",
    "                predictions = torch.sigmoid(predictions)\n",
    "\n",
    "            # Apply threshold to get binary predictions\n",
    "            preds = (predictions >= threshold).float()\n",
    "            \n",
    "            # Collect predictions and targets for the confusion matrix\n",
    "            all_predictions.extend(preds.cpu().numpy())\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "\n",
    "            # Collect results for each sample\n",
    "            for i in range(len(imdbids)):\n",
    "                results.append({\n",
    "                    'IMDBid': imdbids[i],\n",
    "                    'Raw Prediction': predictions[i].item(),\n",
    "                    'Binary Prediction': preds[i].item(),\n",
    "                    'Target': targets[i].item()\n",
    "                })\n",
    "            \n",
    "            # Update metrics for binary classification\n",
    "            precision_metric.update(preds.long(), targets.long())\n",
    "            recall_metric.update(preds.long(), targets.long())\n",
    "            f1_metric.update(preds.long(), targets.long())\n",
    "            accuracy_metric.update(preds.long(), targets.long()) \n",
    "\n",
    "     # Compute average precision, recall, F1 score, and accuracy\n",
    "    test_precision = precision_metric.compute().item()\n",
    "    test_recall = recall_metric.compute().item()\n",
    "    test_f1_score = f1_metric.compute().item()\n",
    "    test_accuracy = accuracy_metric.compute().item()\n",
    "    \n",
    "    # Generate confusion matrix\n",
    "    test_conf_matrix = confusion_matrix(all_targets, all_predictions)\n",
    "\n",
    "    test_average_loss = total_loss / len(dataloader)\n",
    "    \n",
    "    # Create DataFrame and save to CSV\n",
    "    results_df = pd.DataFrame(results)\n",
    "    output_filepath = os.path.join(output_dir, output_filename)\n",
    "    results_df.to_csv(output_filepath, index=False, header=True)\n",
    "\n",
    "    return test_average_loss, test_accuracy, test_precision, test_recall, test_f1_score, test_conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(parameters, lr=learning_rate):\n",
    "    # Create an optimizer, for example, Adam\n",
    "    return optim.Adam(parameters, lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(conf_matrix, class_names=['Negative', 'Positive']):\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False,\n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot training and validation loss\n",
    "def plot_losses(train_losses, val_losses):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_losses, label='Training Loss', color='blue', marker='o')\n",
    "    plt.plot(val_losses, label='Validation Loss', color='orange', marker='x')\n",
    "    plt.title('Training and Validation Loss over Epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1.73 GiB. GPU ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Ensure you have a dataloader that yields inputs and targets\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m train_average_loss, train_accuracy, train_precision, train_recall, train_f1_score \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdense_layer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdense_layer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_dim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m train_losses\u001b[38;5;241m.\u001b[39mappend(train_average_loss)  \u001b[38;5;66;03m# Store training loss\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, param \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mnamed_parameters():\n",
      "Cell \u001b[1;32mIn[36], line 80\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, dense_layer, dataloader, criterion, optimizer, device, output_dir, output_filename, output_dim)\u001b[0m\n\u001b[0;32m     78\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     79\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 80\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;66;03m# !!!Apply if BCEWithLogits or CustomLoss!!!\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m isBCELoss:\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\torch\\optim\\optimizer.py:391\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    386\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    387\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    388\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    389\u001b[0m             )\n\u001b[1;32m--> 391\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    394\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\torch\\optim\\optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\torch\\optim\\adam.py:159\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    156\u001b[0m     state_steps \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    157\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m--> 159\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_group\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    168\u001b[0m     adam(\n\u001b[0;32m    169\u001b[0m         params_with_grad,\n\u001b[0;32m    170\u001b[0m         grads,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    188\u001b[0m         found_inf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    189\u001b[0m     )\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\torch\\optim\\adam.py:115\u001b[0m, in \u001b[0;36mAdam._init_group\u001b[1;34m(self, group, params_with_grad, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps)\u001b[0m\n\u001b[0;32m    113\u001b[0m state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexp_avg\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros_like(p, memory_format\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mpreserve_format)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;66;03m# Exponential moving average of squared gradient values\u001b[39;00m\n\u001b[1;32m--> 115\u001b[0m state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexp_avg_sq\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreserve_format\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mamsgrad\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;66;03m# Maintains max of all exp. moving avg. of sq. grad. values\u001b[39;00m\n\u001b[0;32m    118\u001b[0m     state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_exp_avg_sq\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros_like(p, memory_format\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mpreserve_format)\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.73 GiB. GPU "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    torch.manual_seed(42)\n",
    "\n",
    "    # Initialize the SMCA model A\n",
    "    model = SMCAModel(768, 768, device).to(device)  # Dimension for d_out_kq and d_out_v\n",
    "\n",
    "    # Determine the output dimensions\n",
    "    output_dim = 768\n",
    "\n",
    "    # Own DenseLayer or FinalClassifier\n",
    "    if isFinalClassifier:\n",
    "        dense_layer = FinalClassifier(output_dim * max_pad).to(device) \n",
    "    else:\n",
    "        dense_layer = DenseLayer(output_dim).to(device)\n",
    "\n",
    "    optimizer = get_optimizer(list(dense_layer.parameters()), learning_rate)\n",
    "\n",
    "    # Lists to store the training and validation losses\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"-\" * 40)\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "\n",
    "        # Ensure you have a dataloader that yields inputs and targets\n",
    "        train_average_loss, train_accuracy, train_precision, train_recall, train_f1_score = train_model(model=model, dense_layer=dense_layer, dataloader=train_dataloader, criterion=criterion, optimizer=optimizer, device=device, output_dim=output_dim)\n",
    "        train_losses.append(train_average_loss)  # Store training loss\n",
    "\n",
    "        print(\"-\" * 20, \"Train\", \"-\" * 20)\n",
    "        print(f\"Train Accuracy: {train_accuracy:.4f}\")\n",
    "        print(f\"Train Precision: {train_precision:.4f}\")\n",
    "        print(f\"Train Recall: {train_recall:.4f}\")\n",
    "        print(f\"Train F1 Score: {train_f1_score:.4f}\")\n",
    "        print(f\"Train Loss: {train_average_loss:.4f}\")\n",
    "    \n",
    "        \n",
    "        for name, param in model.named_parameters():\n",
    "            if param.grad is None:\n",
    "                print(\"After train: model:\", \"No gradient for:\", name)\n",
    "        \n",
    "        for name, param in dense_layer.named_parameters():\n",
    "            if param.grad is None:\n",
    "                print(\"After train: classifier:\", \"No gradient for:\", name)\n",
    "\n",
    "        # Validate step\n",
    "        val_average_loss, val_accuracy, val_precision, val_recall, val_f1_score, val_conf_matrix = evaluate_model(model=model, dense_layer=dense_layer, dataloader=val_dataloader, criterion=criterion, device=device, output_dim=output_dim)\n",
    "        val_losses.append(val_average_loss)  # Store validation loss\n",
    "        \n",
    "        print(\"-\" * 20, \"Eval\", \"-\" * 20)\n",
    "        print(f\"Eval Accuracy: {val_accuracy:.4f}\")\n",
    "        print(f\"Eval Precision: {val_precision:.4f}\")\n",
    "        print(f\"Eval Recall: {val_recall:.4f}\")\n",
    "        print(f\"Eval F1 Score: {val_f1_score:.4f}\")\n",
    "        print(f\"Eval Loss: {val_average_loss:.4f}\")\n",
    "        \n",
    "        # print(f\"Training Loss: {train_average_loss:.4f}, Validation Loss: {eval_average_loss:.4f}\")\n",
    "\n",
    "    # Testing the model\n",
    "    print(\"-\" * 40)\n",
    "    print(\"Testing the model on the test set...\")\n",
    "    test_average_loss, test_accuracy, test_precision, test_recall, test_f1_score, test_conf_matrix = test_model(model=model, dense_layer=dense_layer, dataloader=test_dataloader, criterion=criterion, device=device, output_dim=output_dim)\n",
    "    \n",
    "    print(\"-\" * 20, \"Test\", \"-\" * 20)\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "    print(f\"Test Precision: {test_precision:.4f}\")\n",
    "    print(f\"Test Recall: {test_recall:.4f}\")\n",
    "    print(f\"Test F1 Score: {test_f1_score:.4f}\")\n",
    "    print(f\"Test Loss: {test_average_loss:.4f}\")\n",
    "    \n",
    "    # Summary of metrics\n",
    "    metrics_summary = {\n",
    "        \"Train Accuracy\": [train_accuracy],\n",
    "        \"Validation Accuracy\": [val_accuracy],\n",
    "        \"Test Accuracy\": [test_accuracy],\n",
    "        \"Train Precision\": [train_precision],\n",
    "        \"Validation Precision\": [val_precision],\n",
    "        \"Test Precision\": [test_precision],\n",
    "        \"Train Recall\": [train_recall],\n",
    "        \"Validation Recall\": [val_recall],\n",
    "        \"Test Recall\": [test_recall],\n",
    "        \"Train F1 Score\": [train_f1_score],\n",
    "        \"Validation F1 Score\": [val_f1_score],\n",
    "        \"Test F1 Score\": [test_f1_score],\n",
    "        \"Train Loss\": [train_average_loss],\n",
    "        \"Validation Loss\": [val_average_loss],\n",
    "        \"Test Loss\": [test_average_loss]\n",
    "    }\n",
    "    \n",
    "    # Create DataFrame\n",
    "    metrics_df = pd.DataFrame(metrics_summary)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(test_conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the table\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train DataLoader: Total Samples = 927, Number of Batches = 29\n",
      "Validation DataLoader: Total Samples = 199, Number of Batches = 13\n",
      "Test DataLoader: Total Samples = 199, Number of Batches = 13\n"
     ]
    }
   ],
   "source": [
    "# Print sizes of each DataLoader (FOR CHECKING)\n",
    "print_dataloader_sizes(train_dataloader, \"Train\")\n",
    "print_dataloader_sizes(val_dataloader, \"Validation\")\n",
    "print_dataloader_sizes(test_dataloader, \"Test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IMDBid</th>\n",
       "      <th>Raw Prediction</th>\n",
       "      <th>Binary Prediction</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt5292624</td>\n",
       "      <td>0.736823</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt1996264</td>\n",
       "      <td>0.887823</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0110157</td>\n",
       "      <td>0.004624</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0259711</td>\n",
       "      <td>0.053281</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0758774</td>\n",
       "      <td>0.267036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1055</th>\n",
       "      <td>tt0328538</td>\n",
       "      <td>0.276780</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056</th>\n",
       "      <td>tt0082367</td>\n",
       "      <td>0.817319</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1057</th>\n",
       "      <td>tt1366344</td>\n",
       "      <td>0.562297</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1058</th>\n",
       "      <td>tt7634968</td>\n",
       "      <td>0.684587</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1059</th>\n",
       "      <td>tt0396271</td>\n",
       "      <td>0.019819</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1060 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         IMDBid  Raw Prediction  Binary Prediction  Target\n",
       "0     tt5292624        0.736823                1.0     1.0\n",
       "1     tt1996264        0.887823                1.0     1.0\n",
       "2     tt0110157        0.004624                0.0     0.0\n",
       "3     tt0259711        0.053281                0.0     0.0\n",
       "4     tt0758774        0.267036                0.0     0.0\n",
       "...         ...             ...                ...     ...\n",
       "1055  tt0328538        0.276780                0.0     0.0\n",
       "1056  tt0082367        0.817319                1.0     1.0\n",
       "1057  tt1366344        0.562297                1.0     1.0\n",
       "1058  tt7634968        0.684587                1.0     1.0\n",
       "1059  tt0396271        0.019819                0.0     0.0\n",
       "\n",
       "[1060 rows x 4 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('results/train_predictions.csv')\n",
    "train_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IMDBid</th>\n",
       "      <th>Raw Prediction</th>\n",
       "      <th>Binary Prediction</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0300620</td>\n",
       "      <td>0.044776</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0117333</td>\n",
       "      <td>0.024099</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0101414</td>\n",
       "      <td>0.006145</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt2557490</td>\n",
       "      <td>0.274969</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt5918982</td>\n",
       "      <td>0.888453</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>tt1331064</td>\n",
       "      <td>0.025512</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>tt0483607</td>\n",
       "      <td>0.097614</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>tt0102288</td>\n",
       "      <td>0.020075</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>tt0448564</td>\n",
       "      <td>0.004929</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>tt0364751</td>\n",
       "      <td>0.364645</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>265 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        IMDBid  Raw Prediction  Binary Prediction  Target\n",
       "0    tt0300620        0.044776                0.0     0.0\n",
       "1    tt0117333        0.024099                0.0     0.0\n",
       "2    tt0101414        0.006145                0.0     0.0\n",
       "3    tt2557490        0.274969                0.0     1.0\n",
       "4    tt5918982        0.888453                1.0     1.0\n",
       "..         ...             ...                ...     ...\n",
       "260  tt1331064        0.025512                0.0     0.0\n",
       "261  tt0483607        0.097614                0.0     0.0\n",
       "262  tt0102288        0.020075                0.0     0.0\n",
       "263  tt0448564        0.004929                0.0     0.0\n",
       "264  tt0364751        0.364645                0.0     0.0\n",
       "\n",
       "[265 rows x 4 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df = pd.read_csv('results/val_predictions.csv')\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IMDBid</th>\n",
       "      <th>Raw Prediction</th>\n",
       "      <th>Binary Prediction</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt6261048</td>\n",
       "      <td>0.091161</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt1596346</td>\n",
       "      <td>0.197217</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0809504</td>\n",
       "      <td>0.114703</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0472562</td>\n",
       "      <td>0.336006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0134033</td>\n",
       "      <td>0.053163</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>tt0770806</td>\n",
       "      <td>0.683721</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>tt0311941</td>\n",
       "      <td>0.239854</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>tt2072233</td>\n",
       "      <td>0.834122</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>tt1178640</td>\n",
       "      <td>0.190963</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>tt0985025</td>\n",
       "      <td>0.596859</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        IMDBid  Raw Prediction  Binary Prediction  Target\n",
       "0    tt6261048        0.091161                0.0     0.0\n",
       "1    tt1596346        0.197217                0.0     0.0\n",
       "2    tt0809504        0.114703                0.0     0.0\n",
       "3    tt0472562        0.336006                0.0     0.0\n",
       "4    tt0134033        0.053163                0.0     0.0\n",
       "..         ...             ...                ...     ...\n",
       "194  tt0770806        0.683721                1.0     0.0\n",
       "195  tt0311941        0.239854                0.0     1.0\n",
       "196  tt2072233        0.834122                1.0     1.0\n",
       "197  tt1178640        0.190963                0.0     0.0\n",
       "198  tt0985025        0.596859                1.0     1.0\n",
       "\n",
       "[199 rows x 4 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('results/test_predictions.csv')\n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_average_loss_curves(train_losses_folds, val_losses_folds):\n",
    "    # Transpose folds to calculate averages per epoch\n",
    "    num_epochs = len(train_losses_folds[0])\n",
    "    avg_train_losses = [np.mean([fold[epoch] for fold in train_losses_folds]) for epoch in range(num_epochs)]\n",
    "    avg_val_losses = [np.mean([fold[epoch] for fold in val_losses_folds]) for epoch in range(num_epochs)]\n",
    "\n",
    "    epochs = range(1, num_epochs + 1)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(epochs, avg_train_losses, label='Average Training Loss', color='blue', marker='o')\n",
    "    plt.plot(epochs, avg_val_losses, label='Average Validation Loss', color='orange', marker='o')\n",
    "    \n",
    "    plt.title('Average Training and Validation Loss Across Folds')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cross_validate_model(\n",
    "    dataset, \n",
    "    model_class, \n",
    "    dense_layer_class, \n",
    "    num_folds, \n",
    "    num_epochs, \n",
    "    output_dim,\n",
    "    criterion,\n",
    "    learning_rate,\n",
    "    train_batch_size,\n",
    "    val_batch_size,\n",
    "    output_file,\n",
    "    device=None\n",
    "):\n",
    "    # Set device configuration\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Device: {device}\")\n",
    "    \n",
    "    # Initialize the KFold splitter\n",
    "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    # lists to store metrics for each fold\n",
    "    fold_losses = []\n",
    "    fold_accuracies = []\n",
    "    fold_precisions = []\n",
    "    fold_recalls = []\n",
    "    fold_f1_scores = []\n",
    "    \n",
    "    # Lists to store metrics and losses for each fold\n",
    "    train_losses_folds = []  # List of lists: train_losses_folds[fold][epoch]\n",
    "    val_losses_folds = []    # List of lists: val_losses_folds[fold][epoch]\n",
    "    \n",
    "    # Perform K-Fold Cross-Validation\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(dataset)):\n",
    "        print(\"-\" * 60)\n",
    "        print(f\"------------------------- Fold {fold + 1 }/{num_folds} -------------------------\")\n",
    "\n",
    "        # Create data loaders for the train and validation sets\n",
    "        train_sampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
    "        val_sampler = torch.utils.data.SubsetRandomSampler(val_idx)\n",
    "        \n",
    "        train_dataloader = torch.utils.data.DataLoader(dataset, batch_size=train_batch_size, sampler=train_sampler, collate_fn=collate_fn)\n",
    "        val_dataloader = torch.utils.data.DataLoader(dataset, batch_size=val_batch_size, sampler=val_sampler, collate_fn=collate_fn)\n",
    "        \n",
    "        print_dataloader_sizes(train_dataloader, \"Train\")\n",
    "        print_dataloader_sizes(val_dataloader, \"Validation\")\n",
    "        \n",
    "        # Initialize the model, dense layer, criterion, and optimizer for each fold\n",
    "        model = model_class(768, 768, device).to(device)\n",
    "        \n",
    "        dense_layer = dense_layer_class(output_dim * max_pad).to(device)\n",
    "        criterion = criterion.to(device)\n",
    "        optimizer = get_optimizer(list(dense_layer.parameters()), learning_rate)\n",
    "\n",
    "        # Initialize lists to track losses for this fold\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        \n",
    "        # Use tqdm for progress bar\n",
    "        epoch_progress = tqdm(range(num_epochs), desc=f\"Fold {fold + 1}/{num_folds} Training\", leave=True)\n",
    "\n",
    "\n",
    "        # Training loop for each fold\n",
    "        for epoch in epoch_progress:\n",
    "            print(f\"------------------------- Epoch {epoch + 1}/{num_epochs} -------------------------\")\n",
    "            \n",
    "            # Train and evaluate the model on the training and validation sets\n",
    "            train_average_loss, train_accuracy, train_precision, train_recall, train_f1_score = train_model(model=model, dense_layer=dense_layer, dataloader=train_dataloader, criterion=criterion, optimizer=optimizer, device=device)\n",
    "            val_average_loss, val_accuracy, val_precision, val_recall, val_f1_score, val_conf_matrix = evaluate_model(model=model, dense_layer=dense_layer, dataloader=val_dataloader, criterion=criterion, device=device)\n",
    "            \n",
    "            # Track losses for this fold and epoch\n",
    "            train_losses.append(train_average_loss)\n",
    "            val_losses.append(val_average_loss)\n",
    "            \n",
    "            print(f\"\\nTrain Accuracy: {train_accuracy:.4f}\")\n",
    "            print(f\"Train Precision: {train_precision:.4f}\")\n",
    "            print(f\"Train Recall: {train_recall:.4f}\")\n",
    "            print(f\"Train F1 Score: {train_f1_score:.4f}\")\n",
    "            print(f\"Train Loss: {train_average_loss:.4f}\")\n",
    "            \n",
    "            print(f\"\\nEval Accuracy: {val_accuracy:.4f}\")\n",
    "            print(f\"Eval Precision: {val_precision:.4f}\")\n",
    "            print(f\"Eval Recall: {val_recall:.4f}\")\n",
    "            print(f\"Eval F1 Score: {val_f1_score:.4f}\")\n",
    "            print(f\"Eval Loss: {val_average_loss:.4f}\")\n",
    "\n",
    "            \n",
    "            # Update tqdm progress bar description\n",
    "            epoch_progress.set_postfix({\n",
    "                \"Train Loss\": f\"{train_average_loss:.4f}\",\n",
    "                \"Val Loss\": f\"{val_average_loss:.4f}\",\n",
    "                \"Train F1\": f\"{train_f1_score:.4f}\",\n",
    "                \"Val F1\": f\"{val_f1_score:.4f}\",\n",
    "            })\n",
    "        \n",
    "        # Store losses for the fold\n",
    "        train_losses_folds.append(train_losses)\n",
    "        val_losses_folds.append(val_losses)\n",
    "           \n",
    "        # Store the validation metrics for this fold\n",
    "        fold_losses.append(val_average_loss)\n",
    "        fold_accuracies.append(val_accuracy)\n",
    "        fold_precisions.append(val_precision)\n",
    "        fold_recalls.append(val_recall)\n",
    "        fold_f1_scores.append(val_f1_score)\n",
    "\n",
    "    # Calculate the average metrics across all folds\n",
    "    avg_loss = np.mean(fold_losses)\n",
    "    avg_accuracy = np.mean(fold_accuracies)\n",
    "    avg_precision = np.mean(fold_precisions)\n",
    "    avg_recall = np.mean(fold_recalls)\n",
    "    avg_f1_score = np.mean(fold_f1_scores)\n",
    "\n",
    "    print(\"-\" * 50)\n",
    "    print(\"\\nK-Fold Cross-Validation Results:\")\n",
    "    print(f\"Average Loss: {avg_loss:.4f}\")\n",
    "    print(f\"Average Accuracy: {avg_accuracy:.4f}\")\n",
    "    print(f\"Average Precision: {avg_precision:.4f}\")\n",
    "    print(f\"Average Recall: {avg_recall:.4f}\")\n",
    "    print(f\"Average F1 Score: {avg_f1_score:.4f}\")\n",
    "\n",
    "    # Plot average loss curves across folds\n",
    "    plot_average_loss_curves(train_losses_folds, val_losses_folds)\n",
    "\n",
    "    \n",
    "    results_dict = {\"Metrics\": [\"Loss\", \"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"]}\n",
    "    for i in range(num_folds):\n",
    "        results_dict[f\"Fold {i + 1}\"] = [fold_losses[i], fold_accuracies[i], fold_precisions[i], fold_recalls[i], fold_f1_scores[i]]\n",
    "    results_dict[\"Average\"] = [avg_loss, avg_accuracy, avg_precision, avg_recall, avg_f1_score]\n",
    "\n",
    "    # Create DataFrame\n",
    "    results_df = pd.DataFrame(results_dict)\n",
    "    \n",
    "    # Ensure the output directory exists\n",
    "    output_dir = os.path.dirname(output_file)\n",
    "    if output_dir and not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)  \n",
    "        \n",
    "    # Save results to .csv\n",
    "    results_df.to_csv(output_file, index=False)\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "------------------------------------------------------------\n",
      "------------------------- Fold 1/5 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1/5 Training:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------- Epoch 1/10 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1/5 Training:  10%|         | 1/10 [01:52<16:55, 112.85s/it, Train Loss=0.5010, Val Loss=0.5048, Train F1=0.3592, Val F1=0.5469]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Train --------------------\n",
      "Train Accuracy: 0.7745\n",
      "Train Precision: 0.6204\n",
      "Train Recall: 0.2528\n",
      "Train F1 Score: 0.3592\n",
      "Train Loss: 0.5010\n",
      "-------------------- Eval --------------------\n",
      "Eval Accuracy: 0.7811\n",
      "Eval Precision: 0.5932\n",
      "Eval Recall: 0.5072\n",
      "Eval F1 Score: 0.5469\n",
      "Eval Loss: 0.5048\n",
      "------------------------- Epoch 2/10 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1/5 Training:  20%|        | 2/10 [03:51<15:30, 116.36s/it, Train Loss=0.3945, Val Loss=0.5417, Train F1=0.6316, Val F1=0.5730]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Train --------------------\n",
      "Train Accuracy: 0.8415\n",
      "Train Precision: 0.7539\n",
      "Train Recall: 0.5434\n",
      "Train F1 Score: 0.6316\n",
      "Train Loss: 0.3945\n",
      "-------------------- Eval --------------------\n",
      "Eval Accuracy: 0.7132\n",
      "Eval Precision: 0.4679\n",
      "Eval Recall: 0.7391\n",
      "Eval F1 Score: 0.5730\n",
      "Eval Loss: 0.5417\n",
      "------------------------- Epoch 3/10 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1/5 Training:  30%|       | 3/10 [05:43<13:21, 114.44s/it, Train Loss=0.3727, Val Loss=0.4341, Train F1=0.6500, Val F1=0.5902]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Train --------------------\n",
      "Train Accuracy: 0.8415\n",
      "Train Precision: 0.7256\n",
      "Train Recall: 0.5887\n",
      "Train F1 Score: 0.6500\n",
      "Train Loss: 0.3727\n",
      "-------------------- Eval --------------------\n",
      "Eval Accuracy: 0.8113\n",
      "Eval Precision: 0.6792\n",
      "Eval Recall: 0.5217\n",
      "Eval F1 Score: 0.5902\n",
      "Eval Loss: 0.4341\n",
      "------------------------- Epoch 4/10 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1/5 Training:  40%|      | 4/10 [07:40<11:31, 115.26s/it, Train Loss=0.3386, Val Loss=0.4141, Train F1=0.6837, Val F1=0.6230]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Train --------------------\n",
      "Train Accuracy: 0.8594\n",
      "Train Precision: 0.7816\n",
      "Train Recall: 0.6075\n",
      "Train F1 Score: 0.6837\n",
      "Train Loss: 0.3386\n",
      "-------------------- Eval --------------------\n",
      "Eval Accuracy: 0.8264\n",
      "Eval Precision: 0.7170\n",
      "Eval Recall: 0.5507\n",
      "Eval F1 Score: 0.6230\n",
      "Eval Loss: 0.4141\n",
      "------------------------- Epoch 5/10 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1/5 Training:  50%|     | 5/10 [09:33<09:32, 114.56s/it, Train Loss=0.3198, Val Loss=0.4583, Train F1=0.6857, Val F1=0.5812]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Train --------------------\n",
      "Train Accuracy: 0.8547\n",
      "Train Precision: 0.7467\n",
      "Train Recall: 0.6340\n",
      "Train F1 Score: 0.6857\n",
      "Train Loss: 0.3198\n",
      "-------------------- Eval --------------------\n",
      "Eval Accuracy: 0.8151\n",
      "Eval Precision: 0.7083\n",
      "Eval Recall: 0.4928\n",
      "Eval F1 Score: 0.5812\n",
      "Eval Loss: 0.4583\n",
      "------------------------- Epoch 6/10 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1/5 Training:  60%|    | 6/10 [11:28<07:38, 114.66s/it, Train Loss=0.2985, Val Loss=0.4322, Train F1=0.7307, Val F1=0.5763]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Train --------------------\n",
      "Train Accuracy: 0.8783\n",
      "Train Precision: 0.8178\n",
      "Train Recall: 0.6604\n",
      "Train F1 Score: 0.7307\n",
      "Train Loss: 0.2985\n",
      "-------------------- Eval --------------------\n",
      "Eval Accuracy: 0.8113\n",
      "Eval Precision: 0.6939\n",
      "Eval Recall: 0.4928\n",
      "Eval F1 Score: 0.5763\n",
      "Eval Loss: 0.4322\n",
      "------------------------- Epoch 7/10 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1/5 Training:  70%|   | 7/10 [13:25<05:45, 115.26s/it, Train Loss=0.2806, Val Loss=0.4932, Train F1=0.7280, Val F1=0.4255]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Train --------------------\n",
      "Train Accuracy: 0.8774\n",
      "Train Precision: 0.8169\n",
      "Train Recall: 0.6566\n",
      "Train F1 Score: 0.7280\n",
      "Train Loss: 0.2806\n",
      "-------------------- Eval --------------------\n",
      "Eval Accuracy: 0.7962\n",
      "Eval Precision: 0.8000\n",
      "Eval Recall: 0.2899\n",
      "Eval F1 Score: 0.4255\n",
      "Eval Loss: 0.4932\n",
      "------------------------- Epoch 8/10 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1/5 Training:  80%|  | 8/10 [15:12<03:45, 112.69s/it, Train Loss=0.2939, Val Loss=0.4291, Train F1=0.7360, Val F1=0.5984]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Train --------------------\n",
      "Train Accuracy: 0.8755\n",
      "Train Precision: 0.7830\n",
      "Train Recall: 0.6943\n",
      "Train F1 Score: 0.7360\n",
      "Train Loss: 0.2939\n",
      "-------------------- Eval --------------------\n",
      "Eval Accuracy: 0.8075\n",
      "Eval Precision: 0.6552\n",
      "Eval Recall: 0.5507\n",
      "Eval F1 Score: 0.5984\n",
      "Eval Loss: 0.4291\n",
      "------------------------- Epoch 9/10 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1/5 Training:  90%| | 9/10 [17:00<01:51, 111.37s/it, Train Loss=0.2896, Val Loss=0.4220, Train F1=0.7455, Val F1=0.6528]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Train --------------------\n",
      "Train Accuracy: 0.8802\n",
      "Train Precision: 0.7949\n",
      "Train Recall: 0.7019\n",
      "Train F1 Score: 0.7455\n",
      "Train Loss: 0.2896\n",
      "-------------------- Eval --------------------\n",
      "Eval Accuracy: 0.8113\n",
      "Eval Precision: 0.6267\n",
      "Eval Recall: 0.6812\n",
      "Eval F1 Score: 0.6528\n",
      "Eval Loss: 0.4220\n",
      "------------------------- Epoch 10/10 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1/5 Training: 100%|| 10/10 [18:50<00:00, 113.05s/it, Train Loss=0.3150, Val Loss=0.4174, Train F1=0.6949, Val F1=0.6129]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Train --------------------\n",
      "Train Accuracy: 0.8575\n",
      "Train Precision: 0.7478\n",
      "Train Recall: 0.6491\n",
      "Train F1 Score: 0.6949\n",
      "Train Loss: 0.3150\n",
      "-------------------- Eval --------------------\n",
      "Eval Accuracy: 0.8189\n",
      "Eval Precision: 0.6909\n",
      "Eval Recall: 0.5507\n",
      "Eval F1 Score: 0.6129\n",
      "Eval Loss: 0.4174\n",
      "------------------------------------------------------------\n",
      "------------------------- Fold 2/5 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 2/5 Training:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------- Epoch 1/10 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2/5 Training:  10%|         | 1/10 [02:10<19:38, 130.93s/it, Train Loss=0.5270, Val Loss=0.4679, Train F1=0.3541, Val F1=0.5039]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Train --------------------\n",
      "Train Accuracy: 0.7557\n",
      "Train Precision: 0.5420\n",
      "Train Recall: 0.2630\n",
      "Train F1 Score: 0.3541\n",
      "Train Loss: 0.5270\n",
      "-------------------- Eval --------------------\n",
      "Eval Accuracy: 0.7623\n",
      "Eval Precision: 0.5079\n",
      "Eval Recall: 0.5000\n",
      "Eval F1 Score: 0.5039\n",
      "Eval Loss: 0.4679\n",
      "------------------------- Epoch 2/10 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2/5 Training:  20%|        | 2/10 [04:15<16:56, 127.03s/it, Train Loss=0.4098, Val Loss=0.4206, Train F1=0.5541, Val F1=0.5714]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Train --------------------\n",
      "Train Accuracy: 0.8057\n",
      "Train Precision: 0.6667\n",
      "Train Recall: 0.4741\n",
      "Train F1 Score: 0.5541\n",
      "Train Loss: 0.4098\n",
      "-------------------- Eval --------------------\n",
      "Eval Accuracy: 0.8075\n",
      "Eval Precision: 0.6182\n",
      "Eval Recall: 0.5312\n",
      "Eval F1 Score: 0.5714\n",
      "Eval Loss: 0.4206\n",
      "------------------------- Epoch 3/10 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2/5 Training:  30%|       | 3/10 [06:29<15:13, 130.43s/it, Train Loss=0.3686, Val Loss=0.4039, Train F1=0.7008, Val F1=0.5664]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Train --------------------\n",
      "Train Accuracy: 0.8623\n",
      "Train Precision: 0.7844\n",
      "Train Recall: 0.6333\n",
      "Train F1 Score: 0.7008\n",
      "Train Loss: 0.3686\n",
      "-------------------- Eval --------------------\n",
      "Eval Accuracy: 0.8151\n",
      "Eval Precision: 0.6531\n",
      "Eval Recall: 0.5000\n",
      "Eval F1 Score: 0.5664\n",
      "Eval Loss: 0.4039\n",
      "------------------------- Epoch 4/10 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2/5 Training:  40%|      | 4/10 [08:51<13:28, 134.80s/it, Train Loss=0.3628, Val Loss=0.5523, Train F1=0.6517, Val F1=0.3117]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Train --------------------\n",
      "Train Accuracy: 0.8387\n",
      "Train Precision: 0.7240\n",
      "Train Recall: 0.5926\n",
      "Train F1 Score: 0.6517\n",
      "Train Loss: 0.3628\n",
      "-------------------- Eval --------------------\n",
      "Eval Accuracy: 0.8000\n",
      "Eval Precision: 0.9231\n",
      "Eval Recall: 0.1875\n",
      "Eval F1 Score: 0.3117\n",
      "Eval Loss: 0.5523\n",
      "------------------------- Epoch 5/10 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2/5 Training:  50%|     | 5/10 [11:06<11:14, 134.97s/it, Train Loss=0.4007, Val Loss=0.4013, Train F1=0.6074, Val F1=0.6429]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Train --------------------\n",
      "Train Accuracy: 0.8292\n",
      "Train Precision: 0.7330\n",
      "Train Recall: 0.5185\n",
      "Train F1 Score: 0.6074\n",
      "Train Loss: 0.4007\n",
      "-------------------- Eval --------------------\n",
      "Eval Accuracy: 0.8491\n",
      "Eval Precision: 0.7500\n",
      "Eval Recall: 0.5625\n",
      "Eval F1 Score: 0.6429\n",
      "Eval Loss: 0.4013\n",
      "------------------------- Epoch 6/10 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2/5 Training:  60%|    | 6/10 [13:19<08:56, 134.15s/it, Train Loss=0.3116, Val Loss=0.4154, Train F1=0.7202, Val F1=0.5769]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Train --------------------\n",
      "Train Accuracy: 0.8651\n",
      "Train Precision: 0.7635\n",
      "Train Recall: 0.6815\n",
      "Train F1 Score: 0.7202\n",
      "Train Loss: 0.3116\n",
      "-------------------- Eval --------------------\n",
      "Eval Accuracy: 0.8340\n",
      "Eval Precision: 0.7500\n",
      "Eval Recall: 0.4688\n",
      "Eval F1 Score: 0.5769\n",
      "Eval Loss: 0.4154\n",
      "------------------------- Epoch 7/10 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2/5 Training:  70%|   | 7/10 [15:31<06:41, 133.75s/it, Train Loss=0.3113, Val Loss=0.3714, Train F1=0.7232, Val F1=0.5946]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Train --------------------\n",
      "Train Accuracy: 0.8708\n",
      "Train Precision: 0.7956\n",
      "Train Recall: 0.6630\n",
      "Train F1 Score: 0.7232\n",
      "Train Loss: 0.3113\n",
      "-------------------- Eval --------------------\n",
      "Eval Accuracy: 0.8302\n",
      "Eval Precision: 0.7021\n",
      "Eval Recall: 0.5156\n",
      "Eval F1 Score: 0.5946\n",
      "Eval Loss: 0.3714\n",
      "------------------------- Epoch 8/10 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2/5 Training:  80%|  | 8/10 [17:44<04:26, 133.39s/it, Train Loss=0.3138, Val Loss=0.4078, Train F1=0.6960, Val F1=0.6861]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Train --------------------\n",
      "Train Accuracy: 0.8632\n",
      "Train Precision: 0.8019\n",
      "Train Recall: 0.6148\n",
      "Train F1 Score: 0.6960\n",
      "Train Loss: 0.3138\n",
      "-------------------- Eval --------------------\n",
      "Eval Accuracy: 0.8377\n",
      "Eval Precision: 0.6438\n",
      "Eval Recall: 0.7344\n",
      "Eval F1 Score: 0.6861\n",
      "Eval Loss: 0.4078\n",
      "------------------------- Epoch 9/10 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2/5 Training:  90%| | 9/10 [19:57<02:13, 133.24s/it, Train Loss=0.3351, Val Loss=0.4025, Train F1=0.6758, Val F1=0.6667]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Train --------------------\n",
      "Train Accuracy: 0.8443\n",
      "Train Precision: 0.7197\n",
      "Train Recall: 0.6370\n",
      "Train F1 Score: 0.6758\n",
      "Train Loss: 0.3351\n",
      "-------------------- Eval --------------------\n",
      "Eval Accuracy: 0.8377\n",
      "Eval Precision: 0.6615\n",
      "Eval Recall: 0.6719\n",
      "Eval F1 Score: 0.6667\n",
      "Eval Loss: 0.4025\n",
      "------------------------- Epoch 10/10 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2/5 Training: 100%|| 10/10 [22:12<00:00, 133.30s/it, Train Loss=0.2786, Val Loss=0.3682, Train F1=0.7570, Val F1=0.6552]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Train --------------------\n",
      "Train Accuracy: 0.8849\n",
      "Train Precision: 0.8190\n",
      "Train Recall: 0.7037\n",
      "Train F1 Score: 0.7570\n",
      "Train Loss: 0.2786\n",
      "-------------------- Eval --------------------\n",
      "Eval Accuracy: 0.8491\n",
      "Eval Precision: 0.7308\n",
      "Eval Recall: 0.5938\n",
      "Eval F1 Score: 0.6552\n",
      "Eval Loss: 0.3682\n",
      "------------------------------------------------------------\n",
      "------------------------- Fold 3/5 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 3/5 Training:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------- Epoch 1/10 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3/5 Training:  10%|         | 1/10 [02:43<24:32, 163.66s/it, Train Loss=0.5015, Val Loss=0.4770, Train F1=0.2992, Val F1=0.4167]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Train --------------------\n",
      "Train Accuracy: 0.7613\n",
      "Train Precision: 0.5243\n",
      "Train Recall: 0.2093\n",
      "Train F1 Score: 0.2992\n",
      "Train Loss: 0.5015\n",
      "-------------------- Eval --------------------\n",
      "Eval Accuracy: 0.7887\n",
      "Eval Precision: 1.0000\n",
      "Eval Recall: 0.2632\n",
      "Eval F1 Score: 0.4167\n",
      "Eval Loss: 0.4770\n",
      "------------------------- Epoch 2/10 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3/5 Training:  20%|        | 2/10 [05:15<20:52, 156.58s/it, Train Loss=0.4299, Val Loss=0.4562, Train F1=0.5307, Val F1=0.4167]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Train --------------------\n",
      "Train Accuracy: 0.8198\n",
      "Train Precision: 0.7248\n",
      "Train Recall: 0.4186\n",
      "Train F1 Score: 0.5307\n",
      "Train Loss: 0.4299\n",
      "-------------------- Eval --------------------\n",
      "Eval Accuracy: 0.7887\n",
      "Eval Precision: 1.0000\n",
      "Eval Recall: 0.2632\n",
      "Eval F1 Score: 0.4167\n",
      "Eval Loss: 0.4562\n",
      "------------------------- Epoch 3/10 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3/5 Training:  30%|       | 3/10 [07:48<18:06, 155.16s/it, Train Loss=0.3523, Val Loss=0.3860, Train F1=0.6175, Val F1=0.7114]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Train --------------------\n",
      "Train Accuracy: 0.8434\n",
      "Train Precision: 0.7614\n",
      "Train Recall: 0.5194\n",
      "Train F1 Score: 0.6175\n",
      "Train Loss: 0.3523\n",
      "-------------------- Eval --------------------\n",
      "Eval Accuracy: 0.8377\n",
      "Eval Precision: 0.7260\n",
      "Eval Recall: 0.6974\n",
      "Eval F1 Score: 0.7114\n",
      "Eval Loss: 0.3860\n",
      "------------------------- Epoch 4/10 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3/5 Training:  40%|      | 4/10 [10:14<15:07, 151.26s/it, Train Loss=0.3581, Val Loss=0.3664, Train F1=0.6611, Val F1=0.7059]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Train --------------------\n",
      "Train Accuracy: 0.8472\n",
      "Train Precision: 0.7182\n",
      "Train Recall: 0.6124\n",
      "Train F1 Score: 0.6611\n",
      "Train Loss: 0.3581\n",
      "-------------------- Eval --------------------\n",
      "Eval Accuracy: 0.8302\n",
      "Eval Precision: 0.7013\n",
      "Eval Recall: 0.7105\n",
      "Eval F1 Score: 0.7059\n",
      "Eval Loss: 0.3664\n",
      "------------------------- Epoch 5/10 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3/5 Training:  50%|     | 5/10 [12:39<12:26, 149.29s/it, Train Loss=0.3520, Val Loss=0.3451, Train F1=0.6637, Val F1=0.7606]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Train --------------------\n",
      "Train Accuracy: 0.8575\n",
      "Train Precision: 0.7801\n",
      "Train Recall: 0.5775\n",
      "Train F1 Score: 0.6637\n",
      "Train Loss: 0.3520\n",
      "-------------------- Eval --------------------\n",
      "Eval Accuracy: 0.8717\n",
      "Eval Precision: 0.8182\n",
      "Eval Recall: 0.7105\n",
      "Eval F1 Score: 0.7606\n",
      "Eval Loss: 0.3451\n",
      "------------------------- Epoch 6/10 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3/5 Training:  60%|    | 6/10 [15:09<09:58, 149.54s/it, Train Loss=0.3398, Val Loss=0.3827, Train F1=0.6623, Val F1=0.7273]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Train --------------------\n",
      "Train Accuracy: 0.8557\n",
      "Train Precision: 0.7692\n",
      "Train Recall: 0.5814\n",
      "Train F1 Score: 0.6623\n",
      "Train Loss: 0.3398\n",
      "-------------------- Eval --------------------\n",
      "Eval Accuracy: 0.8302\n",
      "Eval Precision: 0.6742\n",
      "Eval Recall: 0.7895\n",
      "Eval F1 Score: 0.7273\n",
      "Eval Loss: 0.3827\n",
      "------------------------- Epoch 7/10 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3/5 Training:  70%|   | 7/10 [17:43<07:32, 150.73s/it, Train Loss=0.3309, Val Loss=0.3885, Train F1=0.6837, Val F1=0.7317]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Train --------------------\n",
      "Train Accuracy: 0.8594\n",
      "Train Precision: 0.7559\n",
      "Train Recall: 0.6240\n",
      "Train F1 Score: 0.6837\n",
      "Train Loss: 0.3309\n",
      "-------------------- Eval --------------------\n",
      "Eval Accuracy: 0.8340\n",
      "Eval Precision: 0.6818\n",
      "Eval Recall: 0.7895\n",
      "Eval F1 Score: 0.7317\n",
      "Eval Loss: 0.3885\n",
      "------------------------- Epoch 8/10 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3/5 Training:  80%|  | 8/10 [20:12<05:00, 150.47s/it, Train Loss=0.3083, Val Loss=0.3715, Train F1=0.7113, Val F1=0.6942]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Train --------------------\n",
      "Train Accuracy: 0.8698\n",
      "Train Precision: 0.7727\n",
      "Train Recall: 0.6589\n",
      "Train F1 Score: 0.7113\n",
      "Train Loss: 0.3083\n",
      "-------------------- Eval --------------------\n",
      "Eval Accuracy: 0.8604\n",
      "Eval Precision: 0.9333\n",
      "Eval Recall: 0.5526\n",
      "Eval F1 Score: 0.6942\n",
      "Eval Loss: 0.3715\n",
      "------------------------- Epoch 9/10 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3/5 Training:  90%| | 9/10 [22:38<02:29, 149.08s/it, Train Loss=0.2689, Val Loss=0.3694, Train F1=0.7401, Val F1=0.7132]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Train --------------------\n",
      "Train Accuracy: 0.8821\n",
      "Train Precision: 0.7982\n",
      "Train Recall: 0.6899\n",
      "Train F1 Score: 0.7401\n",
      "Train Loss: 0.2689\n",
      "-------------------- Eval --------------------\n",
      "Eval Accuracy: 0.8604\n",
      "Eval Precision: 0.8679\n",
      "Eval Recall: 0.6053\n",
      "Eval F1 Score: 0.7132\n",
      "Eval Loss: 0.3694\n",
      "------------------------- Epoch 10/10 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3/5 Training: 100%|| 10/10 [25:06<00:00, 150.68s/it, Train Loss=0.2922, Val Loss=0.3429, Train F1=0.7104, Val F1=0.7660]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Train --------------------\n",
      "Train Accuracy: 0.8708\n",
      "Train Precision: 0.7814\n",
      "Train Recall: 0.6512\n",
      "Train F1 Score: 0.7104\n",
      "Train Loss: 0.2922\n",
      "-------------------- Eval --------------------\n",
      "Eval Accuracy: 0.8755\n",
      "Eval Precision: 0.8308\n",
      "Eval Recall: 0.7105\n",
      "Eval F1 Score: 0.7660\n",
      "Eval Loss: 0.3429\n",
      "------------------------------------------------------------\n",
      "------------------------- Fold 4/5 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 4/5 Training:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------- Epoch 1/10 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4/5 Training:  10%|         | 1/10 [01:58<17:43, 118.22s/it, Train Loss=0.5255, Val Loss=0.3974, Train F1=0.2507, Val F1=0.6606]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Train --------------------\n",
      "Train Accuracy: 0.7462\n",
      "Train Precision: 0.5172\n",
      "Train Recall: 0.1654\n",
      "Train F1 Score: 0.2507\n",
      "Train Loss: 0.5255\n",
      "-------------------- Eval --------------------\n",
      "Eval Accuracy: 0.8604\n",
      "Eval Precision: 0.7660\n",
      "Eval Recall: 0.5806\n",
      "Eval F1 Score: 0.6606\n",
      "Eval Loss: 0.3974\n",
      "------------------------- Epoch 2/10 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4/5 Training:  20%|        | 2/10 [04:01<16:08, 121.03s/it, Train Loss=0.4097, Val Loss=0.3639, Train F1=0.5644, Val F1=0.6122]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Train --------------------\n",
      "Train Accuracy: 0.8151\n",
      "Train Precision: 0.7135\n",
      "Train Recall: 0.4669\n",
      "Train F1 Score: 0.5644\n",
      "Train Loss: 0.4097\n",
      "-------------------- Eval --------------------\n",
      "Eval Accuracy: 0.8566\n",
      "Eval Precision: 0.8333\n",
      "Eval Recall: 0.4839\n",
      "Eval F1 Score: 0.6122\n",
      "Eval Loss: 0.3639\n",
      "------------------------- Epoch 3/10 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4/5 Training:  30%|       | 3/10 [05:55<13:45, 117.86s/it, Train Loss=0.3807, Val Loss=0.4317, Train F1=0.6039, Val F1=0.6944]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Train --------------------\n",
      "Train Accuracy: 0.8292\n",
      "Train Precision: 0.7459\n",
      "Train Recall: 0.5074\n",
      "Train F1 Score: 0.6039\n",
      "Train Loss: 0.3807\n",
      "-------------------- Eval --------------------\n",
      "Eval Accuracy: 0.8340\n",
      "Eval Precision: 0.6098\n",
      "Eval Recall: 0.8065\n",
      "Eval F1 Score: 0.6944\n",
      "Eval Loss: 0.4317\n",
      "------------------------- Epoch 4/10 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4/5 Training:  40%|      | 4/10 [07:49<11:37, 116.27s/it, Train Loss=0.3724, Val Loss=0.3623, Train F1=0.6531, Val F1=0.5833]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Train --------------------\n",
      "Train Accuracy: 0.8387\n",
      "Train Precision: 0.7285\n",
      "Train Recall: 0.5919\n",
      "Train F1 Score: 0.6531\n",
      "Train Loss: 0.3724\n",
      "-------------------- Eval --------------------\n",
      "Eval Accuracy: 0.8491\n",
      "Eval Precision: 0.8235\n",
      "Eval Recall: 0.4516\n",
      "Eval F1 Score: 0.5833\n",
      "Eval Loss: 0.3623\n",
      "------------------------- Epoch 5/10 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4/5 Training:  50%|     | 5/10 [09:42<09:36, 115.35s/it, Train Loss=0.3483, Val Loss=0.4525, Train F1=0.6667, Val F1=0.6410]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Train --------------------\n",
      "Train Accuracy: 0.8500\n",
      "Train Precision: 0.7756\n",
      "Train Recall: 0.5846\n",
      "Train F1 Score: 0.6667\n",
      "Train Loss: 0.3483\n",
      "-------------------- Eval --------------------\n",
      "Eval Accuracy: 0.7887\n",
      "Eval Precision: 0.5319\n",
      "Eval Recall: 0.8065\n",
      "Eval F1 Score: 0.6410\n",
      "Eval Loss: 0.4525\n",
      "------------------------- Epoch 6/10 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4/5 Training:  60%|    | 6/10 [11:36<07:39, 114.91s/it, Train Loss=0.3341, Val Loss=0.3431, Train F1=0.6992, Val F1=0.6263]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Train --------------------\n",
      "Train Accuracy: 0.8547\n",
      "Train Precision: 0.7458\n",
      "Train Recall: 0.6581\n",
      "Train F1 Score: 0.6992\n",
      "Train Loss: 0.3341\n",
      "-------------------- Eval --------------------\n",
      "Eval Accuracy: 0.8604\n",
      "Eval Precision: 0.8378\n",
      "Eval Recall: 0.5000\n",
      "Eval F1 Score: 0.6263\n",
      "Eval Loss: 0.3431\n",
      "------------------------- Epoch 7/10 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4/5 Training:  70%|   | 7/10 [13:30<05:43, 114.53s/it, Train Loss=0.3234, Val Loss=0.3473, Train F1=0.7097, Val F1=0.7154]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Train --------------------\n",
      "Train Accuracy: 0.8642\n",
      "Train Precision: 0.7857\n",
      "Train Recall: 0.6471\n",
      "Train F1 Score: 0.7097\n",
      "Train Loss: 0.3234\n",
      "-------------------- Eval --------------------\n",
      "Eval Accuracy: 0.8679\n",
      "Eval Precision: 0.7213\n",
      "Eval Recall: 0.7097\n",
      "Eval F1 Score: 0.7154\n",
      "Eval Loss: 0.3473\n",
      "------------------------- Epoch 8/10 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4/5 Training:  80%|  | 8/10 [15:23<03:48, 114.13s/it, Train Loss=0.2952, Val Loss=0.3432, Train F1=0.7751, Val F1=0.7111]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Train --------------------\n",
      "Train Accuracy: 0.8943\n",
      "Train Precision: 0.8540\n",
      "Train Recall: 0.7096\n",
      "Train F1 Score: 0.7751\n",
      "Train Loss: 0.2952\n",
      "-------------------- Eval --------------------\n",
      "Eval Accuracy: 0.8528\n",
      "Eval Precision: 0.6575\n",
      "Eval Recall: 0.7742\n",
      "Eval F1 Score: 0.7111\n",
      "Eval Loss: 0.3432\n",
      "------------------------- Epoch 9/10 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4/5 Training:  90%| | 9/10 [17:17<01:53, 113.99s/it, Train Loss=0.3024, Val Loss=0.3346, Train F1=0.7413, Val F1=0.6471]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Train --------------------\n",
      "Train Accuracy: 0.8736\n",
      "Train Precision: 0.7805\n",
      "Train Recall: 0.7059\n",
      "Train F1 Score: 0.7413\n",
      "Train Loss: 0.3024\n",
      "-------------------- Eval --------------------\n",
      "Eval Accuracy: 0.8642\n",
      "Eval Precision: 0.8250\n",
      "Eval Recall: 0.5323\n",
      "Eval F1 Score: 0.6471\n",
      "Eval Loss: 0.3346\n",
      "------------------------- Epoch 10/10 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4/5 Training: 100%|| 10/10 [19:10<00:00, 115.09s/it, Train Loss=0.3144, Val Loss=0.3625, Train F1=0.7349, Val F1=0.7000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Train --------------------\n",
      "Train Accuracy: 0.8755\n",
      "Train Precision: 0.8097\n",
      "Train Recall: 0.6728\n",
      "Train F1 Score: 0.7349\n",
      "Train Loss: 0.3144\n",
      "-------------------- Eval --------------------\n",
      "Eval Accuracy: 0.8642\n",
      "Eval Precision: 0.7241\n",
      "Eval Recall: 0.6774\n",
      "Eval F1 Score: 0.7000\n",
      "Eval Loss: 0.3625\n",
      "------------------------------------------------------------\n",
      "------------------------- Fold 5/5 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 5/5 Training:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------- Epoch 1/10 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 5/5 Training:  10%|         | 1/10 [02:27<22:11, 147.99s/it, Train Loss=0.4904, Val Loss=0.3775, Train F1=0.3931, Val F1=0.5161]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Train --------------------\n",
      "Train Accuracy: 0.7670\n",
      "Train Precision: 0.5882\n",
      "Train Recall: 0.2952\n",
      "Train F1 Score: 0.3931\n",
      "Train Loss: 0.4904\n",
      "-------------------- Eval --------------------\n",
      "Eval Accuracy: 0.8302\n",
      "Eval Precision: 0.8000\n",
      "Eval Recall: 0.3810\n",
      "Eval F1 Score: 0.5161\n",
      "Eval Loss: 0.3775\n",
      "------------------------- Epoch 2/10 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 5/5 Training:  20%|        | 2/10 [05:09<20:49, 156.16s/it, Train Loss=0.4450, Val Loss=0.3709, Train F1=0.5746, Val F1=0.5918]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Train --------------------\n",
      "Train Accuracy: 0.8170\n",
      "Train Precision: 0.7081\n",
      "Train Recall: 0.4834\n",
      "Train F1 Score: 0.5746\n",
      "Train Loss: 0.4450\n",
      "-------------------- Eval --------------------\n",
      "Eval Accuracy: 0.8491\n",
      "Eval Precision: 0.8286\n",
      "Eval Recall: 0.4603\n",
      "Eval F1 Score: 0.5918\n",
      "Eval Loss: 0.3709\n",
      "------------------------- Epoch 3/10 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 5/5 Training:  30%|       | 3/10 [07:44<18:07, 155.34s/it, Train Loss=0.4024, Val Loss=0.3240, Train F1=0.6173, Val F1=0.6186]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Train --------------------\n",
      "Train Accuracy: 0.8245\n",
      "Train Precision: 0.6977\n",
      "Train Recall: 0.5535\n",
      "Train F1 Score: 0.6173\n",
      "Train Loss: 0.4024\n",
      "-------------------- Eval --------------------\n",
      "Eval Accuracy: 0.8604\n",
      "Eval Precision: 0.8824\n",
      "Eval Recall: 0.4762\n",
      "Eval F1 Score: 0.6186\n",
      "Eval Loss: 0.3240\n",
      "------------------------- Epoch 4/10 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 5/5 Training:  40%|      | 4/10 [10:09<15:08, 151.46s/it, Train Loss=0.4040, Val Loss=0.3561, Train F1=0.6481, Val F1=0.4889]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Train --------------------\n",
      "Train Accuracy: 0.8330\n",
      "Train Precision: 0.7026\n",
      "Train Recall: 0.6015\n",
      "Train F1 Score: 0.6481\n",
      "Train Loss: 0.4040\n",
      "-------------------- Eval --------------------\n",
      "Eval Accuracy: 0.8264\n",
      "Eval Precision: 0.8148\n",
      "Eval Recall: 0.3492\n",
      "Eval F1 Score: 0.4889\n",
      "Eval Loss: 0.3561\n",
      "------------------------- Epoch 5/10 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 5/5 Training:  50%|     | 5/10 [12:37<12:30, 150.02s/it, Train Loss=0.3815, Val Loss=0.3837, Train F1=0.6356, Val F1=0.6370]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Train --------------------\n",
      "Train Accuracy: 0.8302\n",
      "Train Precision: 0.7040\n",
      "Train Recall: 0.5793\n",
      "Train F1 Score: 0.6356\n",
      "Train Loss: 0.3815\n",
      "-------------------- Eval --------------------\n",
      "Eval Accuracy: 0.8151\n",
      "Eval Precision: 0.5972\n",
      "Eval Recall: 0.6825\n",
      "Eval F1 Score: 0.6370\n",
      "Eval Loss: 0.3837\n",
      "------------------------- Epoch 6/10 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 5/5 Training:  60%|    | 6/10 [15:02<09:54, 148.56s/it, Train Loss=0.3494, Val Loss=0.3417, Train F1=0.6625, Val F1=0.7119]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Train --------------------\n",
      "Train Accuracy: 0.8472\n",
      "Train Precision: 0.7608\n",
      "Train Recall: 0.5867\n",
      "Train F1 Score: 0.6625\n",
      "Train Loss: 0.3494\n",
      "-------------------- Eval --------------------\n",
      "Eval Accuracy: 0.8717\n",
      "Eval Precision: 0.7636\n",
      "Eval Recall: 0.6667\n",
      "Eval F1 Score: 0.7119\n",
      "Eval Loss: 0.3417\n",
      "------------------------- Epoch 7/10 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 5/5 Training:  70%|   | 7/10 [17:30<07:24, 148.17s/it, Train Loss=0.3220, Val Loss=0.3554, Train F1=0.7080, Val F1=0.6917]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Train --------------------\n",
      "Train Accuracy: 0.8623\n",
      "Train Precision: 0.7729\n",
      "Train Recall: 0.6531\n",
      "Train F1 Score: 0.7080\n",
      "Train Loss: 0.3220\n",
      "-------------------- Eval --------------------\n",
      "Eval Accuracy: 0.8453\n",
      "Eval Precision: 0.6571\n",
      "Eval Recall: 0.7302\n",
      "Eval F1 Score: 0.6917\n",
      "Eval Loss: 0.3554\n",
      "------------------------- Epoch 8/10 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 5/5 Training:  80%|  | 8/10 [19:56<04:54, 147.41s/it, Train Loss=0.3275, Val Loss=0.3219, Train F1=0.6894, Val F1=0.6667]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Train --------------------\n",
      "Train Accuracy: 0.8538\n",
      "Train Precision: 0.7544\n",
      "Train Recall: 0.6347\n",
      "Train F1 Score: 0.6894\n",
      "Train Loss: 0.3275\n",
      "-------------------- Eval --------------------\n",
      "Eval Accuracy: 0.8528\n",
      "Eval Precision: 0.7222\n",
      "Eval Recall: 0.6190\n",
      "Eval F1 Score: 0.6667\n",
      "Eval Loss: 0.3219\n",
      "------------------------- Epoch 9/10 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 5/5 Training:  90%| | 9/10 [22:24<02:27, 147.61s/it, Train Loss=0.3148, Val Loss=0.3714, Train F1=0.7265, Val F1=0.6519]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Train --------------------\n",
      "Train Accuracy: 0.8708\n",
      "Train Precision: 0.7913\n",
      "Train Recall: 0.6716\n",
      "Train F1 Score: 0.7265\n",
      "Train Loss: 0.3148\n",
      "-------------------- Eval --------------------\n",
      "Eval Accuracy: 0.8226\n",
      "Eval Precision: 0.6111\n",
      "Eval Recall: 0.6984\n",
      "Eval F1 Score: 0.6519\n",
      "Eval Loss: 0.3714\n",
      "------------------------- Epoch 10/10 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 5/5 Training: 100%|| 10/10 [24:50<00:00, 149.08s/it, Train Loss=0.2903, Val Loss=0.3163, Train F1=0.7381, Val F1=0.6949]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Train --------------------\n",
      "Train Accuracy: 0.8755\n",
      "Train Precision: 0.7983\n",
      "Train Recall: 0.6863\n",
      "Train F1 Score: 0.7381\n",
      "Train Loss: 0.2903\n",
      "-------------------- Eval --------------------\n",
      "Eval Accuracy: 0.8642\n",
      "Eval Precision: 0.7455\n",
      "Eval Recall: 0.6508\n",
      "Eval F1 Score: 0.6949\n",
      "Eval Loss: 0.3163\n",
      "--------------------------------------------------\n",
      "\n",
      "K-Fold Cross-Validation Results:\n",
      "Average Loss: 0.3615\n",
      "Average Accuracy: 0.8543\n",
      "Average Precision: 0.7444\n",
      "Average Recall: 0.6366\n",
      "Average F1 Score: 0.6858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1YAAAIjCAYAAAAAxIqtAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAACvDUlEQVR4nOzdd3xN9x/H8dfNXpIYEUGIvVftGXtvWlQVVUqrqOre9FetLqpatGq0FDVbq2KPKmq2Zqkt9ogIss7vjyOXKwkRSW7G+/l4nEfuPfeMz7k54X7u9/v9fC2GYRiIiIiIiIhIsjnYOwAREREREZGMTomViIiIiIjII1JiJSIiIiIi8oiUWImIiIiIiDwiJVYiIiIiIiKPSImViIiIiIjII1JiJSIiIiIi8oiUWImIiIiIiDwiJVYiIiIiIiKPSImViEgaO3r0KBaLhSlTpiRrf4vFwvvvv5+iMaU3vXr1IigoKM3P+/7772OxWGzWBQUF0atXrwfuO2XKFCwWC0ePHk2xeB71XhFJzMPcW/b6exTJaJRYiWRR33zzDRaLherVq9s7lHQj7kP1g5b69evbO9Qs79y5czg5OfHUU08lus21a9dwd3enY8eOaRhZ8syYMYPRo0fbOwwbvXr1wsvLy95hPJRq1aphsVj49ttv7R1KqohLhhJaatSoYe/wRLI8J3sHICL2MX36dIKCgtiyZQuHDh2iaNGi9g7J7jp27GjzPoSHhzNgwAA6dOhg8+Hc39//kc5TsGBBbty4gbOzc7L2v3HjBk5OWfuf79y5c9OkSRMWLlxIREQEHh4e8baZN28eN2/evG/ylRQHDhzAwSF1v4ecMWMG//zzD0OGDLFZ/6j3Slby77//snXrVoKCgpg+fToDBgywd0ipplu3brRs2dJmnZ+fn52iEZE4Wft/ZpEs6siRI/zxxx/MmzeP5557junTp/Pee++laQyxsbFERkbi5uaWpue9n/Lly1O+fHnr8wsXLjBgwADKly9/3w/nN2/exMXFJckfvi0WyyNdd3p6z+ype/fuLFu2jF9//ZWuXbvGe33GjBn4+PjQqlWrRzqPq6vrI+3/KB71XslKfvrpJ3Lnzs3nn39O586dOXr0aIp1X7t+/Tqenp4pcqyU8Nhjjz3yFwYikvLUFVAkC5o+fTrZs2enVatWdO7cmenTp1tfi4qKIkeOHPTu3TvefmFhYbi5uTFs2DDrulu3bvHee+9RtGhRXF1dCQwM5NVXX+XWrVs2+1osFgYOHMj06dMpU6YMrq6uLFu2DIDPPvuMWrVqkTNnTtzd3alcuTJz5syJd/4bN24waNAgcuXKRbZs2Wjbti2nTp1KcMzRqVOneOaZZ/D398fV1ZUyZcrwww8/PMrbBsCaNWuwWCzMnDmTt99+m3z58uHh4UFYWBiXLl1i2LBhlCtXDi8vL7y9vWnRogW7du2yOUZCYxviul2dOnWK9u3b4+XlhZ+fH8OGDSMmJibee3n39cZ1YTx06BC9evXC19cXHx8fevfuTURERLLfw3tFRkby7rvvUrlyZXx8fPD09KRu3bqsXr06wev77LPPmDhxIkWKFMHV1ZWqVauydevWeMddsGABZcuWxc3NjbJlyzJ//vz7xhGnQ4cOeHp6MmPGjHivnTt3jpUrV9K5c2dcXV1Zv349jz/+OAUKFLDepy+99BI3btx44HkSGmO1Z88eGjZsiLu7O/nz5+fDDz8kNjY23r4LFy6kVatW5M2bF1dXV4oUKcKIESNsfqf169dn8eLFHDt2zNqtKy4hSGwczKpVq6hbty6enp74+vrSrl079u3bZ7PNw9wXj+KXX36hcuXKuLu7kytXLp566ilOnTpls82ZM2fo3bs3+fPnx9XVlYCAANq1a2czHu2vv/6iWbNm5MqVC3d3dwoVKsQzzzyT5DhmzJhB586dad26NT4+PgneFwCbN2+mZcuWZM+eHU9PT8qXL8+YMWOsr8f9LR4+fJiWLVuSLVs2unfvDpgJ1ssvv0xgYCCurq6UKFGCzz77DMMwbM4REhJCnTp18PX1xcvLixIlSvDmm2/abDN27FjKlCmDh4cH2bNnp0qVKonG/LD+++8/Hn/8cXLkyIGHhwc1atRg8eLFSdo3qX+PM2fOpHLlymTLlg1vb2/KlStn8z6KZEVqsRLJgqZPn07Hjh1xcXGhW7dufPvtt2zdupWqVavi7OxMhw4dmDdvHhMmTMDFxcW634IFC7h165a1dSA2Npa2bduyYcMG+vXrR6lSpfj777/58ssvOXjwIAsWLLA576pVq5g9ezYDBw4kV65c1g+PY8aMoW3btnTv3p3IyEhmzpzJ448/zqJFi2xaG3r16sXs2bPp0aMHNWrUYO3atQm2Rpw9e5YaNWpYkzk/Pz+WLl1Knz59CAsLi9fdKjlGjBiBi4sLw4YN49atW7i4uLB3714WLFjA448/TqFChTh79iwTJkwgODiYvXv3kjdv3vseMyYmhmbNmlG9enU+++wzVqxYweeff06RIkWS1K3piSeeoFChQowcOZLt27fz/fffkzt3bj755BPrNkl9DxMSFhbG999/T7du3ejbty/Xrl1j0qRJNGvWjC1btlCxYkWb7WfMmMG1a9d47rnnsFgsjBo1io4dO/Lff/9Zu7YtX76cTp06Ubp0aUaOHMnFixetH8AfxNPTk3bt2jFnzhwuXbpEjhw5rK/NmjWLmJgY6wfiX375hYiICAYMGEDOnDnZsmULY8eO5eTJk/zyyy9Juv44Z86coUGDBkRHR/P666/j6enJxIkTcXd3j7ftlClT8PLyYujQoXh5ebFq1SreffddwsLC+PTTTwF46623uHr1KidPnuTLL78EuO/YphUrVtCiRQsKFy7M+++/z40bNxg7diy1a9dm+/bt8VppknJfJNeUKVPo3bs3VatWZeTIkZw9e5YxY8awceNGduzYga+vLwCdOnViz549vPjiiwQFBXHu3DlCQkI4fvy49XnTpk3x8/Pj9ddfx9fXl6NHjzJv3rwkxbF582YOHTrE5MmTcXFxoWPHjkyfPj1eMhMSEkLr1q0JCAhg8ODB5MmTh3379rFo0SIGDx5s3S46OppmzZpRp04dPvvsMzw8PDAMg7Zt27J69Wr69OlDxYoV+f3333nllVc4deqU9Xe3Z88eWrduTfny5Rk+fDiurq4cOnSIjRs3Wo//3XffMWjQIDp37szgwYO5efMmu3fvZvPmzTz55JMPvN6IiAguXLhgs87HxwdnZ2fOnj1LrVq1iIiIYNCgQeTMmZOpU6fStm1b5syZQ4cOHRI9blL/HkNCQujWrRuNGjWy3kf79u1j48aNNu+jSJZjiEiW8tdffxmAERISYhiGYcTGxhr58+c3Bg8ebN3m999/NwDjt99+s9m3ZcuWRuHCha3Pf/zxR8PBwcFYv369zXbjx483AGPjxo3WdYDh4OBg7NmzJ15MERERNs8jIyONsmXLGg0bNrSu27ZtmwEYQ4YMsdm2V69eBmC899571nV9+vQxAgICjAsXLths27VrV8PHxyfe+RJz/vz5eMdevXq1ARiFCxeOd5ybN28aMTExNuuOHDliuLq6GsOHD7dZBxiTJ0+2ruvZs6cB2GxnGIZRqVIlo3Llyjbr7o3pvffeMwDjmWeesdmuQ4cORs6cOa3PH+Y9TEh0dLRx69Ytm3WXL182/P39bc4dd305c+Y0Ll26ZF2/cOHCePdVxYoVjYCAAOPKlSvWdcuXLzcAo2DBgveNxzAMY/HixQZgTJgwwWZ9jRo1jHz58ll/Hwn9zkeOHGlYLBbj2LFj1nVx7+XdChYsaPTs2dP6fMiQIQZgbN682bru3Llzho+PjwEYR44csa5P6LzPPfec4eHhYdy8edO6rlWrVgleb0L3SsWKFY3cuXMbFy9etK7btWuX4eDgYDz99NPxruVB90VievbsaXh6eib6emRkpJE7d26jbNmyxo0bN6zrFy1aZADGu+++axiGeY8AxqeffprosebPn28AxtatWx8YV0IGDhxoBAYGGrGxsYZh3LmHduzYYd0mOjraKFSokFGwYEHj8uXLNvvH7WcYd/4WX3/9dZttFixYYADGhx9+aLO+c+fOhsViMQ4dOmQYhmF8+eWXBmCcP38+0XjbtWtnlClT5qGvM+5+SGhZvXq1YRh37s+7/12+du2aUahQISMoKMj6N5HYvZWUv8fBgwcb3t7eRnR09ENfg0hmpq6AIlnM9OnT8ff3p0GDBoDZraxLly7MnDnT2j2pYcOG5MqVi1mzZln3u3z5MiEhIXTp0sW67pdffqFUqVKULFmSCxcuWJeGDRsCxOsiFhwcTOnSpePFdPc3/ZcvX+bq1avUrVuX7du3W9fHdRt8/vnnbfZ98cUXbZ4bhsHcuXNp06YNhmHYxNWsWTOuXr1qc9zk6tmzZ7wWCldXV+s4q5iYGC5evGjtBpTUc/bv39/med26dfnvv/+Sve/FixcJCwsDkv4eJsbR0dHaghkbG8ulS5eIjo6mSpUqCV5fly5dyJ49u008gPV6QkND2blzJz179sTHx8e6XZMmTRK8TxIS18pxdxeqI0eO8Oeff9KtWzfr7+Pu39X169e5cOECtWrVwjAMduzYkaRzxVmyZAk1atSgWrVq1nV+fn7W1rG73X3ea9euceHCBerWrUtERAT79+9/qPPCnfesV69eNi105cuXp0mTJixZsiTePg+6L5Lrr7/+4ty5czz//PM248BatWpFyZIlrV3P3N3dcXFxYc2aNVy+fDnBY8W1bC1atIioqKiHiiM6OppZs2bRpUsXa6n8hg0bkjt3bptuzjt27ODIkSMMGTLEer4495bYB+K1Ei9ZsgRHR0cGDRpks/7ll1/GMAyWLl1qcy0LFy5MsHto3DYnT55MsGtsUvTr14+QkBCbpUKFCtY4q1WrRp06dazbe3l50a9fP44ePcrevXsTPObD/D36+vpy/fp1QkJCkhW/SGalxEokC4mJiWHmzJk0aNCAI0eOcOjQIQ4dOkT16tU5e/YsK1euBMDJyYlOnTqxcOFC61ipefPmERUVZZNY/fvvv+zZswc/Pz+bpXjx4oA5zuVuhQoVSjCuRYsWUaNGDdzc3MiRIwd+fn58++23XL161brNsWPHcHBwiHeMe6sZnj9/nitXrjBx4sR4ccWNG7s3ruRI6FpiY2P58ssvKVasGK6uruTKlQs/Pz92795tcy2JcXNzi1fZK3v27Il+GL1XgQIF4u0LWPdP6nt4P1OnTqV8+fK4ubmRM2dO/Pz8WLx4cYLXl5R4AIoVKxZv3xIlSiQpHicnJ7p06cL69eut43rikqy7E53jx49bk5G48WvBwcEASfrd3O3YsWNJjnnPnj106NABHx8fvL298fPzsxYdeNjzxp07sXOVKlWKCxcucP36dZv1D/o9JNf9YilZsqT1dVdXVz755BOWLl2Kv78/9erVY9SoUZw5c8a6fXBwMJ06deKDDz4gV65ctGvXjsmTJ8cbq5mQ5cuXc/78eapVq2b9N+3IkSM0aNCAn3/+2ZrcHD58GICyZcs+8JhOTk7xur8dO3aMvHnzki1bNpv1pUqVsnk/unTpQu3atXn22Wfx9/ena9euzJ492ybJeu211/Dy8qJatWoUK1aMF154waar4IMUK1aMxo0b2yxxv9djx44len/cHee9Hubv8fnnn6d48eK0aNGC/Pnz88wzz1i/uBHJypRYiWQhq1atIjQ0lJkzZ1KsWDHr8sQTTwDYfLvbtWtXrl27Zv0Wdvbs2ZQsWdL6rSiYiUS5cuXifXMat9zbMpLQGJT169fTtm1b3Nzc+Oabb1iyZAkhISE8+eST8QaEJ0Xch5ennnoq0bhq16790Me9V0LX8tFHHzF06FDq1avHTz/9xO+//05ISAhlypRJ9Jvruzk6Oj5STIntn5z3MSE//fQTvXr1okiRIkyaNIlly5YREhJCw4YNE7y+1I4nzlNPPUVsbCw///wzAD///DOlS5e2jvmKiYmhSZMmLF68mNdee40FCxYQEhJiLQiRlN9Ncly5coXg4GB27drF8OHD+e233wgJCbGOSUmt894rrX4P9zNkyBAOHjzIyJEjcXNz45133qFUqVLW1kKLxcKcOXPYtGkTAwcOtBafqVy5MuHh4fc9dty/W0888YTNv2uzZs3i1KlTrF279qHjvbv1+WG5u7uzbt06VqxYQY8ePdi9ezddunShSZMm1l4BpUqV4sCBA8ycOZM6deowd+5c6tSpk+bVWZMrd+7c7Ny5k19//dU67qxFixb07NnT3qGJ2JWKV4hkIdOnTyd37tyMGzcu3mvz5s1j/vz5jB8/Hnd3d+rVq0dAQACzZs2iTp06rFq1irfeestmnyJFirBr1y4aNWqUYFeapJg7dy5ubm78/vvvNmWtJ0+ebLNdwYIFiY2N5ciRIzbfqB46dMhmOz8/P7Jly0ZMTAyNGzdOVkzJNWfOHBo0aMCkSZNs1l+5coVcuXKlaSwJSep7mJg5c+ZQuHBh5s2bZ/P7Tu6HwYIFCwJmy+e9Dhw4kOTjVK9enSJFijBjxgyaNGnCnj17+N///md9/e+//+bgwYNMnTqVp59+2ro+ud2YChYsmKSY16xZw8WLF5k3bx716tWzrj9y5Ei8fZP69xP3niX0/uzfv59cuXKlWVnwu2OJ6/4b58CBA9bX4xQpUoSXX36Zl19+mX///ZeKFSvy+eef89NPP1m3qVGjBjVq1OB///sfM2bMoHv37sycOZNnn302wRiuX7/OwoUL6dKlC507d473+qBBg5g+fToNGjSgSJEiAPzzzz/J+rehYMGCrFixgmvXrtm0WsV16bz7eh0cHGjUqBGNGjXiiy++4KOPPuKtt95i9erV1nN7enrSpUsXunTpQmRkJB07duR///sfb7zxxiOV2C9YsGCi98e9cd67HyT979HFxYU2bdrQpk0bYmNjef7555kwYQLvvPOO5kWULEstViJZxI0bN5g3bx6tW7emc+fO8ZaBAwdy7do1fv31V8D8YNC5c2d+++03fvzxR6Kjo226AYL5DfGpU6f47rvvEjzfvV2SEuLo6IjFYrEpP3306NF4FQWbNWsGwDfffGOzfuzYsfGO16lTJ+bOncs///wT73znz59/YEzJ5ejoGK8V4JdffolXetpekvoeJiau5ePua9y8eTObNm1KVjwBAQFUrFiRqVOn2nSLCwkJSXQcSGK6d+/Ojh07eO+997BYLDaV1RKK2zCMZJeGbtmyJX/++Sdbtmyxrjt//rxNi29i542MjIz3/oP5ITspXQPvfs+uXLliXf/PP/+wfPnyeJPGpqYqVaqQO3duxo8fb9Nlb+nSpezbt89abTIiIoKbN2/a7FukSBGyZctm3e/y5cvx/nbiWhzv1x1w/vz5XL9+nRdeeCHBf9dat27N3LlzuXXrFo899hiFChVi9OjRNu8dJK31rmXLlsTExPD111/brP/yyy+xWCy0aNECgEuXLsXb995ruXjxos3rLi4ulC5dGsMwHnqMWUJxbtmyxebv8vr160ycOJGgoKBExy8+zN/jvfE7ODhY5wBMSvdNkcxKLVYiWcSvv/7KtWvXaNu2bYKv16hRAz8/P6ZPn25NoLp06cLYsWN57733KFeunLWPfpwePXowe/Zs+vfvz+rVq6lduzYxMTHs37+f2bNn8/vvv1OlSpX7xtWqVSu++OILmjdvzpNPPsm5c+cYN24cRYsWZffu3dbtKleuTKdOnRg9ejQXL160lgo/ePAgYPuN/8cff8zq1aupXr06ffv2pXTp0ly6dInt27ezYsWKBD/4pITWrVszfPhwevfuTa1atfj777+ZPn06hQsXTpXzPayHeQ8T0rp1a+bNm0eHDh1o1aoVR44cYfz48ZQuXfqB3bUSM3LkSFq1akWdOnV45plnuHTpknV+n4c55lNPPcXw4cNZuHAhtWvXtik5XrJkSYoUKcKwYcM4deoU3t7ezJ07N9ljjF599VV+/PFHmjdvzuDBg63l1gsWLGhzz9aqVYvs2bPTs2dPBg0ahMVi4ccff0zwQ3zlypWZNWsWQ4cOpWrVqnh5edGmTZsEz//pp5/SokULatasSZ8+fazl1n18fB44F9nDioqK4sMPP4y3PkeOHDz//PN88skn9O7dm+DgYLp162Yttx4UFMRLL70EwMGDB2nUqBFPPPEEpUuXxsnJifnz53P27Fnr1A1Tp07lm2++oUOHDhQpUoRr167x3Xff4e3tfd9kcfr06eTMmZNatWol+Hrbtm357rvvWLx4MR07duTbb7+lTZs2VKxYkd69exMQEMD+/fvZs2cPv//++33fizZt2tCgQQPeeustjh49SoUKFVi+fDkLFy5kyJAh1hax4cOHs27dOlq1akXBggU5d+4c33zzDfnz57cWlGjatCl58uShdu3a+Pv7s2/fPr7++mtatWoVbwzXw3r99df5+eefadGiBYMGDSJHjhxMnTqVI0eOMHfu3Pt2cUzq3+Ozzz7LpUuXaNiwIfnz5+fYsWOMHTuWihUrxvt/QiRLSfM6hCJiF23atDHc3NyM69evJ7pNr169DGdnZ2uZ8tjYWCMwMDDBEsNxIiMjjU8++cQoU6aM4erqamTPnt2oXLmy8cEHHxhXr161bgcYL7zwQoLHmDRpklGsWDHD1dXVKFmypDF58uQEy15fv37deOGFF4wcOXIYXl5eRvv27Y0DBw4YgPHxxx/bbHv27FnjhRdeMAIDAw1nZ2cjT548RqNGjYyJEycm6f0yjPuXW//ll1/ibX/z5k3j5ZdfNgICAgx3d3ejdu3axqZNm4zg4GAjODjYul1i5dYTKm2d0Ptwb0xx29xb3nny5Mnxyn8/zHt4r9jYWOOjjz4yChYsaLi6uhqVKlUyFi1aZPTs2dOmFHPc9SVUXvve2A3DMObOnWuUKlXKcHV1NUqXLm3Mmzcv3jGTomrVqgZgfPPNN/Fe27t3r9G4cWPDy8vLyJUrl9G3b19j165d8X4PSSm3bhiGsXv3biM4ONhwc3Mz8uXLZ4wYMcKYNGlSvPd748aNRo0aNQx3d3cjb968xquvvmqdziCuPLZhGEZ4eLjx5JNPGr6+vjalrRO6VwzDMFasWGHUrl3bcHd3N7y9vY02bdoYe/futdnmYe6LhMSVHU9oKVKkiHW7WbNmGZUqVTJcXV2NHDlyGN27dzdOnjxpff3ChQvGCy+8YJQsWdLw9PQ0fHx8jOrVqxuzZ8+2brN9+3ajW7duRoECBQxXV1cjd+7cRuvWrY2//vor0fjOnj1rODk5GT169Eh0m4iICMPDw8Po0KGDdd2GDRuMJk2aGNmyZTM8PT2N8uXLG2PHjrW57sTKzF+7ds146aWXjLx58xrOzs5GsWLFjE8//dSmXPvKlSuNdu3aGXnz5jVcXFyMvHnzGt26dTMOHjxo3WbChAlGvXr1jJw5cxqurq5GkSJFjFdeecXm38yE3O9v626HDx82OnfubPj6+hpubm5GtWrVjEWLFiV4rHvvraT8Pc6ZM8do2rSpkTt3bsPFxcUoUKCA8dxzzxmhoaH3jUsks7MYRhqOXhURSWE7d+6kUqVK/PTTTwmWu5YH03soIiLy6DTGSkQyjBs3bsRbN3r0aBwcHGyKA0ji9B6KiIikDo2xEpEMY9SoUWzbto0GDRrg5OTE0qVLWbp0Kf369SMwMNDe4WUIeg9FRERSh7oCikiGERISwgcffMDevXsJDw+nQIEC9OjRg7feegsnJ31PlBR6D0VERFKHEisREREREZFHpDFWIiIiIiIij0iJlYiIiIiIyCNSh/oExMbGcvr0abJly/bACTNFRERERCTzMgyDa9eukTdv3vtOsq3EKgGnT59WdSwREREREbE6ceIE+fPnT/R1JVYJyJYtG2C+ed7e3naORpIjKiqK5cuX07RpU5ydne0djmQBuuckremek7Sk+03SWnq658LCwggMDLTmCIlRYpWAuO5/3t7eSqwyqKioKDw8PPD29rb7H6NkDbrnJK3pnpO0pPtN0lp6vOceNERIxStEREREREQekRIrERERERGRR6TESkRERERE5BFpjJWIiIhIBmMYBtHR0cTExKTJ+aKionBycuLmzZtpdk7J2tLynnN0dMTJyemRp1lSYiUiIiKSgURGRhIaGkpERESandMwDPLkycOJEyc0x6ekibS+5zw8PAgICMDFxSXZx1BiJSIiIpJBxMbGcuTIERwdHcmbNy8uLi5p8qEzNjaW8PBwvLy87jtBqkhKSat7zjAMIiMjOX/+PEeOHKFYsWLJPp8SKxEREZEMIjIyktjYWAIDA/Hw8Eiz88bGxhIZGYmbm5sSK0kTaXnPubu74+zszLFjx6znTA79ZYiIiIhkMEpuRFJWSvxN6a9SRERERETkESmxEhEREREReURKrERERESymJgYWLMGfv7Z/KkK6hnDmjVrsFgsXLlyJcn79OrVi/bt26daTHKHEisRERGRLGTePAgKggYN4MknzZ9BQeb61LZp0yYcHR1p1apV6p/MjqZMmYLFYrnvcvTo0Yc+bq1atQgNDcXHxyfJ+4wZM4YpU6Y89LkelhI4JVYiIiIiWca8edC5M5w8abv+1ClzfWonV5MmTeLFF19k3bp1nD59OlXPFTeJsj106dKF0NBQ61KzZk369u1rsy4wMNC6fWRkZJKO6+LiQp48eR6qxL6Pjw++vr4PewmSDEqs0jE104uIiMj9GAZcv560JSwMBg0y90noOACDB5vbJeV4CR3nfsLDw5k1axYDBgygVatWNq0oTz75JF26dLHZPioqily5cjFt2jTALL89cuRIChUqhLu7OxUqVGDOnDnW7eO6yS1dupTKlSvj6urKhg0bOHz4MO3atcPf3x8vLy+qVq3KihUrbM4VGhpKq1atcHd3p1ChQsyYMYOgoCBGjx5t3ebKlSs8++yz+Pn54e3tTcOGDdm1a1eC1+ru7k6ePHmsi4uLCx4eHtbnr7/+Op06deJ///sfefPmpUSJEgD8+OOPVKlShWzZspEnTx6efPJJzp07F+8a47oCTpkyBV9fX37//XdKlSqFl5cXzZs3JzQ01LrPvS1J9evXZ9CgQbz66qvkyJGDPHny8P7779vEv3//furUqYObmxulS5dmxYoVWCwWFixYkOD1JsXatWupVq0arq6uBAQE8Prrr9skvnPmzKFcuXK4u7uTM2dOmjZtyvXr163XXa1aNTw9PfH19aV27docO3Ys2bGkFiVW6ZQ9m+lFREQkY4iIAC+vpC0+PmbLVGIMw2zJ8vGJv6+3twP58/vi7e1gXRcR8XCxzp49m5IlS1KiRAmeeuopfvjhB4zb2Vn37t357bffCA8Pt27/+++/ExERQYcOHQAYOXIk06ZNY/z48ezZs4eXXnqJp556irVr19qc5/XXX+fjjz9m3759lC9fnvDwcFq2bMnKlSvZsWMHzZs3p02bNhw/fty6z9NPP83p06dZs2YNc+fOZeLEiTYJDcDjjz/OuXPnWLp0Kdu2beOxxx6jUaNGXLp06eHeiNtWrlzJgQMHCAkJYdGiRYCZTI4YMYJdu3axYMECjh49Sq9eve57nIiICD777DN+/PFH1q1bx/Hjxxk2bNh995k6dSqenp5s3ryZUaNGMXz4cEJCQgCIiYmhffv2eHh4sHnzZiZOnMhbb72VrGuMc+rUKVq2bEnVqlXZtWsX3377LZMmTeLDDz8EzMS2W7duPPPMM+zbt481a9bQoUMHa6tj+/btCQ4OZvfu3WzatIl+/fqlycTYD82QeK5evWoAxtWrV+1y/rlzDcNiMQzzn7g7i8ViLnPn2iWsDCUyMtJYsGCBERkZae9QJIvQPSdpTfdc1nTjxg1j7969xo0bNwzDMIzw8PifF9JqCQ9/uNhr1apljB492jAMw4iKijJy5cplrF692ub5tGnTrNt369bN6NKli2EYhnHz5k3Dw8PD+OOPP2yO2adPH6Nbt26GYRjG6tWrDcBYsGDBA2MpU6aMMXbsWMMwDGPfvn0GYGzdutX6+r///msAxpdffmkYhmGsX7/e8Pb2Nm7evGlznCJFihgTJkx44PmCg4ONwYMHW5/37NnT8Pf3N27dunXf/bZu3WoAxrVr12yu8fLly4ZhGMbkyZMNwDh06JB1n3Hjxhn+/v4252rXrp1NLHXq1LE5T9WqVY3XXnvNMAzDWLp0qeHk5GSEhoZaXw8JCTEAY/78+YnGeu957vbmm28aJUqUMGJjY23i9PLyMmJiYoxt27YZgHH06FHr6zExMcbly5eN8+fPG4CxZs2aRM+dEu7927pbUnMDtVilMzExZjP8/ZrphwxRt0AREREBDw8ID0/asmRJ0o65ZEn8fcPCYjl58gphYbHWdR4eSY/zwIEDbNmyhW7dugHg5OREly5dmDRpkvX5E088wfTp0wG4fv06CxcupHv37gAcOnSIiIgImjRpgpeXl3WZNm0ahw8ftjlXlSpVbJ6Hh4czbNgwSpUqha+vL15eXuzbt8/aYnXgwAGcnJx47LHHrPsULVqU7NmzW5/v2rWL8PBwcubMaXP+I0eOxDt/UpUrVw4XFxebddu2baNNmzYUKFCAbNmyERwcDGDTunYvDw8PihQpYn0eEBAQr7XtXuXLl7d5fvc+Bw4cIDAwkDx58lhfr1atWtIuKhH79u2jZs2aNq1MtWvXJjw8nJMnT1KhQgUaNWpEuXLlePzxx/nuu++4fPkyADly5KBXr140a9aMNm3aMGbMGJuujumJk70DEFvr18cfUHo3w4ATJ8zt6tdPs7BEREQkHbJYwNMzads2bQr585vdARP6AtdiMV9v2hQcHW1fi401v9T19ASHZHwtP2nSJKKjo8mbN691nWEYuLq68vXXX+Pj40P37t0JDg7m3LlzhISE4O7uTvPmzQGsXQQXL15Mvnz5bI7t6upq89zznjdk2LBhhISE8Nlnn1G0aFHc3d3p3LlzkgtGxJ0/ICCANWvWxHstuYUh7o3z+vXrNGvWjGbNmjF9+nT8/Pw4fvw4zZo1u2+szs7ONs8tFou1i+XD7BMbG/uQV5ByHB0dCQkJ4Y8//mD58uWMHTuWt956i5CQEMqVK8fkyZMZNGgQy5YtY9asWbz99tuEhIRQo0YNu8WcECVW6UxSE/B0mqiLiIhIOuXoCGPGmNX/LBbb5CquIWH06PhJ1aOKjo5m2rRpfP755zRt2tTmtfbt2/Pzzz/Tv39/atWqRWBgILNmzWLp0qU8/vjj1gSgdOnSuLq6cvz4cWsrTlJt3LiRXr16WcdqhYeH25Q6L1GiBNHR0ezYsYPKlSsDZgtZXIsJwGOPPcaZM2dwcnIiKCgoGe/Cg+3fv5+LFy/y8ccfWysG/vXXX6lyrvspUaIEJ06c4OzZs/j7+wOwdevWRzpmqVKlmDt3LoZhWFutNm7cSLZs2cifPz9gJne1a9emdu3avPvuuxQsWJBFixZRrlw5ACpVqkSlSpV44403qFmzJjNmzFBiJfcXEJCy24mIiIjE6dgR5swxhx3c3UMmf34zqerYMeXPuWjRIi5fvkyfPn3izb/UqVMnJk2aRP/+/QGzOuD48eM5ePAgq1evtm6XLVs2hg0bxksvvURsbCx16tTh6tWrbNy4EW9vb3r27Jno+YsVK8a8efNo06YNFouFd955x6Z1pmTJkjRu3Jh+/frx7bff4uzszMsvv4y7u7s1CWjcuDE1a9akffv2jBo1iuLFi3P69GkWL15Mhw4d4nU/TI4CBQrg4uLC2LFj6d+/P//88w8jRox45OM+rCZNmlCkSBF69uzJqFGjuHbtGm+//TbAAwtGXL16lZ07d9qsy5kzJ88//zyjR4/mxRdfZODAgRw4cID33nuPoUOH4uDgwObNm1m5ciVNmzYld+7cbN68mfPnz1O8eHGOHDnC999/T9u2bcmbNy8HDhzg33//5emnn06ttyDZNMYqnalb1/zHLbH71mKBwEBzOxEREZGH1bEjHD0Kq1fDjBnmzyNHUiepArMbYOPGjROc1LZTp0789ddf7N69GzCrA+7du5d8+fJRu3Ztm21HjBjBO++8w8iRIylVqhTNmzdn8eLFFCpU6L7n/+KLL8iePTu1atWiTZs2NGvWzGY8FcC0adPw9/enXr16dOjQgb59+5ItWzbc3NwAM6FYsmQJ9erVo3fv3hQvXpyuXbty7Ngxa6vOo/Lz82PKlCn88ssvlC5dmo8//pjPPvssRY79MBwdHVmwYAHh4eFUrVqVZ5991loVMO79SMyaNWusLUtxywcffEC+fPlYsmQJW7ZsoUKFCvTv358+ffpYEzZvb2/WrVtHy5YtKV68OG+//TafffYZTZo0wcPDg/3799OpUyeKFy9Ov379eOGFF3juuedS/b14WBbjQZ0ws6CwsDB8fHy4evUq3t7eaX7+uMn7IH4faIvF/KYptf7xyyyioqJYsmQJLVu2jNePWCQ16J6TtKZ7Lmu6efMmR44coVChQg/8kJuSYmNjCQsLw9vbG4fkDLLKYE6ePElgYCArVqygUaNG9g7H7jZu3EidOnU4dOiQTaGM1JTW99z9/raSmhuoK2A6lFgzPcCwYUqqRERERFLSqlWrCA8Pp1y5coSGhvLqq68SFBREvXr17B2aXcyfPx8vLy+KFSvGoUOHGDx4MLVr106zpCqjUmKVTnXsCO3amdX/QkNh8WKYPh22bLF3ZCIiIiKZS1RUFG+++Sb//fcf2bJlo1atWkyfPj3LtgZfu3aN1157jePHj5MrVy4aN27M559/bu+w0j0lVumYo+Odkur16sHMmbB2LezaBRUq2DU0ERERkUwjrsy5mJ5++ul0WRwivcv8nWQziXz57oy7+uor+8YiIiIiIiK2lFhlIIMGmT+nT4cLF+wbi4iIiIiI3KHEKgOpWRMqV4Zbt+C77+wdjYiIiIiIxFFilYFYLGalQIBvvoGoKPvGIyIiIiIiJiVWGcwTT0Du3GYZ9gUL7B2NiIiIiIiAEqsMx9UV+vc3H48ZY99YRERERETEpMQqA+rfH5ydYeNG2LbN3tGIiIhIhhMbA2fXwNGfzZ+xMfaOSBJw9OhRLBYLO3fuBGDNmjVYLBauXLmS6D5TpkzB19f3kc+dUsfJSuyeWI0bN46goCDc3NyoXr06W+4zA+6UKVOwWCw2i5ubm802hmHw7rvvEhAQgLu7O40bN+bff/9N7ctIUwEBZpdAgLFj7RuLiIiIZDAn5sGvQbCyAfzxpPnz1yBzfSrbtGkTjo6OtGrVKtXPZU9nz57F2dmZmTNnJvh6nz59eOyxxx76uLVq1SI0NBQfH59HDdFGUFAQo0ePtlnXpUsXDh48mKLnSUj9+vUZMmRIqp8nLdg1sZo1axZDhw7lvffeY/v27VSoUIFmzZpx7ty5RPfx9vYmNDTUuhw7dszm9VGjRvHVV18xfvx4Nm/ejKenJ82aNePmzZupfTlpKq70+s8/w33eLhEREZE7TsyD9Z0h4qTt+ohT5vpUTq4mTZrEiy++yLp16zh9+nSqnsswDKKjo1P1HInx9/enVatW/PDDD/Feu379OrNnz6ZPnz4PfVwXFxfy5MmDxWJJiTDvy93dndy5c6f6eTITuyZWX3zxBX379qV3796ULl2a8ePH4+HhkeBNGMdisZAnTx7r4u/vb33NMAxGjx7N22+/Tbt27ShfvjzTpk3j9OnTLMhklR6qVYPq1SEyEiZMsHc0IiIiYheGAdHXk7ZEhsFfgwAjoQOZP/4abG6XlOMZCR0nceHh4cyaNYsBAwbQqlUrpkyZYn3tySefpEuXLjbbR0VFkStXLqZNmwZAbGwsI0eOpFChQri7u1OhQgXmzJlj3T6um9zSpUupXLkyrq6ubNiwgcOHD9OuXTv8/f3x8vKiatWqrFixwuZcoaGhtGrVCnd3dwoVKsSMGTPiteJcuXKFZ599Fj8/P7y9vWnYsCG7du1K9Hr79OnDypUrOX78uM36X375hejoaLp3786yZcuoU6cOvr6+5MyZk9atW3P48OFEj5lQV8ApU6ZQoEABPDw86NChAxcvXrTZ50HXX79+fY4dO8ZLL71k7REWd9x7uwJ+++23FClSBBcXF0qUKMGPP/5o87rFYuH777+nQ4cOeHh4UKxYMX799ddErycp5s6dS5kyZXB1dSUoKIjPP//c5vVvvvmGYsWK4ebmhr+/P507d7a+NmfOHMqVK4e7uzs5c+akcePGXL9+/ZHiuR+nVDvyA0RGRrJt2zbeeOMN6zoHBwcaN27Mpk2bEt0vPDycggULEhsby2OPPcZHH31EmTJlADhy5AhnzpyhcePG1u19fHyoXr06mzZtomvXrgke89atW9y6dcv6PCwsDDD/oKPScU3z55+3sHmzE99+azB0aDQuLvaOKP2I+72l59+fZC665ySt6Z7LmqKiojAMg9jYWGJjYyH6Og5zvFPo6AbcOAlz4nczcwB871kX2zkMnDyTfPSZM2dSsmRJihUrxpNPPsnQoUN57bXXsFgsdOvWjS5duhAWFoaXlxcAS5cuJSIignbt2hEbG8tHH33E9OnTrR+k161bx1NPPUXOnDkJDg423w/g9ddfZ9SoURQuXJjs2bNz4sQJmjdvzogRI3B1deXHH3+kTZs27Nu3jwIFCgDQo0cPLl68yKpVq3B2dmbYsGGcO3fO+l4DdO7cGXd3dxYvXoyPjw8TJ06kUaNG7N+/nxw5csS73ubNm+Pv78/kyZN55513rOsnT55Mhw4d8Pb25tq1awwZMoTy5csTHh7Oe++9R4cOHdi+fTsODg7Wc8f9vu99vnnzZvr06cNHH31Eu3bt+P3333n//fet24D5ufZ+1z9nzhwqVapE3759efbZZ22Of/dx5s+fz+DBg/nyyy9p1KgRixcvpnfv3uTNm5cGDRpYr++DDz7g448/5pNPPuHrr7+me/fuHDlyJMH3KM7d7/Pd63bu3EnXrl157733eOKJJ/jjjz8YOHAg2bNnp1evXvz1118MGjSIqVOnUqtWLS5dusSGDRuIjY0lNDSUbt268cknn9C+fXuuXbvGhg0biImJiXeuuOs0DIOoqCgcHR1tXkvqv7N2S6wuXLhATEyMTYsTmE2n+/fvT3CfEiVK8MMPP1C+fHmuXr3KZ599Rq1atdizZw/58+fnzJkz1mPce8y41xIycuRIPvjgg3jrly9fjoeHx8NeWprx8LCQPXtTQkPdePfdXdSrd8reIaU7ISEh9g5Bshjdc5LWdM9lLU5OTuTJk4fw8HAiIyMh+nq8hCethIWFgVPSi1589913dOrUibCwMGrVqsWVK1dYunQpderUoWbNmnh4eDBjxgzrF+HTpk2jefPmGIbB+fPnGTlyJPPnz6datWoAdOzYkTVr1jBu3DgqVapEREQEAK+99hrVq1e3nrdQoUIUKlTI+nzYsGHMnTuX2bNn069fPw4ePMjKlStZtWoVpUqVAsxeVZUrV+bmzZuEhYWxadMmtmzZwr///ourqysA77zzDvPnz+enn36iV69eCV5zly5dmDx5MoMGDcJisXDkyBHWr1/P/PnzCQsLo0mTJtZtc+fOzejRoylatChbtmyhdOnShIeHA2b3wbCwMOs1Xrt2DQcHBz7//HMaNWrEc889B0DPnj1Zu3YtK1eutDYUPOj6nZycsFgsODs7Wz/3hoWFcfPmTQzDsB5n1KhRPPnkk3Tv3h0wW+Q2bNjAJ598QuXKla3H79q1q3UM3WuvvcbYsWNZs2aNTcPH3aKjo4mMjLSe527jxo0jODiYQbfHwHTs2JGdO3fy6aef0rFjRw4cOICHhwf16tUjW7ZsZM+enSJFihAWFsahQ4eIjo6mcePG5MiRgxw5clgbZxI6V2RkJDdu3GDdunXxupDGve8PYrfEKjlq1qxJzZo1rc9r1apFqVKlmDBhAiNGjEj2cd944w2GDh1qfR4WFkZgYCBNmzbF2zulvgVKHf/848AHH8DGjY/x8ccV7B1OuhEVFUVISAhNmjTB2dnZ3uFIFqB7TtKa7rms6ebNm5w4cQIvLy+zgJeRzWw5Sopz63FY9+CiEbH1FkPuujbrDMPg2rVrZMuWzdpVzNvRA5I41ufAgQNs376dhQsXWj9bdenShZkzZ9KyZUsAnnjiCebPn0+/fv24fv06S5cuZcaMGXh7e7Nnzx4iIiLo2LGjzXEjIyOpVKkS3t7e1qSgbt26Np/fwsPD+eCDD1iyZAmhoaFER0dz48YNzp8/j7e3N6dOncLJyYm6devi4GCOkqlYsSLZs2fHzc0Nb29vDh8+zPXr1ylSpIjN+W/cuMHp06cT/bzYv39/Ro8ezbZt22jYsCFz5swhKCiI1q1bY7FY+Pfff3nvvffYsmULFy5csLakXLp0CW9vb2vrnaenp801ZsuWzRpX+/btbc5fr149Vq1aZV33oOsHs9dY3LXGcXNzw2KxWNf9+++/9O/f32ab4OBgvvrqK5t1VapUsT739vbG29ub8PDwRN8jJycnXFxc4r1uGAYHDx6Md30NGjRg/PjxeHp60rZtWz799FMee+wxmjVrRrNmzazdEGvVqkWjRo2oU6cOTZs2pUmTJnTu3Jns2bMnGMfNmzdxd3enXr168YrjJZSIJXgtSdoqFeTKlQtHR0fOnj1rs/7s2bPkyZMnScdwdnamUqVKHDp0CMC639mzZwkICLA5ZsWKFRM9jqurq/Xbh3uPn97/sxowAEaOhM2bHdixw4HbX+LIbRnhdyiZi+45SWu657KWmJgYLBYLDg4O1iQAx2xJ2zlvM/DIbxaqSHCclQU88uOQtxk42HaFio2NBadYLM5ed877ECZPnkx0dDT58+e3rjMMA1dXV8aNG4ePjw9PPfUUwcHBXLhwgZCQENzd3WnZsiUODg7WFoPFixeTL18+m2O7urravB/ZsmWzifHVV18lJCSEzz77jKJFi+Lu7k7nzp2Jioqy2c/mPY17R26/19evXycgIIA1a9bEuzZfX99E35MSJUpQt25dpk6dSsOGDfnxxx/p27evtatZu3btKFiwIN999x158+YlNjaWsmXLEh0dnWBsCcUaF+PdMcdtk5Trv/da49x9rrvX3e9cd/8+7rfNve49N9zpgni/uHx8fNi+fTtr1qxh+fLlvP/++wwfPpytW7fi6+tLSEgIf/zxB8uXL2fcuHG88847bN682aYF7+7jxrXc3ftvalL/jbVb8QoXFxcqV67MypUrretiY2NZuXKlTavU/cTExPD3339bk6hChQqRJ08em2OGhYWxefPmJB8zo/H3h7ihY199Zd9YREREJB1zcITKY24/ubel6fbzyqPjJVWPKjo6mmnTpvH555+zc+dO67Jr1y7y5s3Lzz//DJg9kQIDA5k1axbTp0/n8ccft36gLV26NK6urhw/fpyiRYvaLIGBgfc9/8aNG+nVqxcdOnSgXLly5MmTh6NHj1pfL1GiBNHR0ezYscO67tChQ1y+fNn6/LHHHuPMmTM4OTnFO3+uXLnue/4+ffowd+5c5s6dy6lTp6zdBi9evMiBAwd4++23adSoEaVKlbI5Z1KUKlWKzZs326z7888/H+r6wfxcHhNz/26dpUqVYuPGjfGOXbp06YeK+WEUL148wXMWL17cmpw6OTnRuHFjRo0axe7duzl69CirVq0CzKSsdu3afPDBB+zYsQMXFxfmz5+favHatSvg0KFD6dmzJ1WqVKFatWqMHj2a69ev07t3bwCefvpp8uXLx8iRIwEYPnw4NWrUoGjRoly5coVPP/2UY8eOWQfaWSwWhgwZwocffkixYsUoVKgQ77zzDnnz5qV9+/b2usxUN2gQTJsGs2fDp5+a81yJiIiIxBPYEerOgW2DbUuue+Q3k6rAjonumlyLFi3i8uXL9OnTJ978S506dWLSpEn0798fMKsDjh8/noMHD7J69WrrdtmyZWPYsGG89NJLxMbGUqdOHa5evcrGjRvx9vamZ8+eiZ6/WLFizJs3jzZt2mCxWHjnnXdsiheULFmSxo0b069fP7799lucnZ15+eWXcXd3t7a2NG7cmJo1a9K+fXtGjRpF8eLFOX36NIsXL6ZDhw5UqVIl0fM//vjjDBo0iOeee46mTZtaE8Hs2bOTM2dOJk6cSEBAAMePH+f1119/qPd20KBB1K5dm88++8xavGLZsmUPdf1gzmO1bt06unbtiqura4LJ4iuvvMITTzxBpUqVaNy4Mb/99hvz5s2LV2ExOc6fP2+dBDmOv78/AwcOpGHDhowYMYIuXbqwadMmvv76a7755hvAvLf+++8/6tWrR/bs2VmyZAmxsbGUKFGCzZs3s3LlSpo2bUru3LnZvHkz58+ft46jSxWGnY0dO9YoUKCA4eLiYlSrVs34888/ra8FBwcbPXv2tD4fMmSIdVt/f3+jZcuWxvbt222OFxsba7zzzjuGv7+/4erqajRq1Mg4cODAQ8V09epVAzCuXr36SNeWlmrXNgwwjPfes3ck6UNkZKSxYMECIzIy0t6hSBahe07Smu65rOnGjRvG3r17jRs3bjzagWKiDePMasM4MsP8GRN9/81jYozLly8bMTExD32q1q1bGy1btkzwtc2bNxuAsWvXLsMwDGPv3r0GYBQsWNCIjY212TY2NtYYPXq0UaJECcPZ2dnw8/MzmjVrZqxdu9YwDMNYvXq1ARiXL1+22e/IkSNGgwYNDHd3dyMwMND4+uuvjeDgYGPw4MHWbU6fPm20aNHCcHV1NQoWLGjMmDHDyJ07tzF+/HjrNmFhYcaLL75o5M2b13B2djYCAwON7t27G8ePH3/ge9CvXz8DMGbPnm2zPiQkxChVqpTh6upqlC9f3lizZo0BGPPnz7fGDhg7duxI9BonTZpk5M+f33B3dzfatGljfPbZZ4aPj89DXf+mTZuM8uXLG66urkZcejB58mSb4xiGYXzzzTdG4cKFDWdnZ6N48eLGtGnTbF6/O/Y4Pj4+xuTJkxN9b4KDgw3Mvqk2y/Dhw43Lly8bs2fPNkqXLm04OzsbBQoUMD799FPrvuvXrzeCg4ON7NmzG+7u7kb58uWNWbNmGYZh3kvNmjUz/Pz8DFdXV6N48eLG2LFjE43jfn9bSc0NLLffBLlLWFgYPj4+XL16Nd0Xr4gzezZ06WJ2DTx2DBIYMpalREVFsWTJElq2bKmxB5ImdM9JWtM9lzXdvHmTI0eOUKhQoXgD7FNTXCU1b2/vZI2xymhOnjxJYGAgK1asoFGjRvYOJ0tK63vufn9bSc0NMv9fRhbRoQPkywdnz5pJloiIiIgkzapVq/j11185cuQIf/zxB127diUoKIh69erZOzTJQJRYZRLOzvD88+bjMWMeejJ0ERERkSwrKiqKN998kzJlytChQwf8/PxYs2aNWoPloWSoeazk/vr2heHDYds2+PNPyKSFEEVERERSVNwcSCKPQi1WmYifH9yeDFul10VERERE0pASq0zmxRfNn3PmwKlT9o1FREREUodqj4mkrJT4m1JilclUrAj16kF0NHz7rb2jERERkZQUN+YnIiLCzpGIZC5xf1OPMq5OY6wyoUGDYN06mDAB3n4b0rAaq4iIiKQiR0dHfH19OXfuHAAeHh7WSWxTU2xsLJGRkdy8eTNLlFsX+0ure84wDCIiIjh37hy+vr44Ojom+1hKrDKhdu2gQAE4fhxmzoRevewdkYiIiKSUPHnyAFiTq7RgGAY3btzA3d09TRI5kbS+53x9fa1/W8mlxCoTcnKCF16A114zi1j07An6N1BERCRzsFgsBAQEkDt3bqKiotLknFFRUaxbt4569eqpBLmkibS855ydnR+ppSqOEqtM6tln4f33YccO2LAB6ta1d0QiIiKSkhwdHVPkw2BSzxUdHY2bm5sSK0kTGfGeUyfZTCpHDnjqKfOxSq+LiIiIiKQuJVaZWFzp9fnzzfFWIiIiIiKSOpRYZWLlykHDhhATo9LrIiIiIiKpSYlVJjdokPlz4kS4ccO+sYiIiIiIZFZKrDK51q0hKAguXYLp0+0djYiIiIhI5qTEKpNzdISBA83HX30FhmHfeEREREREMiMlVllAnz7g4QF//w1r19o7GhERERGRzEeJVRbg62tOEgwqvS4iIiIikhqUWGURcd0BFy6Eo0ftGoqIiIiISKajxCqLKF0amjSB2FgYN87e0YiIiIiIZC5KrLKQwYPNn99/D9ev2zcWEREREZHMRIlVFtKiBRQpAleuwE8/2TsaEREREZHMQ4lVFuLgAC++aD5W6XURERERkZSjxCqL6dULvLxg715YudLe0YiIiIiIZA5KrLIYHx8zuQKVXhcRERERSSlKrLKguO6AixbB4cP2jUVEREREJDNQYpUFFS9uFrIwDJVeFxERERFJCUqssqhBg8yfkybBtWv2jUVEREREJKNTYpVFNW1qtlyFhcG0afaORkREREQkY1NilUU5ONxptRo7FmJj7RuPiIiIiEhGpsQqC3v6afD2hgMHICTE3tGIiIiIiGRcSqyysGzZ4JlnzMdjxtg3FhERERGRjEyJVRb3wgtgscDSpXDwoL2jERERERHJmJRYZXFFi0KrVubjr7+2bywiIiIiIhmVEith8GDz5+TJZpVAERERERF5OEqshEaNoFQpCA+HKVPsHY2IiIiISMajxEqwWFR6XURERETkUSixEgB69ABfXzh0yCxkISIiIiIiSafESgDw9IRnnzUff/WVfWMREREREclolFiJ1QsvgIMDLF8O+/bZOxoRERERkYxDiZVYBQVB27bm47Fj7RqKiIiIiEiGosRKbMQVsZg6Fa5csWsoIiIiIiIZhhIrsVG/PpQrBxER8MMP9o5GRERERCRjUGIlNu4uvf711xATY994REREREQyAiVWEs+TT0KOHHDkCCxebO9oRERERETSPyVWEo+HB/Ttaz4eM8a+sYiIiIiIZARKrCRBzz8Pjo6wahX884+9oxERERERSd+UWEmCChSADh3Mxyq9LiIiIiJyf0qsJFFxRSx+/BEuXbJvLCIiIiIi6ZkSK0lUnTpQsSLcuAHff2/vaERERERE0i8lVpKou0uvjxsH0dH2jUdEREREJL1SYiX31a0b5MoFx4/Dr7/aOxoRERERkfRJiZXcl5sbPPec+firr+wbi4iIiIhIeqXESh5owACz9PratbBrl72jERERERFJf5RYyQPlywedO5uP1WolIiIiIhKfEitJkrgiFtOnw4UL9o1FRERERCS9UWIlSVKzJlSpArduwXff2TsaEREREZH0RYmVJMndpde/+Qaiouwbj4iIiIhIeqLESpLsiScgd244eRLmz7d3NCIiIiIi6YcSK0kyV1fo3998rCIWIiIiIiJ3KLGSh9K/Pzg7w8aNsG2bvaMREREREUkflFjJQwkIMLsEAowda99YRERERETSCyVW8tDiilj8/DOcO2ffWERERERE0gMlVvLQqlWD6tUhMhImTLB3NCIiIiIi9qfESpIlrtXq22/NBEtEREREJCtTYiXJ0rmzOd4qNBTmzrV3NCIiIiIi9qXESpLFxQUGDDAfq/S6iIiIiGR1Sqwk2fr1MxOsP/+ELVvsHY2IiIiIiP0osZJk8/eHrl3Nx2q1EhEREZGsTImVPJK4IhazZ5vjrUREREREsiIlVvJIKleG2rUhKkql10VEREQk61JiJY8srtVq/Hi4dcu+sYiIiIiI2IMSK3lkHTpAvnxw9qzZJVBEREREJKtRYiWPzNkZXnjBfDxmDBiGfeMREREREUlrSqwkRfTtC66usG2bWX5dRERERCQrUWIlKSJXLuje3Xys0usiIiIiktUosZIU8+KL5s85c+DUKfvGIiIiIiKSlpRYSYqpWBHq1YPoaPj2W3tHIyIiIiKSdpRYSYoaPNj8OWEC3Lxp31hERERERNKKEitJUW3bQoECcOECzJxp72hERERERNKGEitJUU5Od0qvf/WVSq+LiIiISNagxEpS3LPPgrs77NgBGzbYOxoRERERkdSnxEpSXI4c0KOH+Vil10VEREQkK1BiJakirvT6/Plw/Lh9YxERERERSW1KrCRVlC0LDRtCTIxKr4uIiIhI5qfESlLNoEHmz4kTISLCvrGIiIiIiKQmJVaSalq3hkKF4NIlmDHD3tGIiIiIiKQeJVaSahwdYeBA87FKr4uIiIhIZmb3xGrcuHEEBQXh5uZG9erV2bJlS5L2mzlzJhaLhfbt29us79WrFxaLxWZp3rx5KkQuSfHMM+DhAX//DWvX2jsaEREREZHUYdfEatasWQwdOpT33nuP7du3U6FCBZo1a8a5c+fuu9/Ro0cZNmwYdevWTfD15s2bExoaal1+/vnn1AhfksDXF3r2NB+r9LqIiIiIZFZ2Tay++OIL+vbtS+/evSldujTjx4/Hw8ODH374IdF9YmJi6N69Ox988AGFCxdOcBtXV1fy5MljXbJnz55alyBJEFd6feFCOHrUrqGIiIiIiKQKJ3udODIykm3btvHGG29Y1zk4ONC4cWM2bdqU6H7Dhw8nd+7c9OnTh/Xr1ye4zZo1a8idOzfZs2enYcOGfPjhh+TMmTPRY966dYtbt25Zn4eFhQEQFRVFVFTUw16a3KNoUWjSxJGQEAfGjo3h449jU/2ccb83/f4kreiek7Sme07Sku43SWvp6Z5Lagx2S6wuXLhATEwM/v7+Nuv9/f3Zv39/gvts2LCBSZMmsXPnzkSP27x5czp27EihQoU4fPgwb775Ji1atGDTpk04OjomuM/IkSP54IMP4q1fvnw5Hh4eSb8oSVT16v6EhNRgwoQYqlVbjptbTJqcNyQkJE3OIxJH95ykNd1zkpZ0v0laSw/3XEQS5w2yW2L1sK5du0aPHj347rvvyJUrV6Lbde3a1fq4XLlylC9fniJFirBmzRoaNWqU4D5vvPEGQ4cOtT4PCwsjMDCQpk2b4u3tnXIXkYU1bw4//2xw+LALFy+2oG/f1G21ioqKIiQkhCZNmuDs7Jyq5xIB3XOS9nTPSVrS/SZpLT3dc3G92R7EbolVrly5cHR05OzZszbrz549S548eeJtf/jwYY4ePUqbNm2s62JjzQ/nTk5OHDhwgCJFisTbr3DhwuTKlYtDhw4lmli5urri6uoab72zs7Pdf5GZyYsvwpAhMG6cIwMGOGKxpP459TuUtKZ7TtKa7jlJS7rfJK2lh3suqee3W/EKFxcXKleuzMqVK63rYmNjWblyJTVr1oy3fcmSJfn777/ZuXOndWnbti0NGjRg586dBAYGJniekydPcvHiRQICAlLtWiRpevcGLy/Yuxfu+rWLiIiIiGR4dq0KOHToUL777jumTp3Kvn37GDBgANevX6d3794APP3009biFm5ubpQtW9Zm8fX1JVu2bJQtWxYXFxfCw8N55ZVX+PPPPzl69CgrV66kXbt2FC1alGbNmtnzUgXw9jaTK1DpdRERERHJXOw6xqpLly6cP3+ed999lzNnzlCxYkWWLVtmLWhx/PhxHBySnvs5Ojqye/dupk6dypUrV8ibNy9NmzZlxIgRCXb1S/diY+D8ergRCu4B4FcXHBIuwJFRDBwIY8fCokVw+DAk0HtTRERERCTDsXvxioEDBzJw4MAEX1uzZs19950yZYrNc3d3d37//fcUiszOTsyDbYMh4uSddR75ofIYCOxov7geUfHi0KIFLF0K48bBF1/YOyIRERERkUdn166AkogT82B9Z9ukCiDilLn+xDz7xJVCBg0yf06aBNeu2TcWEREREZGUoMQqvYmNMVuqMBJ48fa6bUPM7TKopk2hRAkIC4Np0+wdjYiIiIjIo1Nild6cXx+/pcqGAREnzO0yKAcHs/Q6mOOtYlN3SisRERERkVSnxCq9uRGastulU08/bVYJPHAA0sGE2iIiIiIij0SJVXrjnsT5tg5+DcfnQMzN1I0nlWTLBs88Yz4eM8a+sYiIiIiIPColVumNX12z+h+W+2934Q/Y8DjMywOb+8K5dWBkrD51AweCxWJWCDx40N7RiIiIiIgknxKr9MbB0SypDsRPrizm8thoKP0GeARC1FU4/D2sCIZfC8OutyHsQNrGnExFikDr1ubjr7+2bywiIiIiIo9CiVV6FNgR6s4Bj3y26z3ym+tLDoaKH0G7o9BoNRR+Bpy94fox2PM/WFQSllWFA1/BzXN2uYSkiiu9PnmyWSVQRERERCQjsvsEwZKIwI6Qr51Z/e9GqDn2yq+u2aIVx+IA/vXNpcrXcOpXOPIThC6DS3+Zy/ahENAcgp6C/O3Ayd1eV5SgRo2gVCnYt89MrgYPtndEIiIiIiIPTy1W6ZmDo5k0BXUzf96dVN3LyR0KdoH6v0GH01D5K8hRFYwYOL0Y/ugG8/zhz2fg7Op0Mx7LYrnTaqXS6yIiIiKSUSmxyozc/KDEi9B8C7TaB2XeAs+CEH0N/psMKxvCwiDY+QZc2WPvaOnRA3x94fBhs5CFiIiIiEhGo8Qqs/MpCRU+hLb/QeN1UKQvOPuYkwzv/RiWlIWlj8H+L+HGGbuE6OkJzz5rPv7qK7uEICIiIiLySJRYZRUWB8hdF6pPhI5noM4cc8yVgzNc3mGOxVqQD1a3gKMzIPp6mob3wgvg4ADLl5vjrUREREREMhIlVlmRoxsU6AT1FkCHUKgyDnLWMMddhS6DP7qb82Nt6glnVkBsTKqHFBQEbduaj8eOTfXTiYiIiIikKCVWWZ1rTij+PDTbBG3+hbLvgVdhiA6HI9NgVRNYWAB2vAqXd6dqKHEVAadOhStXUvVUIiIiIiIpSomV3JGtKJR/H9ocgiYboWh/cMkON07Dvk9haQVYUgH2fQYRp1P89MHBUK4cRETADz+k+OFFRERERFKNEiuJz2IBv1pQ7Vuzq2Dd+ea8Wg4ucGU37HgFFgbCqqZw5EeICk+x08aVXv/6a4hJ/R6IIiIiIiIpQomV3J+jKwS2h7pzzSSr6njwq22OxzoTApueNufH+uMpOP07xEY/0umefBJy5IAjR2DRopS5BBERERGR1KbESpLONQcUew6abIC2h6HccMhWDGIi4Oh0WNMcFgTCtqFwaQcYxkOfwsMD+vY1H6v0uoiIiIhkFEqsJHm8CkO5d6D1AWj6JxR7wSyEcfMMHPgSlj0GS8rB3k8g4uRDHfr558HREVatgn/+SaX4RURERERSkBIreTQWC+SqDlW/hvanod5CKPA4OLjC1T2w83VYUABWNoLDkyEq7IGHLFAAOnQwH6v0uoiIiIhkBEqsJOU4ukD+tlBntjkJcbXvIHc9wICzq2DzM+b8WBu7wakl9x2PFVfE4scf4dKltAlfRERERCS5lFhJ6nDxhaLPQuO10PYIVPgfeJeEmBtwbCasbQUL8sFfg+HiX/HGY9WpAxUrwo0b8P33drkCEREREZEkU2Ilqc8rCMq8Ca32QrOtUHwQuPrBzXNw8Cv4vSosLg17PoLrxwCzh2HchMHjxkH0oxUbFBERERFJVUqsJO1YLJCzClQZAx1OQfAiKNgVHN0gbD/segsWBsGK+nDoe7p2ukquXHD8OPz6q72DFxERERFJnBIrsQ8HZ8jXCmr/DB3PQvUfwL8BYIFza2FLX9wW+7Nq+BO0rvQb48ZG2TtiEREREZFEKbES+3P2hiK9odEqaHcMKowEn9IQe4tyPr/w27C2zOySl/NLX4QLm5M1P5aIiIiISGpSYiXpi2cglHkdWv4DzbdDiZe4ctMfP+8L+F3+GpbXgEUl4e8REH4k4WPExmA5t5Z80euwnFsLsTFpew0iIiIikuUosZL0yWKBHJWg8hfsK3mS5p8sZeamJzEc3OHaQfj7Xfi1MITUhX8nQORlc78T8+DXIJzWNqHKrS9wWtsEfg0y14uIiIiIpBIlVpLu1ajpxEWX5nT7ejpfHD0LNaZCnsaABc5vgK39zfmxfq8B6ztBxEnbA0ScgvWdlVyJiIiISKpRYiXpnsVyZ8Lg0eOyERX4NDQMgfYnoOIo8C0HsZFwcXMiR7g9JmvbEHULFBEREZFUocRKMoQnngB/fzh5EubPv73SIx+UfgVa7oZqD5pF2ICIE3B+fWqHKiIiIiJZkBIryRBcXaF/f/PxV18lsIGTR9IOdCM0xWISEREREYmjxEoyjOeeA2dn2LgRtm2750X3gKQdJKnbiYiIiIg8BCVWkmEEBJhdAgHGjr3nRb+64JEfsCR+AIuT2X1QRERERCSFKbGSDCWuiMXPP8PZs3e94OAIlcfcfnJvcnX7uRENIXXg4tZUjlJEREREsholVpKhVKsGNWpAZCRMnHjPi4Edoe6c+K1SHvnN4hbZK8HNc7CiPpxaklYhi4iIiEgWoMRKMpy4VqtvvzUTLBuBHaHtUaKDQ/jLdSjRwSHQ9ggU7QON10JAM4iJgHVt4dB3aR67iIiIiGROSqwkw+nUyRxvFRoKc+cmsIGDI0buYE451cPIHWx2EwRwzgbBv0Hh3mDEwJZ+sPtdMIw0jV9EREREMh8lVpLhuLjAgAHm4wRLr9+PgzNUnwRl3zOf/zMC/uwNsVEpGqOIiIiIZC1KrCRD6tfPTLD+/BO2bHnInS0WKP8+VP8eLI5wZCqsaQVRYakRqoiIiIhkAUqsJEPy94du3czHD91qFadIH7NroJMnnAmBFcEQcTrFYhQRERGRrEOJlWRYL75o/pw92xxvlSx5W0CjNeCWGy7vhOU14erelAlQRERERLIMJVaSYVWuDLVrQ1QUTJjwCAfKWQWaboJsxSHiOCyvDefWpVicIiIiIpL5KbGSDO3u0uu3bj3CgbwKQ9M/IFctiLoCq5rAsdkpEaKIiIiIZAFKrCRD69AB8ueHc+fMLoGPxDUnNFwB+TtAbCRs7AL7v0yROEVEREQkc1NiJRmaszM8/7z5eMyYFJiSyskd6vwCxW8P4No+FLYNgdiYRzywiIiIiGRmSqwkw+vbF1xdYds2s/z6I3NwhMpjoNJn5vMDY8zWq+gbKXBwEREREcmMlFhJhpcrF3Tvbj5Odun1e1ksUOplqPUzOLjAibmwugncuphCJxARERGRzESJlWQKcUUs5syBU6dS8MBBXaHBcnD2hfMbIaQ2hB9JwROIiIiISGagxEoyhQoVIDgYoqPNCoEpyj8YmmwAj0AIO2DOdXVpWwqfREREREQyMiVWkmnEtVpNmAA3b6bwwX3LQNM/wbcC3DwLK4Lh9NIUPomIiIiIZFRKrCTTaNsWChSACxdg9mxLyp/AIy80WQd5GkP0dVjbBg5PSvnziIiIiEiGo8RKMg0nJ3jhBfPxyJGOrFuXj7VrLcSkZKV0Z28IXgxBPcCIgc3Pwu73U6DOu4iIiIhkZEqsJFPx9zd/Hj5s4YsvqtCkiRNBQTBvXgqexNEFak6FMm+Zz//5wEywYqNS8CQiIiIikpEosZJMY9486N07/vpTp6Bz5xROriwWqPAhVB0PFgf47wdY2xaiwlPwJCIiIiKSUSixkkwhJgYGD064R17cuiFDSNlugQDFnoN6C8HRA0KXmUUtbpxJ4ZOIiIiISHqnxEoyhfXr4eTJxF83DDhxwtwuxeVrDY1Wg6sfXN5ulmO/uj8VTiQiIiIi6ZUSK8kUQkNTdruHlqsaNN0EXkXh+lEIqQXnNqTSyUREREQkvVFiJZlCQEDKbpcs2YpA0z8gZw2IvAyrGsPxual4QhERERFJL5RYSaZQty7kz2/WlEiMlxfUqZPKgbj5QaOVkL8dxN6CDY/D/jGpfFIRERERsTclVpIpODrCmNv5S2LJVXg4DB+eBsE4eUCduVDsecCA7UNg+8tgxKbByUVERETEHpRYSabRsSPMmQP58tmuDwyEvn3NxyNG3EnAUpWDI1T5Gip+bD7f/wVs7AYxN9Pg5CIiIiKS1pRYSabSsSMcPQohIdEMHfoXISHRHDkCEyfChx+a2wwZAtOmpUEwFguUfg1q/gQOznB8NqxuZo6/EhEREZFMRYmVZDqOjhAcbFCv3imCgw0cHc31b74JL71kPn7mGfj11zQKqFB3qL8MnL3h3DpYXhuuH0ujk4uIiIhIWlBiJVmGxQKffQY9e5oTBT/xBKxZk0Ynz9MQmmwA93wQts+c6+ryzjQ6uYiIiIikNiVWkqU4OMD330O7dnDrFrRtC9u2pdHJfctBsz/BpyzcCIWQuhC6PI1OLiIiIiKpSYmVZDlOTjBzJjRoANeuQfPmsH9/Gp3cI7/ZcuXfAKLDYU0r+G9qGp1cUk1sDJZza8kXvQ7LubUQG2PviERERCSNKbGSLMnNDRYsgMqV4cIFaNoUjh9Po5O7+JhjroK6gxENf/aCfz4Ew0ijACRFnZgHvwbhtLYJVW59gdPaJvBrkLleREREsgwlVpJleXvD0qVQogScOGEmV+fPp9HJHV2g5jQo/br5fPc7sOU5iI1OowAkRZyYB+s7Q8RJ2/URp8z1Sq5ERESyDCVWkqX5+UFIiDnX1YED0KIFhIWl0cktDlBxJFQZZz4+/B2sawdR4WkUgDyS2BjYNhhIqKXx9rptQ9QtUEREJItQYiVZXmCgmVzlymUWsmjXDm6m5Ty+xZ+HuvPA0R1OL4GVDeDG2TQMQJLl/Pr4LVU2DIg4Afs+h/N/wJV/zDL7kZfVMikiIpIJOdk7AJH0oEQJ+P13qF/fLMHepQvMnWsWukgT+dtBo1Wwtg1c+gtCakH9peBdPI0CkIcW/l/Sttv1WsLrHd3BORs4eZtznDlnM386ZbN9ntC6u587ZQMHx5S7rrQUG2MmqDdCwT0A/Opm3GsREZEsT4mVyG2PPQa//QbNmpmTBz/7LPzwg1miPU3kqgFN/oA1LSD8sJlc1fsN/GqmUQDyQLHRcGYlHJkGJ+YkbR+vIoABUWEQdQ1ib5nrY26YC+cePS4nz/skX/dJ2pzuTuCygZOX2S01LZyYZ3alvLvVzyM/VB4DgR3TJgYREZEUlKzE6sSJE1gsFvLnzw/Ali1bmDFjBqVLl6Zfv34pGqBIWgoOhtmzoWNHmDoVcuSAzz83JxdOE97FoOkfsKY1XNoKqxpCrZ8hsH0aBSAJurzLTKaOzoCbZ+6stziZlR0TZDEThdYHbFthYiIh+tqdRCsqzFzuXRfveQKvxUaZx4y+bi53x5ZcTl5Jayl70DZOnon/4cQV/bh3fFpc0Y+6c5RciYhIhpOsxOrJJ5+kX79+9OjRgzNnztCkSRPKlCnD9OnTOXPmDO+++25KxymSZtq2NVuqevaEL7+EnDnhrbfSMAC33NB4NWzoCqcXwfqOUGUsFH8hDYMQIk6ZidTRH+HK33fWu+aEAl2hUA+ztWXD47dfuDtJuJ1QVB4dv2ubows45jSP86hibiU9MbvvNmFg3C6yER1uLjdOP1psFoc7Sdq9XRdDfyfxoh8Ws+hHvnbqFigiIhlKshKrf/75h2rVqgEwe/ZsypYty8aNG1m+fDn9+/dXYiUZ3tNPw+XLMGQIvP222XI1YEAaBuDkCfXmw18D4dAE8+f142YVwbTqqpUVRYXDyflm69SZlVg//Du4QL42ZjIV0MJMjgCobrauJNilbXTqt7o4uoKjH7j5PdpxDANibj44+Uq0Ne2e5M2INZe4dQ8XjFn04/x68K//aNclIiKShpKVWEVFReHq6grAihUraNu2LQAlS5YkNDQ05aITsaPBg+HiRRgxAl54AXx9oVu3NAzAwQmqfgueBWHXm7BvlPmBs8Zk8wO1pIzYGDi7Eo78aHZRi4m485pfHTOZKvA4uGRPeP/AjpCvHdGhq9n551Iq1miBU0CDjNXaYrGAk7u54P9oxzIM8z1MLDE7swqOTH7wcW7o/xIREclYkpVYlSlThvHjx9OqVStCQkIYMWIEAKdPnyZnzhTo3iKSTnzwAVy6BOPGma1Yvr7mXFdpxmKBMm+YLSB/PgPHfjY/cNabDy6+aRhIJnR5t9nN7+gM225vXkXNZKrQU+BVOGnHcnDEyB3MKafrVMgdnLGSqpRmsdwupuEJ7nniv+6RP4mJ1SN2RRQREUljyUqsPvnkEzp06MCnn35Kz549qVChAgC//vqrtYugSGZgscBXX5ndAmfMgE6dzDmvatdO40AK9TDLUa/rCOfWQEgdsxy7Z2AaB5LB3Qg1E6kj0+DK7jvrXXJAwS4Q1MOszphm1UqyIL+6ZnIVcYqEx1ndtmOYObbtsc9TZjyaiIhIKktWYlW/fn0uXLhAWFgY2bPf6R7Tr18/PDw8Uiw4kfTAwQGmTIErV2DJEmjVCtauhdvfJ6SdPI2hyXpY0xKu7oHlNczkKnv5NA4kg4m+Difmm139zq4wx/4AODhD3tZQ6GnI2/KucVOSqhwczZLq6ztjFvlIoOhHQHMIXQZHppqTZlf+ykx8lfCKiEg6lqxR8Ddu3ODWrVvWpOrYsWOMHj2aAwcOkDt37hQNUCQ9cHaGX36BOnXg6lVzrqtDh+wQSPYK0HQT+JQ2u0qtqHu7yILYiI2BMytgU0+Y5w+besCZ5WZSlauWOXatwxmoN88sZa+kKm0FdjSLfnjks13vkd9c32AJNNlo3ue3zsMf3czJs68ft0+8IiIiSZCsFqt27drRsWNH+vfvz5UrV6hevTrOzs5cuHCBL774ggFpWj5NJG14eJgTCNevD7t2QZMmsHEj5M2bxoF4FoAmG2BdBzi31pxQuPoP5pigrO7KP2bL1NHpcOPUnfVehc1ufoWegmxF7Ref3HG76Afn15tdNN0DzG6CcePT/GpC8x2w92PY8z84vRgWl4EKH0Gx57P2ODYREUmXktVitX37durWrQvAnDlz8Pf359ixY0ybNo2vvvoqRQMUSU98feH336FoUTh6FJo2NYtbpDmX7NDgdyjY1ZwkdlMP2DPSrMiW1dw4A/u+gKWVYEk5s3rijVPme1S0v9ny0eYQlH9fSVV64+BollQP6mb+TGjOr3LvQoud4FfbnF9r2yBzjOGVPXYIWEREJHHJSqwiIiLIli0bAMuXL6djx444ODhQo0YNjh07lqIBiqQ3/v5mAYu8eWHPHmjZEsLD7RCIoyvUmg6lXjGf73oTtj4PsdF2CCaNRUeYRShWt4AF+WDHy3B5pzluKn97qDsXOoRCtW/Br5bG5mR0PqWg8Tqo+o05wfDFP2FZJdj9njlJsoiISDqQrMSqaNGiLFiwgBMnTvD777/TtGlTAM6dO4e3t3eKBiiSHgUFwfLl5sTBmzdDx45wyx6f7ywOUGmUObgfCxwaD+s7mgUbMhsj1pwD6c/e5ripP7qbBQ6MWMhZw/zQ3eF2KfrAjprrK7OxOECxAdB6rzlZc2wU/DMcllaE8xvtHZ2IiEjyEqt3332XYcOGERQURLVq1ahZsyZgtl5VqlQpRQMUSa/KlDGrBHp6mi1YPXpATIydginxotlK4+gGp36DlQ3h5jk7BZPCruyBna/DwoKwqhH8N8XsEuZZCMq+C60PQrNN5oduleXO/DzyQ72FUGc2uPlD2H6za+DW5yHyqr2jExGRLCxZxSs6d+5MnTp1CA0Ntc5hBdCoUSM6dOiQYsGJpHfVq8OCBWYJ9l9+McdgTZhgp55ngR2g4UqzetrFLbC8FjRYljHHFd04a06GfORHuLz9znpnXyj4hFmIwq+2uvhlVRYLFHjcnIJgxytweBL8+y2c/BWqjoP87ewdoYiIZEHJSqwA8uTJQ548eTh58iQA+fPn1+TAkiU1bmxOHvzEE/Ddd2b3wI8/tlMwfrWg6R/m2KPww7C8JgQvglzV7RTQQ4i+AScXmpP3nlkOxu3mP4uTOc9UoachXyuzVU4EzAIl1b+HoO6wuR+EH4J17SGwM1QZC+557B2hiIhkIcnqChgbG8vw4cPx8fGhYMGCFCxYEF9fX0aMGEFsbOxDHWvcuHEEBQXh5uZG9erV2bJlS5L2mzlzJhaLhfbt29usNwyDd999l4CAANzd3WncuDH//vvvQ8Uk8rA6dTJbqgA++QQ+/dSOwXiXMOe6ylEZbl2AlQ3Mb/LTIyMWzq6GP5+5PW6qG4QuNZOqnNWhytfmuKnghVCgk5IqSZh/A2i5G0q/DhZHODEHFpUyW7KyYqVMERGxi2QlVm+99RZff/01H3/8MTt27GDHjh189NFHjB07lnfeeSfJx5k1axZDhw7lvffeY/v27VSoUIFmzZpx7tz9x4YcPXqUYcOGWUu+323UqFF89dVXjB8/ns2bN+Pp6UmzZs24efPmQ1+nyMN49lkYNcp8/Oqr8P33dgzG3R8arTFbemJuwPoO8O94OwZ0j6v7YOebsLCQOR7sv8kQfQ08g6DM29D6ADT7E4q/AG657B2tZARO7lBxJDT/y/xSIeoKbH7WHJcXpi/XREQk9SUrsZo6dSrff/89AwYMoHz58pQvX57nn3+e7777jilTpiT5OF988QV9+/ald+/elC5dmvHjx+Ph4cEPP/yQ6D4xMTF0796dDz74gMKFC9u8ZhgGo0eP5u2336Zdu3aUL1+eadOmcfr0aRYsWJCcSxV5KK+8Aq+9Zj5+7jmYO9eOwTh7mYP8izxrtgxtHWAmM/b6Bv/mOTjwFSyrAotLw96REHEcnH2gSF+znHbbw1BhBHgXt0+MkvFlrwhN/4RKn4Gju9kiurQ87PnYrCQoIiKSSpI1xurSpUuULFky3vqSJUtyKYmzpUZGRrJt2zbeeOMN6zoHBwcaN27Mpk2bEt1v+PDh5M6dmz59+rB+/Xqb144cOcKZM2do3LixdZ2Pjw/Vq1dn06ZNdO3aNcFj3rp1i1t31coOCwsDICoqiqgo/UecEcX93uzx+xs+HC5ccGTSJAeefNJg4cIYGjWyY3ekSuNwcMuH454PYO9IYsOPEVN1Iji4pP65Y25gOf0bDsdmYDnzO5bb46YMixNGnmbEFuyOkbf1nS5+0TGAvUorPhp73nOSgKKDIE9rHLcPxOHsCtj1BsbRn4mpMgEjR2V7R5cidM9JWtL9JmktPd1zSY0hWYlVhQoV+Prrr/nqq69s1n/99deUL18+Sce4cOECMTEx+Pv726z39/dn//79Ce6zYcMGJk2axM6dOxN8/cyZM9Zj3HvMuNcSMnLkSD744IN465cvX46Hh8f9LkPSuZCQELuct2VL2LevCn/8kY8OHWD48E0UL37ZLrGYKhHo8iIVI7/B4fgMLp78hy1urxFt8Uz5Uxmx5IzdS2D0GvJG/4ETEdaXLjsU44RTfU451SEyzAf+Bv5elfIx2JG97jlJhPECgS5lKBv5Ay5Xd+O4sjaHnVqz3+VJYiyZY8ye7jlJS7rfJK2lh3suIiLiwRuRzMRq1KhRtGrVihUrVljnsNq0aRMnTpxgyZIlyTnkA127do0ePXrw3XffkStXyo65eOONNxg6dKj1eVhYGIGBgTRt2lQTHmdQUVFRhISE0KRJE5ydne0SQ9Om0KFDLCtWOPHxx3VZuTKaMmXsEsptLYk90wzLpq74Re+mpfNIouv8as4LlBKuHcDh2HQcjv2M5eYx62rDoyCxBbsRW+BJvLxLUgoolTJnTFfSwz0niWkFN18hdufLOJyYRdHoXynispuYx8Zh5Gli7+CSTfecpCXdb5LW0tM9F9eb7UGSlVgFBwdz8OBBxo0bZ21d6tixI/369ePDDz9MsKjEvXLlyoWjoyNnz561WX/27Fny5IlfIvfw4cMcPXqUNm3aWNfFVSB0cnLiwIED1v3Onj1LQECAzTErVqyYaCyurq64urrGW+/s7Gz3X6Q8Gnv+Dp2dYf58aNIE/vzTQqtWzmzcCEFBdgnHFNgKPNfBmpZYrv6D8+p6UH8p+JZN3vFunodjM835pi5tvbPe2ducZyioB5bcdXG0OOCYMleQ7unfjXTKOR/UnQmnnoat/bFEHMVpfSuzjP9jX2ToyaV1z0la0v0maS093HNJPX+y57HKmzcv//vf/2zW7dq1i0mTJjFx4sQH7u/i4kLlypVZuXKltWR6bGwsK1euZODAgfG2L1myJH///bfNurfffptr164xZswYAgMDcXZ2Jk+ePKxcudKaSIWFhbF582YGDBiQvAsVeQReXrB4MdSrB3v2mEnWhg1wT2/VtJWjkllxb3ULCNsHIXWg3nyzZHVsDJxfDzdCwT0A/OqCwz0pUcxNOPWbmUydXgpGtLne4ggBzW/PN9XGrNImkt7kawm598Cut+HgWHPetNNLofJoKNhNk06LiEiyJTuxSglDhw6lZ8+eVKlShWrVqjF69GiuX79O7969AXj66afJly8fI0eOxM3NjbJlbb9V9/X1BbBZP2TIED788EOKFStGoUKFeOedd8ibN2+8+a5E0kqOHLB8OdSuDYcOQbNmsGYN3L597cOzIDTZYE6men49rG4GxV4w5/+JOHlnO4/8UHkM5G8P5zeaH0KP/wJRV+9sk6MKFOoBBbuCW+60vhKRh+ecDaqMgaBuZkn2q3vgj+5w5Ceo9q359yEiIvKQ7JpYdenShfPnz/Puu+9y5swZKlasyLJly6zFJ44fP46Dw8NVhH/11Ve5fv06/fr148qVK9SpU4dly5bh5pY5BilLxpQ3L4SEQJ06sGsXtGkDv/8Odq2N4poDGi6HTU+bydKB0fG3iTgF6zuBqx/cOn9nvUcgBD1lJlQ+mXHElGQJuWpA8+2wbxT8M8KcnHpxGajwkflFw72ttSIiIvdh18QKYODAgQl2/QNYs2bNffdNaM4si8XC8OHDGT58eApEJ5JyihY1W67q1TO7Az7+OCxYYI7FshtHN6g53ewKFR2ewAa3y8TfOg+OXlDwcbOrX+56YEnWNHgi6YujC5R9GwI7w5a+cH4DbBsMR2dA9e+TP/5QRESynIdKrDp27Hjf169cufIosYhkeuXLm2OumjSBJUugVy/48Ud4yIbZlHVhYyJJ1T3q/gJ5m6d+PCL24FMSGq+FQxNhx6twcTMsrQSlX4eyb92Za01ERCQRD/VxzsfH575LwYIFefrpp1MrVpFMoXZtmDsXnJxgxgwYNAgMO84fzI3QpG0Xac95uETSgMUBivWH1vsgfzuzMMueD2FpRTi3/oG7i4hI1vZQLVaTJ09OrThEspQWLWDaNOjeHcaNg5w5IYE5qtOGe8CDt3mY7UQyOo98UHc+nJgHfw2EsAOwoh4UfQ4qfgIuPvaOUERE0iENkhCxk27dzKQKYPhwGDPGToH41b09SXBiZaYtZrEKvwfPTyeSaVgsUKATtN4LRfqa6w5NgMWl4cQCu4YmIiLpkxIrETsaMABGjDAfDxlitmKlOQdHs6Q6ED+5uv288mhVSJOsySU7VJ8IjVZDtmJw4zSs7wDrOye9G62IiGQJSqxE7Oytt8ykCuCZZ+DXX+0QRGBHqDvH7AJ1N4/85vrA+xeuEcn0/OtDi11Q+g1zMuwTc2FRKTj0vZ0HScpDiY2Bs2vg6M/mz9gYe0ckIpmI3cuti2R1Fgt8/jlcvgxTp8ITT8CyZVC/fhoHEtgR8rUzJwy+EWqOqfKrq5YqkThO7lDxIyjYxZxY+NJfZon2oz9BtYngXdzeEcr9nJhnltJPaBJ0fXkkIilALVYi6YCDA3z/PbRrB7duQdu2sG2bPQJxNL+ZD+pm/lRSJRJf9grQdBNU+hwcPeDcWlhSHvaMhNgoe0cnCTkxz+y+eXdSBbcnQe9svi4i8oiUWImkE05OMHOm2VJ17Ro0bw4HDtg7KhFJkIMTlBoKrf6BPE0h9hbsehOWVYGLW+0dndwtNsZsqSKhLpu3120bom6BIvLIlFiJpCNubrBwIVSuDBcumBMJnzhh76hEJFFehaDBMqj5I7jmhCu7YXkN2DYUoq/bOzoBs3vzvS1VNgyIOGFuJyLyCJRYiaQz3t6wdCmUKGEmVU2bwvnz9o5KRBJlsUChp6DVPgjqDkYsHPgSFpeF07/bO7qs6eY5OLUYdr8P215K2j6q8igij0jFK0TSIT8/CAmB2rVh/35zQuFVq8ykS0TSKTc/qPWTmVxt6Q/Xj8Ka5hDUAx77Atxy2TvCzCkqDC5tg4tbzG6YF7dCxPGHP871o2ZSbNF3ziKSPEqsRNKpwEAzuapTxyxk0b49LFlidhcUkXQsbwtotQd2vw0HvoKjP0LoUnhsNAQ9abZwSfLE3ITLO+8kUJe2QtgB4o+fsoB3SchZFbJXhj3/g1vnE9juLrvehMPfQ7EBUPgZcM2RetchIpmSEiuRdKxECbP0eoMGsHo1dO0Kc+aYhS5EJB1z9jIn1i7YzSzNfvUf2PTU7dLs48GzoL0jTP9io+HqXjN5ikukruwGIzr+tp4FIUdVM5HKWRVyVAbnu5r4PfOb1f+wYJtc3U5y87Uxx1iF/wc7XoHd75i/u+IvmMcSEUkCfTwTSecqV4bffoNmzczCFn37wqRJZol2EUnnclWH5ttg36fwz3AIXQaLy0D5/0HxgZrSII5hQPjhO935Lm2FSzsgJiL+tq5+txOoareTqSrglvv+x4+bBD3BeaxGm69HR8Cxn+HgOLi8A/6bbC45a5gJVoHHwdE1RS9bRDIXJVYiGUBwMMyeDR07wpQpkD27OamwehSJZACOLlD2LSjQGbb0g3PrYPsQODYDqn0H2cvbO8K0F3HqTgJ1cas52XLk5fjbOWUzE6e7W6M8CiTvH78HTYLu5AFF+pjdAC/8Cf+Og+Oz4eKfsOlP2D4UijwLxfqDZ4FHu34RyZSUWIlkEG3bwg8/QM+e8OWXkDMnvPWWvaMSkSTzLgGNVpvjeHa8YrbOLKsMpV+Dsm+DYyYdQHnrkpk4XdxqXvOlrQlX4HNwhewVb3flu90i5V08ZYtJxE2Cfj8WC/jVNJdKn5u/r0PjzZauvSNh3ydm18HiA8G/kb7hEhErJVYiGcjTT8PlyzBkCLz9NuTIAQMG2DsqEUkyiwMU7Qd5W8NfA+HkfLOwwvFfoNpE8A+2d4SPJvo6XNpu2xoVfjj+dhYH8Cl7VxJV1Xzu6JL2Md+Pu7/Z2lj6NTj1m9lN8OxKOLnQXLxLQLHnoVBPcPGxd7QiYmdKrEQymMGD4eJFGDECXnjB7BbYtau9oxKRh+KRF+rNgxPzzATr2kFYWd9Muip+Ai6+9o7wwWIi4erfthX6ru4xS5bfy6voXYUlqkKOSuDkmfYxJ5eDEwR2MJer++Dfb+C/qWZFwm2DzYqCQU+ZY7F8y9k7WhGxEyVWIhnQBx/ApUswbhz06AE+PuZcVyKSwQR2BP+GsPM1ODTRXE79BlXGmR/i0wsj1kwi7i4ucXkXxN6Kv617XrMbn7U1qgq4ZE/7mFOLTymoMhYqfGRWeTw4zkwoD00wl9z1oNgL5u/Pwdne0YpIGlJiJZIBWSzw1VdmcvXzz9Cp050JhUUkg3HxhWoToOCTsKUvXPsX1nc0k67KY83WrbRkGHD9mG2Z80vbIPpaArFnv6fMedW0j9denLOZc14V7Q/n1poJ1sn5ZnGSc+vM4hhFnzNbId0D7B2tiKQBJVYiGZSDA0ydClevmhMHt2oFa9dChQr2jkxEksU/GFruhn9GwN5RZjfBMyuh0iizGl1KFnG4281ztt35Lm69PZnuPRw9IMdjdyVS1cCrsIo3WCxmQQz/+ma1w0MTzZarG6Hw9/vwz4dmklz8BbMKYVZ/v0QyMSVWIhmYszP88os5x9WGDXd+Fi1q78hEJFkc3aDC/6BAF3Ni4UtbYctzcHS6WdzCu4S5XWwMlnNryRe9Dss5TwhokLQ5saLCzNanuC59F7dCxPH42zk4g29529Yo71LmWCNJnEc+KP8BlHnLTIz/HQfnN5hl24/PNsdfFXveHI/l7GXvaEUkhelfSJEMzsPDnEC4fn3YtQuaNIGNGyFvFumNI5IpZS8PTTfBwbGw6y2za9mSClD2HchWDHa8jFPESaoArP3i9kS3Y8yWkTgxN+HyTtvWqLADgHHPySzgXdK2Ql/2Cpm3/HtacHSBoK7mcnmXWeziyE9w5W/YOsAcU1eoFxR//k6yLCIZnhIrkUzA1xeWLYM6deDwYWjaFNatM8uxi0gG5eAIJYdA/vawtT+E/g67305424hTsL6zOXmtEWu2SF35G4zo+Nt6FjS78cUlUTkeA2fv1LySrC17BXMMXcVP4L8pZpJ17V84+JW55GlsFrvI11otgiIZnP6CRTKJPHnMAhZ16sCePeaYq5AQ8FJvE5GMzSsI6i81Wzz+7AUkUM48rhXq329tV7vlviuBuv3TzS9145WEufiaiXKJQXBmBRz8Gk4tMh+fWQEeBczEuMiz+h2JZFBKrEQykUKFYPlyqFcP/vwTOnY0uwm6uto7MhF5JBYLeAaScFJ1jwJdoUBnM4nyCFSxhPTG4gABTc0l/CgcGg+HvzfHuu160yx4UeAJKD7QbFnU708kw0ilEkMiYi9lyphVAj09zRarHj0gJsbeUYnII7sRmrTt8reFAp3As4A+lKd3XkFQ8WNofxJqTDVbFWMjzfmxlteA36vC4ckQfcPekYpIEiixEsmEqleH+fPvVA0cMMCcmkZEMrCkzoWkOZMyHkc3KPw0NN8CzbZAoZ7g4GpWcNz8DCzIDztegfD/7B2pPIzYGDi7Bo7+bP6M1becmZ0SK5FMqkkTmDHDnO/qu+/gzTftHZGIPBK/umb1PxJrhbKYXf/86qZlVJLSclaFmlPMVqyKn5jFRiIvwb7P4NeisKY1nF5qFimR9OvEPPg1CFY2gD+eNH/+GmSul0xLiZVIJta5M0yYYD7++GP49FP7xiMij8DB0SypDsRPrm4/rzw6afNZSfrnlgtKvwptDkO9XyGgGWDA6cWwpiX8Vhz2fQ63Ltk7UrnXiXlmlc6Ik7br46p3KrnKtJRYiWRyzz4Ln3xiPn71VZg0yb7xiMgjCOwIdeeYE9HezSO/uf7ueawkc3BwhPxtoMEyaH0QSrwEzj4Qfhh2DDO7CW5+Fi7tsHekAmZ3v22DiT9fHHfWbRuiboGZlKoCimQBr74KFy/CqFHQrx9kz25WDBSRDCiwI+RrR3Toanb+uZSKNVrgFNBALVVZgXcxqPwFVBgBR2fAwXFwZRccnmQuuWqac2IV6AyOKgeb6qJvmOPewv8zE93w/8w55O5tqbJhQMQJOL8e/OunVaSSRpRYiWQRH38Mly7B999Dt26weDE0bmzvqEQkWRwcMXIHc8rpOhVyByupymqcPKFoX3POqwt/mHNiHZ8DFzaZy46hUKQvFH3udpl+SRbDgFvn4drhu5Knux4ntVJnQq7uV2KVCSmxEskiLBYYPx6uXIE5c6B9e1i50qwgKCIiGZDFAn61zeWxL+HQd3BoAtw4BXv+B3s/hnxtofgL4N9Q5fcTEhMJ14/ZtjpZf/4H0eH339/ZB7yKgFdhyFYEYqNg/xcPPu+2QXB1N5R6BbwKpcy1iN0psRLJQhwd4aef4OpVc46rli1h3Tpz7isREcnA3PNAuXegzOtw8lezFevcGjg531y8S0Gx582y7s7e9o42bUVeNpOka/cmTofNbnn3rbBoMccw3p08ed7+6VUYXHLYJqyxMXB8tlmoIsFxVoCDizlf2b/fwqGJULArlH4dfMum5FWLHSixEsliXF1h3jyzG+DmzdC0KWzcCEFB9o5MREQemYOzOUF0gU5wZQ/8+w0cmQZh+2Dbi7DrDSjUwxyL5ZtJvlWLjYEbJxNPniIv339/Rw8zSfIqbJtAeRUGz6CHG68WV71zfWfMap13J1e3E7BaM8A1J+wZCWeWw9Hp5pK3NZR5A/xqPdz1S7qhxEokC/LygiVLoF492LPHnPNqwwbIlQvWr4fQUAgIgLp1zVYuERHJgHzLQNVxUHEk/DcN/h0HYfvNlpJ/v4Xc9c1ugvnbmQlZehYVDtePJJw4XT9qdsG7H7c8CSdOXkXAzT9lu0nGVe/cNti2kIVHfnNKhLjqnf714dJ2s8vm8TlwepG55K5ntmAFNFf3zQxGiZVIFpUjByxfDrVrw6FD5lirqCg4ffrONvnzw5gxqiAoIpKhOXtDiYFmEnV2tZlgnVxodhU8twbc85qFLor2M7sU3is2Bsu5teSLXoflnCekRhVKw4CbZxJOnML/g5tn77+/gzN4FkokeSpsFvxIS7erd3J+vVnkwj3AnLz73vctx2NQZzaEHYR9o8zWxXPrzCV7RTPBCuysAjUZhBIrkSwsb15zrFWVKnDsWPzXT50yJxmeM0fJlYhIhmexQJ6G5hJxEv6dAIcnwo3T8Pd7sOdDCOxkdhP0q21uf2IebBuMU8RJqgCs/eJ2y8uYh583LeaW2bqUWPIUc+P++7vkSLzVyT1f+ks+HByTXvnPuzhU/x7KvQ/7vzSLkFzeCRu7gldRc7LoQk+rjH46p8RKJIsrVAjc3MyCFvcyDPP/1SFDoF07dQsUEck0PPKb82GVfRtOzDXnxLrwBxybaS6+5c15sQ5NJF4RhohT5hiieyelNgyIvJR44hRxMv6x7mZxAI8CCSdOXoXBxTcV3oh0xiM/PPY5lHnTLEBy4CsIPwRb+pnJb8mhZuuiczZ7RyoJUGIlksWtXw9n79PDwjDgxAlzu/r10ywsERFJC46uEPSkuVzaYXYTPDoDruw2lwTdTo42PwvnN5ljn+ISqKiw+5/PyfN2opRAlT2PAuDokqKXl2G55oRy70GpYWYZ/f2fm4npjldgz0dQfCAUHwRuuewdqdxFiZVIFheaxPkNu3SBBg2galVzeewxswiGiIhkEjkqmd3RKn0KO9+CQ9/ef/vIy7D/s/jr3fPeSZzubX1y9VNBhofh5Aklh5il8o/+BHs/gWsH4Z8RsO8zcyLoUi+DZwF7RyoosRLJ8gICkrbduXMwa5a5ADg4QKlSdxKtqlWhfHmznLuIiGRgLtkhd90HJ1YAeZpB3hZ3lScvBE7uqR9jVuPoAkWegUI94eQC2DsSLm2Dg1+ZJfULPQWlXgWfUvaONEtTYiWSxdWta1b/O3XK7PZ3L4vFLHLx/fewfTts3Woup06Zpdr37IEpU8xtnZ3N5OruZKt0aY3NEhHJcNyT+K1bmdeTXqBBHp2DozlHWWBHOLPCLNV+dhX8NwX+mwr525tzYeWsau9IsyQlViJZnKOjWVK9c2czibo7uYrrrfHVV9C8ubnECQ01E6y//rqTbF28CNu2mcv48eZ2Hh5mt8G7k60iRdQTREQkXfOraxZSiDhFwgUnLObrfnXTOjIB8z/RgCbmcmGzmWCdXAAn55uLf6PbSW8j/YebhpRYiQgdO5ol1QcPhpN3zWWYPz+MHp1wqfWAAGjb1lzATMiOHr2TZG3daiZY4eHm5MMbNtzZN3t2s8T73clWvnypeYUiIvJQHBzNkurrOwMWbJOr2x/UK49OfyXOs6Jc1aHefLi61xyDdXQGnF1pLjmqmglW/vZm1UVJVUqsRAQwk6d27czqf6GhZuJUt27Su/FZLGbp9kKF4IknzHUxMXDggG2ytXMnXL5szp8VEnJn/4AA20SrShXImTPFL1NERJIqsKNZUn3b4Nul0m/zyG8mVQ87j5WkLp/SUHMqlB8O+z6Hw9/Dpa2wvhN4l4BSr0FQd1VeTEVKrETEytExZUuqOzqaY6xKl4aePc11kZHw99+2ydaePWYy9+uv5hKncOE7SVbVqlC5sioRioikqcCOkK8d0aGr2fnnUirWaIFTQAO1VKVnngWhyldQ9h1zHqyDX0PYAdj8zO25sF6Gos+aFQclRSmxEpE05eJiJkiVK0P//ua669dhxw7bZOvQIfjvP3OJq0RoscSvRFihgioRioikKgdHjNzBnHK6ToXcwUqqMgo3P3MS6NKvwL8TYP8XEHECtg+BPSPMebCKDwTXHPaONNNQYiUidufpCXXqmEucy5fvFMaI+3nyJOzday5Tp5rbqRKhiIjIfTh7m8lViRfNyoH7RpkTOv/9Huz7FIo+ByWHgkdee0ea4SmxEpF0KXt2aNLEXOKEhtpWIVQlQhERkSRydINiz0GRPnB8jllJ8Mou2P85HBwLhZ4258LyLmbvSDMsJVYikmEEBECbNuYCqkQoIiLy0BycIKgrFOwCoctgz0g4v94sdvHfDxDYGUq/Djkq2TvSDEeJlYhkWClRifDeZCs5lQhjYmDtWgvr1uXD09NCgwbqiigiIumcxQJ5W5jL+Y1mgnV6MRyfbS4Bzc0EK3c9dflIIiVWIpKpPGwlwt9+M5c4hQrZJlqPPQbZsiV+vnnz4ub/cgKq8MUX5vxfY8YkPP+XiIhIuuNXG+ovgsu7zbmwjs80W7NCl0GumlD6DcjXSnNhPYASKxHJ9B6mEuGRI+Yye7a53f0qEc6bB507m10S73bqlLl+zhwlVyIikoFkLw+1p5vVBPd+Cv9NhgubYF1b8CkLpV+Dgl3N7oQSj94VEcmSEqtEuG2bbbKVWCXCcuXMLof3JlVgrrNYYMgQc9JldQsUEZEMxaswVPsWyr0HB0bDwW/g6j+wqQfsfgdKvQKFe4OTu70jTVeUWImI3JY9OzRubC5xEqtEuH37/Y9lGHDiBKxfn7KTLouIiKQZ9zxQ8WNzrNW/38D+0XD9KPz1AvzzAZQYAsWeBxcfOweaPqijpIjIfcRVIhw+HJYuhfPnzUmLBw1K2v5t20KDBvDiizBhAmzcCFeupGrIIiIiKcvFF8q8Ce2OQpWvwbMg3DwHu96EhQVg5xtw46y9o7Q7tViJiDyEuEqEHTrAV189ePtr12DNGnO5W/78ULYslClj/ixb1hzL5emZGlGLiIikACcPKP4CFO0Hx2aac2Fd3Wv+3P8lFHnG7CboVcjekdqFEisRkWSoW9dMjk6dSniclcVizpM1dy7s2wf//HNnOXnyzrJsme0+hQvfSbTiluLFzQIcIiIi6YKDMxTqAUHd4dQis1T7xT/h32/h0ESzwEXp18G3rL0jTVNKrEREksHR0Syp3rmzmRDdnVzFTfcxZgxUq2Yud7tyxSz3/s8/d37+/TdcuACHD5vLwoV3tndyMpOrexOuwoVVGENEROzI4gD520K+NnBurZlgnVkOR6ebS97WUOYN8Ktl70jThBIrEZFk6tjRLKluzmN1Z33+/DB6dOKl1n19oXZtc7nbuXO2LVtxSVdY2J3KhHFl4AHc3Mz5uuISrbhuhYGBmstRRETSkMUC/vXN5dJ2s2vg8TlwepG55K5ntmAFNM/U/0EpsRIReQQdO5ol1Vevjmbp0p20aFGRBg2cktWSlDs3NGxoLnEMw0za7k64/vnHTLJu3jSrE95bodDb23bsVtySO/ejXauIiMgD5XgM6syGsIOwbxQcmQbn1plL9opmghXYGRwyX5cLJVYi/2/v3uN0LvM/jr/vuedgZgw5zVlrnCUhU84h5LBbhCKKdNqKjaYTyili2bLUhlLKUlQW+Yna2VEO5RQRS3IMwzibMYMxZu7fH9fOmHsOTO6Z+ztzz+v5eHwfM/f3/t73fG5z7ebtuq7PF3CR3S61aeNQSkq82rRpWKjL82w2MwNVtarUpcvV8+nppjth5qxW5rF7t5nhWrfOHNlVqZI7cNWvb2bQAAAoVOVqS00/kBqMMY0t9r4nnd0qfd9HKltTuuVlKaq/ZPezutJCQ7ACgBLIbpdq1TJH9+5Xz1++LP36a+7lhPv2mVbx1+pQmH054S23SAEBbvxAAADPFBAp3f6Wadf+6z+k3W9LyXuljU9J20dLdWOkmn+WfIKuviYjXbYTqxRxZbVsJwKlsHYlYoaLYAUAHsTX92pIyu7ChdzdCelQCABwG79KUoPRUr0Xpb2zpF/eki4ckX56SfrvBKn2YKn2c9LJ1dLmIfK+cETRkrRqiglnTaZJVfPZvFxMEKwAoBQICJCaNDFHdufOmf1a2cPW9ToU1qmTe0nhjXQoTE+X1qyRjh0zN2Ju3ZouhwDg8bwDpbpDpVrPSgfnSTsnSed/lXaMM99nXM79mgvx0ppeUuuFxTpcEawAoBS76SapRQtzZJfZoTDnHq6kJHPuv/91rUPhokV5d1OcNi3/booAAA9i9zU3FI4aIB1ZYmatzm7J52KHJJu0eagU0a3YLgskWAEAciloh8LMkPV7OhT+9pv0+OO5b6wcH2/uC7ZwIeEKAEoNL7t0c0/Jt6K08u5rXOiQLhyWTq4xbd2LIYIVAKBArtWh8MCB3Pu3rtWhMC8Oh/kZQ4eaFvYsCwSAUuRSQsGuu3isaOtwAcEKAOASu12qWdMcOTsU7tnjHLY2bpSOHs3/vRwO6fBhs/eqbduirhwAUGz4hxXudRYgWAEAioSvr1kGWL++1Lu3OTd/vtS37/Vfe6z4/oMkAKAoVGltuv9diJfZU5WTzTxfpbW7KyswL6sLAACUHmEF/IfGgl4HAPAQXnbTUl2SlLPr0f8eN5labBtXSAQrAIAbtW5tuv/l1Skwk81m7rsFAChlqvYwLdUDIpzPB0QW+1brEsEKAOBGdrtpqS7lDleZjx0O6b77pPfec29tAIBioGoP6b6DutImVj/6xehKm1jpvgPFPlRJBCsAgJv16GFaqkfk+AfJyEjps8+k/v1Np8Gnn5ZeeknKyLCmTgCARbzscgS3Ubz3XXIEtynWy/+yo3kFAMDtevQwLdXXrDGNKsLCzDJBu1164AHTYXDUKOnNN6X9+6W5c6WAAKurBgAgfwQrAIAl7Pa8W6rbbNLIkVKNGtLAgdKiRaYF+9KlUmio28sEAKBAWAoIACiW+vaV4uKkSpWkTZukZs2k//7X6qoAAMgbwQoAUGy1aiWtWyfVqiX99pvUooUUG2t1VQAA5EawAgAUa7VqmXDVurWUlCR16SLNmmV1VQAAOCNYAQCKvUqVzExVv36mY+BTT0nDhtExEABQfBCsAAAlgp+f6Q44Zox5PGmS1Lu3dPGipWUBACCJYAUAKEFsNmn0aBOwfHzM/bDatZNOnLC6MgBAaUewAgCUOA8/LP3nP1LFitKGDVLTptLOnVZXBQAozQhWAIAS6a67TFOLmjWlgwdNx8C4OKurAgCUVgQrAECJVbu2CVctW0qJiVLnztLs2VZXBQAojQhWAIASrXJlsyywb1/pyhXp8celESPoGAgAcC/Lg9W7776ratWqqUyZMmratKk2btyY77WLFi1SdHS0brrpJgUGBqpRo0aaO3eu0zWPPvqobDab09G5c+ei/hgAAAuVKSPNmyeNGmUeT5woPfQQHQMBAO5jabD67LPPFBMTo9GjR2vLli1q2LChOnXqpBP5tHeqWLGiXn31Va1bt04///yzBg4cqIEDB+qbb75xuq5z5846duxY1jF//nx3fBwAgIVsNmnsWGnOHNMx8PPPpfbtpZMnra4MAFAaeFv5w6dMmaInn3xSAwcOlCTNnDlTX331lWbPnq1hw4blur5t27ZOj4cMGaI5c+Zo7dq16tSpU9Z5Pz8/hYaGFriO1NRUpaamZj1OSkqSJKWlpSktLe33fCQUE5m/N35/cBfGXPHx0ENSeLhNDzxg17p1NjVr5tCSJVdUt67VlRUuxhzcifEGdytOY66gNdgcDoejiGvJ0+XLlxUQEKCFCxeqe/fuWecHDBigc+fO6csvv7zm6x0Oh1auXKn77rtPS5YsUceOHSWZpYBLliyRr6+vKlSooLvvvlvjx49XpUqV8n2vMWPGaOzYsbnOf/rppwoICLixDwgAsNSRI2U1blwzHT8eqMDAyxo2bJMaNDhldVkAgBLmwoUL6tu3rxITE1WuXLl8r7MsWB09elQRERH64Ycf1Lx586zzL7/8slatWqUNGzbk+brExERFREQoNTVVdrtd06dP12OPPZb1/IIFCxQQEKCoqCjt27dPI0aMUNmyZbVu3TrZ7fY83zOvGauqVavq1KlT1/zDQ/GVlpam2NhYdezYUT4+PlaXg1KAMVc8nTwp9exp1/r1XvL2dmjmzHT172/Jf/YKHWMO7sR4g7sVpzGXlJSkypUrXzdYWboU8EYEBQVp69atSk5OVlxcnGJiYlS9evWsZYJ9+vTJurZBgwa67bbbVKNGDX333Xdq3759nu/p5+cnPz+/XOd9fHws/0XCNfwO4W6MueIlPFz69lvp0Uelzz6z6YknvHXwoPT662ZPlidgzMGdGG9wt+Iw5gr68y1rXlG5cmXZ7XYdP37c6fzx48evuT/Ky8tLNWvWVKNGjfTCCy+oV69emjhxYr7XV69eXZUrV9bevXsLrXYAQMlRpoz06afSq6+ax+PHS/36SZcuWVsXAMCzWBasfH191aRJE8XFxWWdy8jIUFxcnNPSwOvJyMhwWsaX05EjR3T69GmFhYW5VC8AoOTy8jKBavZsydtbmj9f6tBBOsWWKwBAIbG03XpMTIxmzZqlOXPmaNeuXXrmmWeUkpKS1SWwf//+Gj58eNb1EydOVGxsrPbv369du3bprbfe0ty5c/Xwww9LkpKTk/XSSy9p/fr1OnjwoOLi4tStWzfVrFnTqWsgAKB0GjhQ+uYbqXx56fvvpWbNpN27ra4KAOAJLN1j1bt3b508eVKjRo1SQkKCGjVqpK+//lohISGSpEOHDsnL62r2S0lJ0bPPPqsjR47I399fdevW1bx589S7d29Jkt1u188//6w5c+bo3LlzCg8P1z333KNx48bluYcKAFD63H23tG6d1LWrtG+f1Ly5tHix1KaN1ZUBAEoyy5tXDB48WIMHD87zue+++87p8fjx4zV+/Ph838vf3z/XzYIBAMipXj1pwwapWzdp/XqpY0fpww+lRx6xujIAQEll6VJAAACsEhwsrVwpPfCAlJYm9e8vjR4tWXMTEgBASUewAgCUWv7+0oIFUuZ23tdfN7NW1+iJBABAnghWAIBSzctLmjBB+uAD0zHwk0/M0sDTp62uDABQkhCsAACQ9Pjj0ooVUrly0po1pqnFnj1WVwUAKCkIVgAA/E+HDtIPP0h/+IMJVc2amZAFAMD1EKwAAMimfn3TMfDOO6UzZ0zY+uQTq6sCABR3BCsAAHIICZG+/Vbq2VO6fFl6+GHT2IKOgQCA/BCsAADIQ0CA9Pnn0ssvm8ejR0sDBtAxEACQN4IVAAD58PKSJk2S3ntPstuluXOlTp3MEkEAALIjWAEAcB1PPSUtXy4FBUmrVpmOgXv3Wl0VAKA4IVgBAFAA99xjOgbefLP066+mY+D331tdFQCguCBYAQBQQLfeajoGRkebGwjffbc0f77VVQEAigOCFQAAv0NoqFkOeP/9pmNg377SG2/QMRAASjuCFQAAv1NAgPTFF9ILL5jHr70mPfaYCVoAgNKJYAUAwA2w26U335RmzDDff/yx1LmzdPas1ZUBAKxAsAIAwAVPPy0tW2Y6Bn77rekYuH+/1VUBANyNYAUAgIs6d5bWrpWqVpV275aaNjUdBAEApQfBCgCAQnDbbaZjYJMm0qlTpmPgZ59ZXRUAwF0IVgAAFJKwMNMxsFs3KTVV6tNHmjiRjoEAUBoQrAAAKESBgdK//iU9/7x5PGKE9MQTUlqatXUBAIoWwQoAgEJmt0tTpkj/+Ifk5SXNnm32YZ07Z3VlAICiQrACAKCIDBok/d//SWXLSitXSi1aSAcOWF0VAKAoEKwAAChCXbuajoEREdKuXaZj4Pr1VlcFAChsBCsAAIpYw4amY2DjxtLJk1K7dtLChVZXBQAoTAQrAADcICJCWr1a+tOfpEuXpAcekCZPpmMgAHgKghUAAG5Stqy0ZIn03HPm8SuvSH/+Mx0DAcATEKwAAHAju12aNs0cXl7SrFnSH/8oJSZaXRkAwBUEKwAALPDcc9KXX5r7XsXGmo6BBw9aXRUA4EYRrAAAsMif/iStWSOFh0s7d0rNmkkbN1pdFQDgRhCsAACwUOPGpmNgw4bS8eNS27bSokVWVwUA+L0IVgAAWCwy0sxcde0qXbwo9eolvfkmHQMBoCQhWAEAUAwEBZk9V4MGmUD10kvSM8/QMRAASgqCFQAAxYS3t/TOO9LUqZLNJr33ntmHRcdAACj+CFYAABQjNps0ZIi531VAgPTvf0utWkmHDlldGQDgWghWAAAUQ/fdJ61eLYWFSTt2SE2bSj/+aJ5LT5dWrbJp9eoIrVplU3q6tbUCAAhWAAAUW02amI6BDRpICQnSXXdJr7wiVasmdezorSlTotWxo7eqVaOTIABYjWAFAEAxVrWqtHat1Lmz6Rg4ebJ05IjzNfHxppMg4QoArEOwAgCgmCtXzuy5CgzM+/nMtuxDh4plgQBgEYIVAAAlwLp1UkpK/s87HNLhw+Z+WAAA9yNYAQBQAhw7VrDrvvpKSk0t2loAALkRrAAAKAHCwgp23ZtvSsHBUv/+0tKl0qVLRVsXAMAgWAEAUAK0bi1FRpr7XOWnbFkTwJKSpLlzpW7dTMh6+GHpyy8JWQBQlAhWAACUAHa7NG2a+T5nuLLZzDFnjukYuGaN9NxzUni4dP689MknUvfuJmT162caYRCyAKBwEawAACghevSQFi6UIiKcz0dGmvM9ekheXlKrViaEHT5sWrUPGWJec/689Omn0v33S1WqSH37SosXmzbuAADXEKwAAChBevSQDh6UYmOvKCbmR8XGXtGBA+Z8Tl5eUsuW0tSp0qFD0g8/SM8/b+6NlZwszZ9vXhccLD30kLkPFiELAG4MwQoAgBLGbpfatHHorrvi1aaNQ3b79V/j5SU1by5NmWKC2bp1UkyMdPPNJmQtWCD17Glmsvr0MTNgFy4U+UcBAI9BsAIAoJTx8pKaNZPeesuErPXrpRdekP7wB3OvrM8+kx54wISsBx+Uvvji2vfQAgAQrAAAKNVsNqlpU9Om/cABacMG6cUXpWrVzIzVF1+YcBUcbMLW558TsgAgLwQrAAAgyYSsO++U/vY3af9+adMm6eWXpagoE7IWLpR69zYzWb16mZmt5GSrqwaA4oFgBQAAcrHZpOhoadIkad8+6ccfpVdekapXNw0u/vUvsxerShWzN2vBAkIWgNKNYAUAAK7JZpOaNJH++ldp715p82Zp2DCpRg1zP6xFi0xXwSpVTJfB+fNNa3cAKE0IVgAAoMBsNun226WJE6U9e6QtW6Thw6WaNU3IWrzY3B+rShVzU+JPPpGSkqyuGgCKHsEKAADcEJtNatxYmjBB+vVXaetW6dVXpdq1pdRU6csvpYcfNo0vunWT5s0jZAHwXAQrAADgMptNathQGj9e+uUXads26bXXpDp1TMhaulR65BEzk3XffdLcuVJiotVVA0DhIVgBAIBCZbNJt90mjRsn7dol/fyzNHKkVLeudPmy9H//J/Xvb2ay7r1X+uc/pXPnrK4aAFxDsAIAAEXGZpMaNJBef13auVPavl0aNUqqV8+ErGXLpAEDTMj64x+ljz+Wzp61umoA+P0IVgAAwC1sNunWW6WxY03I+u9/pTFjpPr1pbQ0aflyaeBAKSRE6tpV+ugjQhaAkoNgBQAALHHLLdLo0dKOHSZojR1rgldamrRihfTYY2Ymq0sXafZs6cwZqysGgPwRrAAAgOXq1TNLBLdvN/uyXn/dLCG8ckX6+mvp8cfNTFbnztKHH0qnT1tdMQA4I1gBAIBipW5d0+zi559Nh8Fx40wzjCtXpG++kZ54woSsTp2kDz6QTp2yumIAIFgBAIBirE4d07Z92zZp927pjTekRo2k9HTp3/+WnnxSCg2VOnaU3n9fOnky//dKT5e++06aP998TU9304cAUCoQrAAAQIlQu7Y0YoT000/mhsQTJpgbFKenS//5j/TnP0thYVKHDtJ77zmHrEWLpGrVpHbtpL59zddq1cx5ACgMBCsAAFDi1KolDR8ubdki7dkjTZwo3X67CVlxcdLTT5uZrPbtTeDq1Us6csT5PeLjzXnCFYDCQLACAAAlWs2a0rBh0ubN0t690l//KjVpImVkSCtXmiWCDkfu12WeGzqUZYEAXEewAgAAHqNGDemVV6Qff5T27zezVdficEiHD0svvWRCWHx83iEMAK7H2+oCAAAAikJUlNSmjdlvdT1//7s5JCkw0Oznql3bNM/I/L52bal8+aKtGUDJRbACAAAeKyysYNc1a2bujbV/v5SSYhpk/PRT7utCQpzDVub31atLvr6FWzuAkoVgBQAAPFbr1lJkZP5L/Gw28/zatZLdLl2+LB04YLoO7t7t/DUhQTp+3ByrVzu/j91uZsjyCl3h4ebnAPBsBCsAAOCx7HZp2jTT/c9mcw5XmWFn6lRznWRmnerUMce99zq/V2Ki6UCYV+hKSTGNM/bulb76yvl1eS0tzPxarlyRfXQAbkawAgAAHq1HD2nhQmnIEOeW65GRJlT16FGw9ylfXoqONkd2Dod07FjusLV7t5n9utbSwtDQvENXVBRLC4GShmAFAAA8Xo8eUrdu0po1JgSFhZllgpkzVa6w2cxyv/Bwc+Ph7DKXFuYVuo4fN8sLExKuv7Qw+xJDlhYCxRPBCgAAlAp2u9S2rXt/ZvalhTllLi3MGboKurQwr9DF0kLAOgQrAAAAC1xraeHRo3nv5Sro0sKcoat6dcnH58bqTE+XVq2yafXqCAUG2tSuXeHM9AGehmAFAABQjNhsUkSEOfJaWrh/f96h63pLC6tXzzt0hYXlv7Rw0aLMvWnekqI1ZYrZmzZtWsH3pgGlBcEKAACghPD1lerWNUdOiYlXlxJmX1aYubRwzx5z5FxaWLZs3jdE/uUXqX//3G3q4+NNl8WFCwlXQHYEKwAAAA9Qvrx0xx3myC5zaWFee7kOHJCSk6UtW8xREA6HmeEaOtQ0BGFZIGAQrAAAADxY9qWFd9/t/Fzm0sKcoWvHDuns2fzf0+GQDh+WmjSR7rxTqlnz6lGjhmmwAZQ2BCsAAIBSKr+lhfPnS337Xv/127aZI6fw8KtBq1Yt59AVFFQ4tQPFDcEKAAAATsLCCnbdiBGSt/fV1vB790pnzpilh0eP5m6iIZnOhdlnuLIHL9rFoyQjWAEAAMBJ69am+198fO7mFZJZXhgZKb3+eu49VmfOOAetPXuufn/q1NXOhWvX5n7fKlWcg1b24HXTTUXyUYFCQ7ACAACAE7vdtFTv1cuEqOzhKrM1+9SpeTeuqFjR7Lu6887cz5075xy6sgevEyekkyfN8cMPuV9bqVLuGa7MxxUrFsanBlxDsAIAAEAuPXqYlurmPlZXz0dGmlB1I63Wb7op75siS1JSkrRvn/MMV2bwSkiQTp82x4YNuV9boULeSwtr1pQqV87/Pl1AYSJYAQAAIE89epiW6t9+e0UrVmxVly6N1K6dd5G0WC9XTmrc2Bw5JSeb0JXX8sL4eNPBcNMmc+RUvnz+e7qCgwldKDwEKwAAAOTLbpfatHEoJSVebdo0tOS+VWXLSg0bmiOnCxecQ1f24HX4sLlx8ubN5sgpKMg5dGUPXqGhroWu9HRpzRrp2DHTDKR1a+755ekIVgAAACixAgKkBg3MkdPFi+YmyHktLzx0SDp/XvrpJ3PkFBiYf+gKC5O8vPKvadGivJdQTpt2Y0soUTIQrAAAAOCR/P2lW24xR06pqSZ05VxauHevdPCglJKS/326/P3NPbly7ueqWVPauFF68MHc3RTj400zkIULCVeeimAFAACAUsfPL++bI0vS5csmXOW1p+vAATMTtmOHOQrK4TBLC4cMMfvWWBboeQhWAAAAQDa+vlLt2ubIKS1N+u23vNvG79tn9lblx+EwywNDQ6Xq1aXwcHNEROT+Wr48jTVKGsuD1bvvvqu//e1vSkhIUMOGDfXOO+/ozrxufCBp0aJFmjBhgvbu3au0tDTVqlVLL7zwgh555JGsaxwOh0aPHq1Zs2bp3LlzatmypWbMmKFatWq56yMBAADAQ/n4XF32l9O8eVK2v5bm69Qpc1yLv3/egStnGCtT5sY+BwqfpcHqs88+U0xMjGbOnKmmTZtq6tSp6tSpk3bv3q3g4OBc11esWFGvvvqq6tatK19fXy1btkwDBw5UcHCwOnXqJEmaPHmy3n77bc2ZM0dRUVEaOXKkOnXqpJ07d6oMIw8AAABFJDKyYNfNnGlmrY4eNXuvcn49e9YsN8ycDbuWihWvH75CQlh66A6WBqspU6boySef1MCBAyVJM2fO1FdffaXZs2dr2LBhua5v27at0+MhQ4Zozpw5Wrt2rTp16iSHw6GpU6fqtddeU7du3SRJ//znPxUSEqIlS5aoT58+Rf6ZAAAAUDq1bm3CVXx87uYVklnaFxkpPfHEtYPOxYsmZGUPXDnDV3y8dOmSdOaMOa6138vLywS5682A3XQTyw9dYVmwunz5sjZv3qzhw4dnnfPy8lKHDh20bt26677e4XBo5cqV2r17tyZNmiRJOnDggBISEtShQ4es68qXL6+mTZtq3bp1+Qar1NRUpaamZj1OSkqSJKWlpSktLe2GPh+slfl74/cHd2HMwd0Yc3AnxlvBvfWWTX362GWzSQ7H1ZRis5mk9eab6crIcCgjI//38PaWbr7ZHPlxOKRz5zJDl03Hjknx8c5fjx61KSFBysiwZYWza/H3dyg8XAoLc/wvcF19HBFx9by//+/4A7kB6enSd9+la/XqCPn5pattW2tn3Ao67i0LVqdOnVJ6erpCQkKczoeEhOiXX37J93WJiYmKiIhQamqq7Ha7pk+fro4dO0qSEhISst4j53tmPpeXiRMnauzYsbnO//vf/1ZAQECBPxOKn9jYWKtLQCnDmIO7MebgToy36/Pzk15+OUwffNBAp09fTSCVKl3U44/vkJ/fMS1fXvg/t3Jlc+S8iXJ6upSY6KczZ/x15kwZnT5dRmfOXD1On/bX2bNldP68ry5etGnfPmnfvmtPW5Ute1kVK17KOipVuqgKFS6pUqXMx5dUvnyq7PY8pu2uY9267H920ZoyxfzZPfHEdjVvfux3v19huHDhQoGus7x5xe8VFBSkrVu3Kjk5WXFxcYqJiVH16tVzLRP8PYYPH66YmJisx0lJSapataruuecelStXrhCqhrulpaUpNjZWHTt2lI+Pj9XloBRgzMHdGHNwJ8bb79O1qzRmjLR27RUdO2ZuKNyqlY/s9saSGltdXp4uXkzLmuXKaxbs2DGb4uOlixdtSk72VXKyrw4dyv/vyV5eDoWGmlmusDApIsL5a+ZsWIUKV5cfLl5s0+TJ9lzLKM+cKaPJk+/QggXpuv/+3x/WXJW5mu16LAtWlStXlt1u1/Hjx53OHz9+XKGhofm+zsvLSzX/14alUaNG2rVrlyZOnKi2bdtmve748eMKCwtzes9GjRrl+55+fn7y8/PLdd7Hx4f/8yjh+B3C3RhzcDfGHNyJ8VZwPj5Stt0pxZ6Pj1SunFSnTv7XOBxSYmLeDTeyf01IkNLTrwa0aylT5uo+r82b896b5nDYZLNJL77orZ493b8ssKBj3rJg5evrqyZNmiguLk7du3eXJGVkZCguLk6DBw8u8PtkZGRk7Y+KiopSaGio4uLisoJUUlKSNmzYoGeeeaawPwIAAABQathspsHFTTdJ9evnf116unTiRP6NNzK/njljGnDs32+Oa3E4pMOHpTVrJBcWqhUpS5cCxsTEaMCAAYqOjtadd96pqVOnKiUlJatLYP/+/RUREaGJEydKMnuhoqOjVaNGDaWmpmr58uWaO3euZsyYIUmy2WwaOnSoxo8fr1q1amW1Ww8PD88KbwAAAACKjt1ulj9mW0CWp0uXrgavzz+X3nnn+u99zJptVgViabDq3bu3Tp48qVGjRikhIUGNGjXS119/ndV84tChQ/Ly8sq6PiUlRc8++6yOHDkif39/1a1bV/PmzVPv3r2zrnn55ZeVkpKip556SufOnVOrVq309ddfcw8rAAAAoBgpU0aqXt0cV64ULFhdL6xZyeZw5LWSsXRLSkpS+fLllZiYSPOKEiotLU3Lly9X165dWQsOt2DMwd0Yc3AnxhuKWnq6VK3a9e8BduCA+/dYFTQbeOX7DAAAAAC4gd0uTZtmvs95k+LMx1OnWns/q+shWAEAAACwXI8e0sKFUkSE8/nISHO+Rw9r6iqoEncfKwAAAACeqUcPqVs36dtvr2jFiq3q0qWR2rXzLtYzVZkIVgAAAACKDbtdatPGoZSUeLVp07BEhCqJpYAAAAAA4DKCFQAAAAC4iGAFAAAAAC4iWAEAAACAiwhWAAAAAOAighUAAAAAuIhgBQAAAAAuIlgBAAAAgIsIVgAAAADgIoIVAAAAALiIYAUAAAAALiJYAQAAAICLCFYAAAAA4CJvqwsojhwOhyQpKSnJ4kpwo9LS0nThwgUlJSXJx8fH6nJQCjDm4G6MObgT4w3uVpzGXGYmyMwI+SFY5eH8+fOSpKpVq1pcCQAAAIDi4Pz58ypfvny+z9sc14tepVBGRoaOHj2qoKAg2Ww2q8vBDUhKSlLVqlV1+PBhlStXzupyUAow5uBujDm4E+MN7lacxpzD4dD58+cVHh4uL6/8d1IxY5UHLy8vRUZGWl0GCkG5cuUs/x8jShfGHNyNMQd3YrzB3YrLmLvWTFUmmlcAAAAAgIsIVgAAAADgIoIVPJKfn59Gjx4tPz8/q0tBKcGYg7sx5uBOjDe4W0kcczSvAAAAAAAXMWMFAAAAAC4iWAEAAACAiwhWAAAAAOAighUAAAAAuIhgBY8yceJE3XHHHQoKClJwcLC6d++u3bt3W10WSom//vWvstlsGjp0qNWlwIPFx8fr4YcfVqVKleTv768GDRroxx9/tLoseKj09HSNHDlSUVFR8vf3V40aNTRu3DjR+wyFYfXq1br33nsVHh4um82mJUuWOD3vcDg0atQohYWFyd/fXx06dNCePXusKbYACFbwKKtWrdKgQYO0fv16xcbGKi0tTffcc49SUlKsLg0ebtOmTXrvvfd02223WV0KPNjZs2fVsmVL+fj4aMWKFdq5c6feeustVahQwerS4KEmTZqkGTNm6B//+Id27dqlSZMmafLkyXrnnXesLg0eICUlRQ0bNtS7776b5/OTJ0/W22+/rZkzZ2rDhg0KDAxUp06ddOnSJTdXWjC0W4dHO3nypIKDg7Vq1SrdddddVpcDD5WcnKzbb79d06dP1/jx49WoUSNNnTrV6rLggYYNG6bvv/9ea9assboUlBJ/+tOfFBISog8//DDrXM+ePeXv76958+ZZWBk8jc1m0+LFi9W9e3dJZrYqPDxcL7zwgl588UVJUmJiokJCQvTxxx+rT58+FlabN2as4NESExMlSRUrVrS4EniyQYMG6Y9//KM6dOhgdSnwcEuXLlV0dLQeeOABBQcHq3Hjxpo1a5bVZcGDtWjRQnFxcfr1118lSdu2bdPatWvVpUsXiyuDpztw4IASEhKc/ttavnx5NW3aVOvWrbOwsvx5W10AUFQyMjI0dOhQtWzZUrfeeqvV5cBDLViwQFu2bNGmTZusLgWlwP79+zVjxgzFxMRoxIgR2rRpk5577jn5+vpqwIABVpcHDzRs2DAlJSWpbt26stvtSk9P1xtvvKF+/fpZXRo8XEJCgiQpJCTE6XxISEjWc8UNwQoea9CgQdqxY4fWrl1rdSnwUIcPH9aQIUMUGxurMmXKWF0OSoGMjAxFR0drwoQJkqTGjRtrx44dmjlzJsEKReLzzz/XJ598ok8//VT169fX1q1bNXToUIWHhzPmgBxYCgiPNHjwYC1btkzffvutIiMjrS4HHmrz5s06ceKEbr/9dnl7e8vb21urVq3S22+/LW9vb6Wnp1tdIjxMWFiYbrnlFqdz9erV06FDhyyqCJ7upZde0rBhw9SnTx81aNBAjzzyiJ5//nlNnDjR6tLg4UJDQyVJx48fdzp//PjxrOeKG4IVPIrD4dDgwYO1ePFirVy5UlFRUVaXBA/Wvn17bd++XVu3bs06oqOj1a9fP23dulV2u93qEuFhWrZsmesWEr/++qv+8Ic/WFQRPN2FCxfk5eX810W73a6MjAyLKkJpERUVpdDQUMXFxWWdS0pK0oYNG9S8eXMLK8sfSwHhUQYNGqRPP/1UX375pYKCgrLW4JYvX17+/v4WVwdPExQUlGv/XmBgoCpVqsS+PhSJ559/Xi1atNCECRP04IMPauPGjXr//ff1/vvvW10aPNS9996rN954QzfffLPq16+vn376SVOmTNFjjz1mdWnwAMnJydq7d2/W4wMHDmjr1q2qWLGibr75Zg0dOlTjx49XrVq1FBUVpZEjRyo8PDyrc2BxQ7t1eBSbzZbn+Y8++kiPPvqoe4tBqdS2bVvaraNILVu2TMOHD9eePXsUFRWlmJgYPfnkk1aXBQ91/vx5jRw5UosXL9aJEycUHh6uhx56SKNGjZKvr6/V5aGE++6779SuXbtc5wcMGKCPP/5YDodDo0eP1vvvv69z586pVatWmj59umrXrm1BtddHsAIAAAAAF7HHCgAAAABcRLACAAAAABcRrAAAAADARQQrAAAAAHARwQoAAAAAXESwAgAAAAAXEawAAAAAwEUEKwAAAABwEcEKAAAX2Ww2LVmyxOoyAAAWIlgBAEq0Rx99VDabLdfRuXNnq0sDAJQi3lYXAACAqzp37qyPPvrI6Zyfn59F1QAASiNmrAAAJZ6fn59CQ0OdjgoVKkgyy/RmzJihLl26yN/fX9WrV9fChQudXr99+3bdfffd8vf3V6VKlfTUU08pOTnZ6ZrZs2erfv368vPzU1hYmAYPHuz0/KlTp3T//fcrICBAtWrV0tKlS7OeO3v2rPr166cqVarI399ftWrVyhUEAQAlG8EKAODxRo4cqZ49e2rbtm3q16+f+vTpo127dkmSUlJS1KlTJ1WoUEGbNm3SF198of/85z9OwWnGjBkaNGiQnnrqKW3fvl1Lly5VzZo1nX7G2LFj9eCDD+rnn39W165d1a9fP505cybr5+/cuVMrVqzQrl27NGPGDFWuXNl9fwAAgCJnczgcDquLAADgRj366KOaN2+eypQp43R+xIgRGjFihGw2m55++mnNmDEj67lmzZrp9ttv1/Tp0zVr1iy98sorOnz4sAIDAyVJy5cv17333qujR48qJCREERERGjhwoMaPH59nDTabTa+99prGjRsnyYS1smXLasWKFercubPuu+8+Va5cWbNnzy6iPwUAgNXYYwUAKPHatWvnFJwkqWLFilnfN2/e3Om55s2ba+vWrZKkXbt2qWHDhlmhSpJatmypjIwM7d69WzabTUePHlX79u2vWcNtt92W9X1gYKDKlSunEydOSJKeeeYZ9ezZU1u2bNE999yj7t27q0WLFjf0WQEAxRPBCgBQ4gUGBuZamldY/P39C3Sdj4+P02ObzaaMjAxJUpcuXfTbb79p+fLlio2NVfv27TVo0CC9+eabhV4vAMAa7LECAHi89evX53pcr149SVK9evW0bds2paSkZD3//fffy8vLS3Xq1FFQUJCqVaumuLg4l2qoUqWKBgwYoHnz5mnq1Kl6//33XXo/AEDxwowVAKDES01NVUJCgtM5b2/vrAYRX3zxhaKjo9WqVSt98skn2rhxoz788ENJUr9+/TR69GgNGDBAY8aM0cmTJ/WXv/xFjzzyiEJCQiRJY8aM0dNPP63g4GB16dJF58+f1/fff6+//OUvBapv1KhRatKkierXr6/U1FQtW7YsK9gBADwDwQoAUOJ9/fXXCgsLczpXp04d/fLLL5JMx74FCxbo2WefVVhYmObPn69bbrlFkhQQEKBvvvlGQ4YM0R133KGAgAD17NlTU6ZMyXqvAQMG6NKlS/r73/+uF198UZUrV1avXr0KXJ+vr6+GDx+ugwcPyt/fX61bt9aCBQsK4ZMDAIoLugICADyazWbT4sWL1b17d6tLAQB4MPZYAQAAAICLCFYAAAAA4CL2WAEAPBor3gEA7sCMFQAAAAC4iGAFAAAAAC4iWAEAAACAiwhWAAAAAOAighUAAAAAuIhgBQAAAAAuIlgBAAAAgIsIVgAAAADgov8HyVi8zphpiq4AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DenseLayer or FinalClassifier\n",
    "if isFinalClassifier:\n",
    "    dense_layer_class = FinalClassifier\n",
    "else:\n",
    "    dense_layer_class = DenseLayer\n",
    "    \n",
    "output_dim = 768\n",
    "\n",
    "# Run k-fold cross-validation   \n",
    "results_df = cross_validate_model(\n",
    "    dataset=full_dataset,\n",
    "    model_class=SMCAModel,\n",
    "    dense_layer_class=dense_layer_class,\n",
    "    criterion=criterion,\n",
    "    output_dim=output_dim,\n",
    "    num_epochs=num_epochs_cv,    \n",
    "    num_folds=num_folds,\n",
    "    train_batch_size=train_batch_size,\n",
    "    val_batch_size=val_batch_size,\n",
    "    learning_rate=learning_rate,\n",
    "    output_file=\"results/SMCA-F1_scores.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>Fold 1</th>\n",
       "      <th>Fold 2</th>\n",
       "      <th>Fold 3</th>\n",
       "      <th>Fold 4</th>\n",
       "      <th>Fold 5</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Loss</td>\n",
       "      <td>0.417407</td>\n",
       "      <td>0.368194</td>\n",
       "      <td>0.342923</td>\n",
       "      <td>0.362495</td>\n",
       "      <td>0.316262</td>\n",
       "      <td>0.361456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.818868</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.875472</td>\n",
       "      <td>0.864151</td>\n",
       "      <td>0.864151</td>\n",
       "      <td>0.854340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.690909</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.830769</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.745455</td>\n",
       "      <td>0.744408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.550725</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.650794</td>\n",
       "      <td>0.636643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F1 Score</td>\n",
       "      <td>0.612903</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.694915</td>\n",
       "      <td>0.685790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Metrics    Fold 1    Fold 2    Fold 3    Fold 4    Fold 5   Average\n",
       "0       Loss  0.417407  0.368194  0.342923  0.362495  0.316262  0.361456\n",
       "1   Accuracy  0.818868  0.849057  0.875472  0.864151  0.864151  0.854340\n",
       "2  Precision  0.690909  0.730769  0.830769  0.724138  0.745455  0.744408\n",
       "3     Recall  0.550725  0.593750  0.710526  0.677419  0.650794  0.636643\n",
       "4   F1 Score  0.612903  0.655172  0.765957  0.700000  0.694915  0.685790"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
