{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisite Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler\n",
    "from torcheval.metrics import BinaryPrecision, BinaryRecall, BinaryF1Score\n",
    "from sklearn.model_selection import train_test_split, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../')\n",
    "\n",
    "from modules.cross_attentionb import CrossAttentionB\n",
    "from modules.dataloader import load_npy_files\n",
    "from modules.classifier import DenseLayer, BCELoss, CustomLoss, BCEWithLogits\n",
    "from modules.linear_transformation import LinearTransformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultimodalDataset(Dataset):\n",
    "    def __init__(self, id_label_df, text_features, audio_features, video_features):\n",
    "        self.id_label_df = id_label_df\n",
    "        \n",
    "        # Convert feature lists to dictionaries for fast lookup\n",
    "        self.text_features = {os.path.basename(file).split('.')[0]: tensor for file, tensor in text_features}\n",
    "        self.audio_features = {os.path.basename(file).split('_')[1].split('.')[0]: tensor for file, tensor in audio_features}\n",
    "        self.video_features = {os.path.basename(file).split('_')[0]: tensor for file, tensor in video_features}\n",
    "\n",
    "        # List to store missing files\n",
    "        self.missing_files = []\n",
    "\n",
    "        # Filter out entries with missing files\n",
    "        self.valid_files = self._filter_valid_files()\n",
    "\n",
    "    def _filter_valid_files(self):\n",
    "        valid_indices = []\n",
    "        missing_files = []\n",
    "\n",
    "        for idx in range(len(self.id_label_df)):\n",
    "            imdbid = self.id_label_df.iloc[idx]['IMDBid']\n",
    "\n",
    "            # Check if the IMDBid exists in each modality's features\n",
    "            if imdbid in self.text_features and imdbid in self.audio_features and imdbid in self.video_features:\n",
    "                valid_indices.append(idx)\n",
    "            else:\n",
    "                missing_files.append({'IMDBid': imdbid})\n",
    "\n",
    "        # Filter id_label_df to only include valid rows\n",
    "        self.id_label_df = self.id_label_df.iloc[valid_indices].reset_index(drop=True)\n",
    "        self.missing_files = missing_files\n",
    "\n",
    "        # Return valid indices\n",
    "        return valid_indices\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.valid_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get the original index from the filtered valid files\n",
    "        original_idx = self.valid_files[idx]\n",
    "        imdbid = self.id_label_df.iloc[original_idx]['IMDBid']\n",
    "        label = self.id_label_df.iloc[original_idx]['Label']\n",
    "\n",
    "        # Retrieve data from the loaded features\n",
    "        text_data = self.text_features.get(imdbid, torch.zeros((1024,)))\n",
    "        audio_data = self.audio_features.get(imdbid, torch.zeros((1, 197, 768)))\n",
    "        video_data = self.video_features.get(imdbid, torch.zeros((95, 768)))\n",
    "        \n",
    "        # Define label mapping\n",
    "        label_map = {'red': 1, 'green': 0} \n",
    "        \n",
    "        # Convert labels to tensor using label_map\n",
    "        try:\n",
    "            label_data = torch.tensor([label_map[label]], dtype=torch.float32)\n",
    "        except KeyError as e:\n",
    "            print(f\"Error: Label '{e}' not found in label_map.\")\n",
    "            raise\n",
    "\n",
    "        return text_data, audio_data, video_data, label_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    text_data, audio_data, video_data, label_data = zip(*batch)\n",
    "\n",
    "    # Convert lists to tensors\n",
    "    text_data = torch.stack(text_data)\n",
    "    audio_data = torch.stack(audio_data)\n",
    "\n",
    "    # Padding for video data\n",
    "    # Determine maximum length of video sequences in the batch\n",
    "    video_lengths = [v.size(0) for v in video_data]\n",
    "    max_length = max(video_lengths)\n",
    "\n",
    "    # Pad video sequences to the maximum length\n",
    "    video_data_padded = torch.stack([\n",
    "        F.pad(v, (0, 0, 0, max_length - v.size(0)), \"constant\", 0)\n",
    "        for v in video_data\n",
    "    ])\n",
    "\n",
    "    # Convert labels to tensor and ensure the shape [batch_size, 1]\n",
    "    label_data = torch.stack(label_data)  # Convert list of tensors to a single tensor\n",
    "\n",
    "    return text_data, audio_data, video_data_padded, label_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of text feature vectors loaded: 1353\n",
      "Number of audio feature vectors loaded: 1353\n",
      "Number of video feature vectors loaded: 1353\n",
      "(947, 2)\n",
      "(203, 2)\n",
      "(203, 2)\n",
      "Train label distribution: Label\n",
      "green    707\n",
      "red      240\n",
      "Name: count, dtype: int64\n",
      "Validation label distribution: Label\n",
      "green    151\n",
      "red       52\n",
      "Name: count, dtype: int64\n",
      "Test label distribution: Label\n",
      "green    152\n",
      "red       51\n",
      "Name: count, dtype: int64\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Load the labels DataFrame\n",
    "id_label_df = pd.read_excel('../../misc/MM-Trailer_dataset.xlsx')\n",
    "\n",
    "# Define the directories\n",
    "text_features_dir = '../../misc/text_features'\n",
    "audio_features_dir = '../../misc/audio_features'\n",
    "video_features_dir = '../../misc/video_features'\n",
    "\n",
    "# Load the feature vectors from each directory\n",
    "text_features = load_npy_files(text_features_dir)\n",
    "audio_features = load_npy_files(audio_features_dir)\n",
    "video_features = load_npy_files(video_features_dir)\n",
    "\n",
    "print(f\"Number of text feature vectors loaded: {len(text_features)}\")\n",
    "print(f\"Number of audio feature vectors loaded: {len(audio_features)}\")\n",
    "print(f\"Number of video feature vectors loaded: {len(video_features)}\")\n",
    "\n",
    "# Drop unnecessary columns\n",
    "id_label_df = id_label_df.drop(columns=['Movie Title', 'URL'])\n",
    "\n",
    "full_dataset = MultimodalDataset(id_label_df, text_features, audio_features, video_features)\n",
    "\n",
    "# First, filter the id_label_df using the valid indices before creating dataset splits\n",
    "filtered_id_label_df = id_label_df.iloc[full_dataset.valid_files].reset_index(drop=True)\n",
    "\n",
    "# perform train-test split on the filtered DataFrame\n",
    "train_df, val_test_df = train_test_split(\n",
    "    filtered_id_label_df, test_size=0.3, random_state=42, stratify=filtered_id_label_df['Label'])\n",
    "\n",
    "# Further splitting remaining set into validation and test sets\n",
    "val_df, test_df = train_test_split(\n",
    "    val_test_df, test_size=0.5, random_state=42, stratify=val_test_df['Label'])\n",
    "\n",
    "print(train_df.shape)\n",
    "print(val_df.shape)\n",
    "print(test_df.shape)\n",
    "\n",
    "print(\"Train label distribution:\", train_df['Label'].value_counts())\n",
    "print(\"Validation label distribution:\", val_df['Label'].value_counts())\n",
    "print(\"Test label distribution:\", test_df['Label'].value_counts())\n",
    "\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# create datasets based on these splits\n",
    "train_dataset = MultimodalDataset(train_df, text_features, audio_features, video_features)\n",
    "val_dataset = MultimodalDataset(val_df, text_features, audio_features, video_features)\n",
    "test_dataset = MultimodalDataset(test_df, text_features, audio_features, video_features)\n",
    "\n",
    "# Calculate weights for the classes in the training set\n",
    "class_counts = train_df['Label'].value_counts().to_dict()\n",
    "class_weights = {label: 1.0 / count for label, count in class_counts.items()}\n",
    "sample_weights = [class_weights[label] for label in train_df['Label']]\n",
    "\n",
    "# Initialize the WeightedRandomSampler\n",
    "weighted_sampler = WeightedRandomSampler(\n",
    "    weights=sample_weights,\n",
    "    num_samples=len(sample_weights),\n",
    "    replacement=True\n",
    ")\n",
    "\n",
    "# RESAMPLING\n",
    "# train_dataloader = DataLoader(train_dataset, batch_size=32, sampler=weighted_sampler, num_workers=0, collate_fn=collate_fn)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0, collate_fn=collate_fn)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=True, num_workers=0, collate_fn=collate_fn)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=0, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Attention Function\n",
    "def PairCrossAttention(modalityAlpha, modalityBeta, d_out_kq=768, d_out_v=768):\n",
    "    cross_attn = CrossAttentionB(modalityAlpha.shape[-1], modalityBeta.shape[-1], d_out_kq, d_out_v)\n",
    "    modalityAlphaBeta = cross_attn(modalityAlpha, modalityBeta)\n",
    "    return modalityAlphaBeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiheadCrossAttention(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads=1):\n",
    "        super().__init__()\n",
    "        self.multihead_attn = nn.MultiheadAttention(embed_dim, num_heads, batch_first=True)\n",
    "        \n",
    "    def forward(self, query, key_value):\n",
    "        # Ensure inputs are 3D: (batch_size, sequence_length, embed_dim)\n",
    "        if query.dim() == 2:\n",
    "            query = query.unsqueeze(1)  # Add sequence length dimension\n",
    "        if key_value.dim() == 2:\n",
    "            key_value = key_value.unsqueeze(1)  # Add sequence length dimension\n",
    "            \n",
    "        output, _ = self.multihead_attn(query, key_value, key_value)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters and Important Assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# !!! Choose if pytorch's multiheadattention or own crossattention\n",
    "isTorch = False\n",
    "\n",
    "# Modality assignments\n",
    "modality_assignments = {\n",
    "    'modalityAlpha': 'audio_features',\n",
    "    'modalityBeta': 'text_features',\n",
    "    'modalityGamma': 'video_features'\n",
    "}\n",
    "\n",
    "# Define the loss function\n",
    "isBCELoss = True                          # !!! SET ACCORDINGLY !!!\n",
    "# criterion = BCELoss()\n",
    "# criterion = BCEWithLogits()\n",
    "criterion = CustomLoss(pos_weight=2.94)  \n",
    "\n",
    "# Hyperparameters\n",
    "threshold = 0.5        # for predictions\n",
    "learning_rate = 1e-2\n",
    "dropout_rate = 0.3    # for FinalClassifier\n",
    "num_epochs = 10       # Set the number of epochs you want to train for"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMCA Functions and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SMCAStage1(modalityAlpha, modalityBeta, d_out_kq, d_out_v, device):\n",
    "    \n",
    "    if isTorch: \n",
    "        cross_attn = MultiheadCrossAttention(d_out_v).to(device)\n",
    "    else:\n",
    "        cross_attn = CrossAttentionB(modalityAlpha.shape[-1], modalityBeta.shape[-1], d_out_kq, d_out_v).to(device)\n",
    "\n",
    "    # Cross-attention: Alpha -> Beta\n",
    "    alphaBeta = cross_attn(modalityAlpha, modalityBeta)  # Shape: (batch_size, num_queries, d_out_v)\n",
    "\n",
    "    # Cross-attention: Beta -> Alpha\n",
    "    betaAlpha = cross_attn(modalityBeta, modalityAlpha)  # Shape: (batch_size, num_kv, d_out_v)\n",
    "\n",
    "    # Get the sequence lengths\n",
    "    seq_len_alpha = alphaBeta.size(1)  # This is num_queries\n",
    "    seq_len_beta = betaAlpha.size(1)    # This is num_kv\n",
    "\n",
    "    # Instead of expanding, use padding or trimming\n",
    "    max_seq_len = max(seq_len_alpha, seq_len_beta)\n",
    "\n",
    "    # Ensure both alphaBeta and betaAlpha are of shape (batch_size, max_seq_len, d_out_v)\n",
    "    if seq_len_alpha < max_seq_len:\n",
    "        alphaBeta = torch.nn.functional.pad(alphaBeta, (0, 0, 0, max_seq_len - seq_len_alpha), value=0)\n",
    "\n",
    "    if seq_len_beta < max_seq_len:\n",
    "        betaAlpha = torch.nn.functional.pad(betaAlpha, (0, 0, 0, max_seq_len - seq_len_beta), value=0)\n",
    "\n",
    "    # Concatenate cross-attention outputs along the feature dimension (-1)\n",
    "    modalityAlphaBeta = torch.cat((alphaBeta, betaAlpha), dim=-1)  # Shape: (batch_size, max_seq_len, 2 * d_out_v)\n",
    "\n",
    "    return modalityAlphaBeta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProjectionLayer(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(ProjectionLayer, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SMCAStage2(modalityAlphaBeta, modalityGamma, d_out_kq, d_out_v, device):\n",
    "    # modalityAlphaBeta: (batch_size, seq_len, 2 * d_out_v) [output of Stage 1]\n",
    "    \n",
    "    # Initialize the projection layer for modalityAlphaBeta\n",
    "    projection_layer = ProjectionLayer(modalityAlphaBeta.shape[-1], d_out_v).to(device)\n",
    "\n",
    "    # Project modalityAlphaBeta to (batch_size, seq_len, d_out_v)\n",
    "    modalityAlphaBetaProjected = projection_layer(modalityAlphaBeta)\n",
    "\n",
    "    # Initialize the cross-attention module\n",
    "    if isTorch: \n",
    "        cross_attn = MultiheadCrossAttention(d_out_v).to(device)\n",
    "    else:\n",
    "        cross_attn = CrossAttentionB(modalityAlphaBetaProjected.shape[-1], modalityGamma.shape[-1], d_out_kq, d_out_v).to(device)\n",
    "\n",
    "    # Cross-attention: AlphaBeta -> Gamma\n",
    "    alphaBetaGamma = cross_attn(modalityAlphaBetaProjected, modalityGamma)  # Shape: (batch_size, seq_len_alphaBeta, d_out_v)\n",
    "\n",
    "    # Cross-attention: Gamma -> AlphaBeta\n",
    "    gammaAlphaBeta = cross_attn(modalityGamma, modalityAlphaBetaProjected)  # Shape: (batch_size, seq_len_gamma, d_out_v)\n",
    "\n",
    "    # Get the sequence lengths for both modalities\n",
    "    seq_len_alphaBeta = alphaBetaGamma.size(1)\n",
    "    seq_len_gamma = gammaAlphaBeta.size(1)\n",
    "\n",
    "    # Pad the smaller sequence to match the larger one (expanding to before)\n",
    "    max_seq_len = max(seq_len_alphaBeta, seq_len_gamma)\n",
    "\n",
    "    if seq_len_alphaBeta < max_seq_len:\n",
    "        alphaBetaGamma = torch.nn.functional.pad(alphaBetaGamma, (0, 0, 0, max_seq_len - seq_len_alphaBeta), value=0)\n",
    "\n",
    "    if seq_len_gamma < max_seq_len:\n",
    "        gammaAlphaBeta = torch.nn.functional.pad(gammaAlphaBeta, (0, 0, 0, max_seq_len - seq_len_gamma), value=0)\n",
    "\n",
    "    # Concatenate along the feature dimension (-1)\n",
    "    multimodal_representation = torch.cat((alphaBetaGamma, gammaAlphaBeta), dim=-1)  # Shape: (batch_size, max(seq_len_alphaBeta, seq_len_gamma), 2 * d_out_v)\n",
    "\n",
    "    # Apply Global Average Pooling across the feature (sequence to before)\n",
    "    GAP = torch.mean(multimodal_representation, dim=1)  # Shape: (batch_size, 2 * d_out_v)\n",
    "\n",
    "    return GAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SMCAModel(nn.Module):\n",
    "    def __init__(self, d_out_kq, d_out_v, device):\n",
    "        super(SMCAModel, self).__init__()\n",
    "        self.d_out_kq = d_out_kq\n",
    "        self.d_out_v = d_out_v\n",
    "        self.device = device\n",
    "    \n",
    "    def forward(self, modalityAlpha, modalityBeta, modalityGamma):\n",
    "        # Stage 1: Cross attention between modalityAlpha and modalityBeta\n",
    "        modalityAlphaBeta = SMCAStage1(modalityAlpha, modalityBeta, self.d_out_kq, self.d_out_v, self.device)\n",
    "\n",
    "        # Stage 2: Cross attention with modalityAlphaBeta (as query) and modalityGamma (as key-value)\n",
    "        multimodal_representation = SMCAStage2(modalityAlphaBeta, modalityGamma, self.d_out_kq, self.d_out_v, self.device)\n",
    "\n",
    "        return multimodal_representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dense_layer, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    dense_layer.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for text_features, audio_features, video_features, targets in dataloader:\n",
    "        text_features, audio_features, video_features, targets = (\n",
    "            text_features.to(device),\n",
    "            audio_features.to(device),\n",
    "            video_features.to(device),\n",
    "            targets.to(device).view(-1)\n",
    "        )\n",
    "                \n",
    "        # Squeeze the audio features to remove the extra dimension\n",
    "        audio_features = audio_features.squeeze(1) \n",
    "\n",
    "        # Apply linear transformations to match dimensions\n",
    "        linear_transform_audio = LinearTransformations(audio_features.shape[-1], 768) \n",
    "        linear_transform_text = LinearTransformations(text_features.shape[-1], 768)   \n",
    "        linear_transform_video = LinearTransformations(video_features.shape[-1], 768)    \n",
    "\n",
    "        # Transform features to match the target dimension\n",
    "        audio_features = linear_transform_audio(audio_features)  \n",
    "        text_features = linear_transform_text(text_features)    \n",
    "        video_features = linear_transform_video(video_features)\n",
    "        \n",
    "        transformed_features = {\n",
    "            'audio_features': audio_features,\n",
    "            'text_features': text_features,\n",
    "            'video_features': video_features\n",
    "        }\n",
    "\n",
    "        outputs = model(\n",
    "            modalityAlpha=transformed_features[modality_assignments['modalityAlpha']],  # Use the dictionary for modality assignment\n",
    "            modalityBeta=transformed_features[modality_assignments['modalityBeta']],\n",
    "            modalityGamma=transformed_features[modality_assignments['modalityGamma']]\n",
    "        )\n",
    "\n",
    "        # Pass the fused features through the dense layer\n",
    "        predictions = dense_layer(outputs).view(-1)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(predictions, targets)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dense_layer, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    dense_layer.eval()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    # Initialize the metrics for binary classification\n",
    "    precision_metric = BinaryPrecision().to(device)\n",
    "    recall_metric = BinaryRecall().to(device)\n",
    "    f1_metric = BinaryF1Score().to(device)\n",
    "\n",
    "    precision_metric.reset()\n",
    "    recall_metric.reset()\n",
    "    f1_metric.reset()\n",
    "\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "         for text_features, audio_features, video_features, targets in dataloader:\n",
    "            text_features, audio_features, video_features, targets = (\n",
    "                text_features.to(device),\n",
    "                audio_features.to(device),\n",
    "                video_features.to(device),\n",
    "                targets.to(device).view(-1)\n",
    "            )\n",
    "        \n",
    "            # Squeeze the audio features to remove the extra dimension\n",
    "            audio_features = audio_features.squeeze(1) \n",
    "\n",
    "            # Apply linear transformations to match dimensions\n",
    "            linear_transform_audio = LinearTransformations(audio_features.shape[-1], 768) \n",
    "            linear_transform_text = LinearTransformations(text_features.shape[-1], 768)   \n",
    "            linear_transform_video = LinearTransformations(video_features.shape[-1], 768)    \n",
    "\n",
    "            # Transform features to match the target dimension\n",
    "            audio_features = linear_transform_audio(audio_features)  \n",
    "            text_features = linear_transform_text(text_features)    \n",
    "            video_features = linear_transform_video(video_features)\n",
    "            \n",
    "            transformed_features = {\n",
    "                'audio_features': audio_features,\n",
    "                'text_features': text_features,\n",
    "                'video_features': video_features\n",
    "            }\n",
    "\n",
    "            outputs = model(\n",
    "                modalityAlpha=transformed_features[modality_assignments['modalityAlpha']],  # Use the dictionary for modality assignment\n",
    "                modalityBeta=transformed_features[modality_assignments['modalityBeta']],\n",
    "                modalityGamma=transformed_features[modality_assignments['modalityGamma']]\n",
    "            )\n",
    "\n",
    "            # Pass the fused features through the dense layer\n",
    "            predictions = dense_layer(outputs).view(-1)\n",
    "\n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "            \n",
    "            # Compute loss\n",
    "            loss = criterion(predictions, targets)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # !!!Apply if BCEWithLogits or CustomLoss!!!\n",
    "            if not isBCELoss:\n",
    "                predictions = torch.sigmoid(predictions)\n",
    "\n",
    "            # Apply threshold to get binary predictions\n",
    "            preds = (predictions >= threshold).float()\n",
    "            \n",
    "            # Print model predictions and targets for each batch\n",
    "            print(\"-\" * 15, \"Eval\", \"-\" * 15)\n",
    "            print(f\"Predictions (raw):  {np.round(predictions.cpu().numpy(), 3)}\")            \n",
    "            print(f\"Binary Predictions: {preds.cpu().numpy()}\")\n",
    "            print(f\"Targets:            {targets.cpu().numpy()}\")\n",
    "            \n",
    "\n",
    "            # Update the precision, recall, and F1 score metrics\n",
    "            precision_metric.update(preds.long(), targets.long())\n",
    "            recall_metric.update(preds.long(), targets.long())\n",
    "            f1_metric.update(preds.long(), targets.long())\n",
    "\n",
    "    # Compute precision, recall, and F1 score\n",
    "    precision = precision_metric.compute().item()\n",
    "    recall = recall_metric.compute().item()\n",
    "    f1_score = f1_metric.compute().item()\n",
    "\n",
    "    average_loss = total_loss / len(dataloader)\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1_score:.4f}\")\n",
    "    \n",
    "    return average_loss, precision, recall, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, dense_layer, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    dense_layer.eval()\n",
    "    total_loss = 0\n",
    "\n",
    "    # Initialize the metrics for binary classification\n",
    "    precision_metric = BinaryPrecision().to(device)\n",
    "    recall_metric = BinaryRecall().to(device)\n",
    "    f1_metric = BinaryF1Score().to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for text_features, audio_features, video_features, targets in dataloader:\n",
    "            text_features, audio_features, video_features, targets = (\n",
    "                text_features.to(device),\n",
    "                audio_features.to(device),\n",
    "                video_features.to(device),\n",
    "                targets.to(device).view(-1)\n",
    "            )\n",
    "            \n",
    "            # Squeeze the audio features to remove the extra dimension\n",
    "            audio_features = audio_features.squeeze(1) \n",
    "\n",
    "            # Apply linear transformations to match dimensions\n",
    "            linear_transform_audio = LinearTransformations(audio_features.shape[-1], 768) \n",
    "            linear_transform_text = LinearTransformations(text_features.shape[-1], 768)   \n",
    "            linear_transform_video = LinearTransformations(video_features.shape[-1], 768)    \n",
    "\n",
    "            # Transform features to match the target dimension\n",
    "            audio_features = linear_transform_audio(audio_features)  \n",
    "            text_features = linear_transform_text(text_features)    \n",
    "            video_features = linear_transform_video(video_features)\n",
    "            \n",
    "            transformed_features = {\n",
    "                'audio_features': audio_features,\n",
    "                'text_features': text_features,\n",
    "                'video_features': video_features\n",
    "            }\n",
    "\n",
    "            outputs = model(\n",
    "                modalityAlpha=transformed_features[modality_assignments['modalityAlpha']],  # Use the dictionary for modality assignment\n",
    "                modalityBeta=transformed_features[modality_assignments['modalityBeta']],\n",
    "                modalityGamma=transformed_features[modality_assignments['modalityGamma']]\n",
    "            )\n",
    "\n",
    "            # Pass the fused features through the dense layer\n",
    "            predictions = dense_layer(outputs).view(-1)\n",
    "                \n",
    "            # Compute loss\n",
    "            loss = criterion(predictions, targets)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # !!!Apply if BCEWithLogits or CustomLoss!!!\n",
    "            if not isBCELoss:\n",
    "                predictions = torch.sigmoid(predictions)\n",
    "\n",
    "            # Apply threshold to get binary predictions\n",
    "            preds = (predictions >= threshold).float()\n",
    "\n",
    "            # Print model predictions and targets for each batch\n",
    "            print(\"-\" * 15, \"Test\", \"-\" * 15)\n",
    "            print(f\"Predictions (raw):  {np.round(predictions.cpu().numpy(), 3)}\")            \n",
    "            print(f\"Binary Predictions: {preds.cpu().numpy()}\")\n",
    "            print(f\"Targets:            {targets.cpu().numpy()}\")\n",
    "            \n",
    "            # Update the precision, recall, and F1 score metrics\n",
    "            precision_metric.update(preds.long(), targets.long())\n",
    "            recall_metric.update(preds.long(), targets.long())\n",
    "            f1_metric.update(preds.long(), targets.long())\n",
    "\n",
    "    # Compute precision, recall, and F1 score\n",
    "    precision = precision_metric.compute().item()\n",
    "    recall = recall_metric.compute().item()\n",
    "    f1_score = f1_metric.compute().item()\n",
    "\n",
    "    average_loss = total_loss / len(dataloader)\n",
    "\n",
    "    print(f\"Test Precision: {precision:.4f}\")\n",
    "    print(f\"Test Recall: {recall:.4f}\")\n",
    "    print(f\"Test F1 Score: {f1_score:.4f}\")\n",
    "    print(f\"Test Loss: {average_loss:.4f}\")\n",
    "\n",
    "    return average_loss, precision, recall, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(parameters, lr=learning_rate):\n",
    "    # Create an optimizer, for example, Adam\n",
    "    return optim.Adam(parameters, lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the custom weight initialization function\n",
    "def initialize_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        # Xavier initialization for weights\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            # Set bias to zero\n",
    "            nn.init.zeros_(m.bias)\n",
    "    elif isinstance(m, nn.BatchNorm1d):\n",
    "        # Set batch norm parameters\n",
    "        nn.init.ones_(m.weight)\n",
    "        nn.init.zeros_(m.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinalClassifier(nn.Module):\n",
    "    def __init__(self, input_size, dropout_rate=dropout_rate):\n",
    "        super(FinalClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 512)  # First fully connected layer\n",
    "        self.bn1 = nn.BatchNorm1d(512)          # Batch normalization after first layer\n",
    "        self.fc2 = nn.Linear(512, 256)          # Second fully connected layer\n",
    "        self.bn2 = nn.BatchNorm1d(256)          # Batch normalization after second layer\n",
    "        self.dropout = nn.Dropout(dropout_rate) # Dropout layer\n",
    "        self.dense = nn.Linear(256, 1)          # Final dense layer for binary classification\n",
    "        self.relu = nn.ReLU()                    # ReLU activation\n",
    "        self.sigmoid = nn.Sigmoid()              # Sigmoid activation for final output\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)                         # First fully connected layer\n",
    "        x = self.bn1(x)                         # Apply batch normalization\n",
    "        x = self.relu(x)                        # Apply ReLU activation\n",
    "        x = self.dropout(x)                     # Apply dropout\n",
    "        \n",
    "        x = self.fc2(x)                         # Second fully connected layer\n",
    "        x = self.bn2(x)                         # Apply batch normalization\n",
    "        x = self.relu(x)                        # Apply ReLU activation\n",
    "        x = self.dropout(x)                     # Apply dropout\n",
    "        \n",
    "        x = self.dense(x)                       # Final dense layer\n",
    "        # !!!Remove if BCEWithLogits!!!\n",
    "        # if isBCELoss:\n",
    "        #     x = self.sigmoid(x)                  # Apply sigmoid activation\n",
    "        return x                                 # Output probabilities for BCELoss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier: No gradient for: fc.weight\n",
      "classifier: No gradient for: fc.bias\n",
      "----------------------------------------\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.499 0.505 0.501 0.49  0.498 0.504 0.507 0.496 0.503 0.495 0.505 0.509\n",
      " 0.5   0.502 0.5   0.494]\n",
      "Binary Predictions: [0. 1. 1. 0. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0.]\n",
      "Targets:            [1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.502 0.508 0.502 0.503 0.499 0.505 0.502 0.506 0.504 0.503 0.499 0.505\n",
      " 0.501 0.497 0.504 0.508]\n",
      "Binary Predictions: [1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1.]\n",
      "Targets:            [0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.477 0.483 0.476 0.475 0.466 0.477 0.477 0.481 0.479 0.477 0.494 0.476\n",
      " 0.478 0.487 0.481 0.486]\n",
      "Binary Predictions: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Targets:            [0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.48  0.485 0.488 0.491 0.486 0.491 0.485 0.486 0.481 0.474 0.48  0.485\n",
      " 0.481 0.477 0.493 0.487]\n",
      "Binary Predictions: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Targets:            [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.538 0.523 0.531 0.548 0.525 0.528 0.539 0.526 0.545 0.534 0.533 0.534\n",
      " 0.52  0.509 0.529 0.536]\n",
      "Binary Predictions: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Targets:            [0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.474 0.462 0.464 0.463 0.467 0.461 0.468 0.473 0.464 0.465 0.466 0.462\n",
      " 0.459 0.462 0.471 0.463]\n",
      "Binary Predictions: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Targets:            [0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.497 0.509 0.493 0.49  0.511 0.509 0.504 0.509 0.498 0.498 0.507 0.498\n",
      " 0.511 0.493 0.507 0.502]\n",
      "Binary Predictions: [0. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1.]\n",
      "Targets:            [0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.47  0.473 0.478 0.485 0.473 0.471 0.466 0.477 0.473 0.463 0.478 0.478\n",
      " 0.471 0.475 0.482 0.473]\n",
      "Binary Predictions: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Targets:            [0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.512 0.519 0.515 0.519 0.515 0.526 0.512 0.513 0.515 0.512 0.515 0.533\n",
      " 0.511 0.518 0.511 0.515]\n",
      "Binary Predictions: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Targets:            [1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.534 0.539 0.53  0.527 0.54  0.534 0.533 0.522 0.526 0.531 0.538 0.541\n",
      " 0.537 0.528 0.541 0.531]\n",
      "Binary Predictions: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Targets:            [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.475 0.48  0.485 0.476 0.476 0.478 0.492 0.478 0.481 0.474 0.484 0.473\n",
      " 0.487 0.489 0.484 0.469]\n",
      "Binary Predictions: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Targets:            [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.489 0.488 0.495 0.493 0.489 0.471 0.489 0.495 0.489 0.486 0.486 0.488\n",
      " 0.489 0.489 0.498 0.482]\n",
      "Binary Predictions: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Targets:            [1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.492 0.496 0.494 0.482 0.504 0.496 0.484 0.49  0.485 0.488 0.473]\n",
      "Binary Predictions: [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "Targets:            [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Precision: 0.2716\n",
      "Recall: 0.4231\n",
      "F1 Score: 0.3308\n",
      "Training Loss: 1.4929, Validation Loss: 1.4898\n",
      "----------------------------------------\n",
      "Epoch 2/10\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.461 0.461 0.469 0.455 0.465 0.46  0.465 0.457 0.471 0.455 0.463 0.464\n",
      " 0.484 0.465 0.462 0.451]\n",
      "Binary Predictions: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Targets:            [1. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.528 0.529 0.53  0.548 0.523 0.53  0.508 0.529 0.526 0.521 0.517 0.531\n",
      " 0.515 0.529 0.532 0.526]\n",
      "Binary Predictions: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Targets:            [0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.49  0.486 0.496 0.49  0.501 0.491 0.499 0.5   0.496 0.485 0.508 0.489\n",
      " 0.497 0.472 0.491 0.496]\n",
      "Binary Predictions: [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "Targets:            [0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.432 0.44  0.443 0.434 0.437 0.439 0.439 0.431 0.432 0.435 0.434 0.431\n",
      " 0.438 0.435 0.442 0.438]\n",
      "Binary Predictions: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Targets:            [0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.466 0.459 0.469 0.455 0.449 0.452 0.462 0.454 0.451 0.457 0.463 0.453\n",
      " 0.465 0.459 0.449 0.455]\n",
      "Binary Predictions: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Targets:            [1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.532 0.535 0.532 0.537 0.526 0.546 0.535 0.529 0.544 0.527 0.531 0.531\n",
      " 0.538 0.523 0.529 0.537]\n",
      "Binary Predictions: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Targets:            [1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.472 0.481 0.452 0.483 0.455 0.48  0.459 0.479 0.483 0.466 0.471 0.476\n",
      " 0.48  0.463 0.468 0.47 ]\n",
      "Binary Predictions: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Targets:            [0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.486 0.483 0.473 0.473 0.489 0.506 0.49  0.486 0.486 0.489 0.474 0.493\n",
      " 0.494 0.492 0.495 0.485]\n",
      "Binary Predictions: [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Targets:            [0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.488 0.49  0.496 0.469 0.483 0.484 0.474 0.476 0.483 0.487 0.476 0.477\n",
      " 0.478 0.472 0.474 0.482]\n",
      "Binary Predictions: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Targets:            [0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.534 0.531 0.528 0.523 0.529 0.524 0.526 0.524 0.52  0.529 0.529 0.525\n",
      " 0.537 0.524 0.532 0.528]\n",
      "Binary Predictions: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Targets:            [0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.476 0.488 0.483 0.482 0.479 0.47  0.482 0.479 0.48  0.484 0.492 0.497\n",
      " 0.486 0.48  0.475 0.487]\n",
      "Binary Predictions: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Targets:            [1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.488 0.485 0.484 0.501 0.478 0.493 0.52  0.482 0.498 0.501 0.49  0.489\n",
      " 0.483 0.495 0.484 0.502]\n",
      "Binary Predictions: [0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1.]\n",
      "Targets:            [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.51  0.505 0.499 0.501 0.468 0.497 0.506 0.481 0.504 0.482 0.483]\n",
      "Binary Predictions: [1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0.]\n",
      "Targets:            [1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "Precision: 0.2333\n",
      "Recall: 0.2692\n",
      "F1 Score: 0.2500\n",
      "Training Loss: 1.4930, Validation Loss: 1.4916\n",
      "----------------------------------------\n",
      "Epoch 3/10\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.482 0.489 0.476 0.469 0.488 0.478 0.491 0.497 0.483 0.493 0.491 0.487\n",
      " 0.485 0.489 0.487 0.481]\n",
      "Binary Predictions: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Targets:            [1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.515 0.498 0.519 0.524 0.5   0.53  0.518 0.514 0.511 0.511 0.521 0.501\n",
      " 0.529 0.522 0.526 0.502]\n",
      "Binary Predictions: [1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Targets:            [1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.457 0.495 0.475 0.481 0.489 0.461 0.472 0.474 0.473 0.478 0.462 0.472\n",
      " 0.482 0.468 0.479 0.463]\n",
      "Binary Predictions: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Targets:            [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.432 0.434 0.438 0.432 0.44  0.458 0.433 0.444 0.439 0.441 0.443 0.444\n",
      " 0.469 0.44  0.443 0.423]\n",
      "Binary Predictions: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Targets:            [0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.437 0.444 0.438 0.447 0.437 0.446 0.437 0.442 0.442 0.449 0.453 0.457\n",
      " 0.453 0.43  0.442 0.438]\n",
      "Binary Predictions: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Targets:            [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.5   0.47  0.483 0.467 0.498 0.475 0.504 0.473 0.511 0.485 0.498 0.447\n",
      " 0.497 0.478 0.497 0.485]\n",
      "Binary Predictions: [1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Targets:            [0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.555 0.552 0.563 0.553 0.551 0.562 0.555 0.572 0.557 0.56  0.568 0.56\n",
      " 0.569 0.554 0.553 0.559]\n",
      "Binary Predictions: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Targets:            [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.49  0.482 0.496 0.498 0.498 0.503 0.492 0.482 0.487 0.488 0.492 0.499\n",
      " 0.489 0.488 0.494 0.494]\n",
      "Binary Predictions: [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Targets:            [1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.539 0.543 0.521 0.539 0.526 0.53  0.532 0.525 0.528 0.517 0.52  0.536\n",
      " 0.527 0.524 0.52  0.54 ]\n",
      "Binary Predictions: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Targets:            [1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.491 0.478 0.481 0.481 0.474 0.472 0.473 0.481 0.479 0.474 0.484 0.489\n",
      " 0.485 0.481 0.473 0.479]\n",
      "Binary Predictions: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Targets:            [0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 1.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.55  0.535 0.535 0.533 0.536 0.527 0.528 0.538 0.54  0.542 0.528 0.549\n",
      " 0.536 0.531 0.548 0.532]\n",
      "Binary Predictions: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Targets:            [0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.468 0.461 0.467 0.441 0.475 0.454 0.461 0.455 0.455 0.462 0.473 0.464\n",
      " 0.455 0.454 0.465 0.464]\n",
      "Binary Predictions: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Targets:            [0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.517 0.512 0.518 0.523 0.528 0.512 0.549 0.523 0.518 0.529 0.525]\n",
      "Binary Predictions: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Targets:            [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "Precision: 0.2597\n",
      "Recall: 0.3846\n",
      "F1 Score: 0.3101\n",
      "Training Loss: 1.4891, Validation Loss: 1.4897\n",
      "----------------------------------------\n",
      "Epoch 4/10\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.454 0.463 0.466 0.473 0.449 0.452 0.459 0.474 0.462 0.474 0.452 0.441\n",
      " 0.442 0.468 0.45  0.464]\n",
      "Binary Predictions: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Targets:            [0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.487 0.452 0.46  0.467 0.462 0.482 0.47  0.48  0.458 0.456 0.471 0.461\n",
      " 0.486 0.458 0.454 0.474]\n",
      "Binary Predictions: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Targets:            [0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.491 0.492 0.48  0.479 0.494 0.494 0.511 0.484 0.498 0.486 0.485 0.495\n",
      " 0.538 0.498 0.499 0.493]\n",
      "Binary Predictions: [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "Targets:            [0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.494 0.502 0.511 0.507 0.499 0.486 0.516 0.5   0.504 0.499 0.507 0.49\n",
      " 0.502 0.497 0.484 0.512]\n",
      "Binary Predictions: [0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1.]\n",
      "Targets:            [0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.473 0.478 0.457 0.483 0.481 0.476 0.467 0.454 0.48  0.479 0.446 0.469\n",
      " 0.455 0.476 0.457 0.45 ]\n",
      "Binary Predictions: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Targets:            [1. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.472 0.472 0.456 0.467 0.47  0.479 0.468 0.459 0.452 0.458 0.463 0.456\n",
      " 0.446 0.466 0.459 0.461]\n",
      "Binary Predictions: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Targets:            [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.466 0.458 0.47  0.454 0.463 0.456 0.471 0.469 0.444 0.45  0.462 0.445\n",
      " 0.448 0.473 0.464 0.463]\n",
      "Binary Predictions: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Targets:            [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.448 0.447 0.471 0.454 0.478 0.476 0.455 0.461 0.466 0.445 0.481 0.468\n",
      " 0.46  0.465 0.461 0.455]\n",
      "Binary Predictions: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Targets:            [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.451 0.419 0.437 0.439 0.442 0.426 0.456 0.446 0.439 0.45  0.469 0.449\n",
      " 0.445 0.446 0.435 0.441]\n",
      "Binary Predictions: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Targets:            [0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.523 0.497 0.513 0.538 0.517 0.522 0.518 0.521 0.511 0.499 0.512 0.526\n",
      " 0.528 0.528 0.514 0.526]\n",
      "Binary Predictions: [1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.]\n",
      "Targets:            [0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.439 0.455 0.458 0.448 0.48  0.424 0.435 0.449 0.441 0.425 0.436 0.473\n",
      " 0.434 0.435 0.452 0.438]\n",
      "Binary Predictions: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Targets:            [0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.505 0.504 0.493 0.49  0.516 0.498 0.49  0.5   0.496 0.484 0.51  0.493\n",
      " 0.487 0.495 0.496 0.5  ]\n",
      "Binary Predictions: [1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "Targets:            [0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.446 0.481 0.461 0.494 0.489 0.464 0.466 0.465 0.464 0.454 0.455]\n",
      "Binary Predictions: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Targets:            [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "Precision: 0.3214\n",
      "Recall: 0.1731\n",
      "F1 Score: 0.2250\n",
      "Training Loss: 1.4889, Validation Loss: 1.4932\n",
      "----------------------------------------\n",
      "Epoch 5/10\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.452 0.428 0.402 0.454 0.439 0.449 0.465 0.424 0.442 0.45  0.442 0.445\n",
      " 0.441 0.442 0.461 0.426]\n",
      "Binary Predictions: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Targets:            [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.515 0.521 0.526 0.541 0.518 0.555 0.538 0.511 0.537 0.531 0.535 0.53\n",
      " 0.55  0.548 0.536 0.538]\n",
      "Binary Predictions: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Targets:            [0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 1.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.518 0.521 0.51  0.515 0.503 0.505 0.515 0.522 0.506 0.534 0.509 0.517\n",
      " 0.53  0.527 0.531 0.516]\n",
      "Binary Predictions: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Targets:            [0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.509 0.502 0.515 0.517 0.51  0.509 0.52  0.516 0.517 0.512 0.515 0.516\n",
      " 0.524 0.511 0.526 0.517]\n",
      "Binary Predictions: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Targets:            [1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.424 0.431 0.428 0.429 0.427 0.447 0.419 0.415 0.451 0.43  0.413 0.424\n",
      " 0.425 0.43  0.43  0.429]\n",
      "Binary Predictions: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Targets:            [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.589 0.58  0.56  0.56  0.574 0.574 0.578 0.565 0.574 0.58  0.566 0.556\n",
      " 0.556 0.568 0.557 0.558]\n",
      "Binary Predictions: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Targets:            [0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.519 0.547 0.564 0.544 0.522 0.537 0.533 0.536 0.522 0.536 0.52  0.539\n",
      " 0.541 0.526 0.511 0.543]\n",
      "Binary Predictions: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Targets:            [0. 1. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.465 0.468 0.469 0.457 0.464 0.472 0.446 0.452 0.461 0.459 0.457 0.469\n",
      " 0.44  0.465 0.464 0.452]\n",
      "Binary Predictions: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Targets:            [0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.465 0.462 0.451 0.435 0.448 0.451 0.461 0.455 0.453 0.447 0.452 0.455\n",
      " 0.441 0.456 0.461 0.444]\n",
      "Binary Predictions: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Targets:            [0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.489 0.503 0.532 0.497 0.51  0.509 0.526 0.509 0.5   0.521 0.52  0.52\n",
      " 0.51  0.52  0.502 0.522]\n",
      "Binary Predictions: [0. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Targets:            [0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.498 0.489 0.497 0.505 0.488 0.492 0.481 0.496 0.479 0.48  0.469 0.495\n",
      " 0.49  0.465 0.489 0.504]\n",
      "Binary Predictions: [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "Targets:            [1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.411 0.415 0.414 0.427 0.434 0.41  0.4   0.409 0.405 0.418 0.409 0.411\n",
      " 0.398 0.392 0.404 0.437]\n",
      "Binary Predictions: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Targets:            [0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 1. 0. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.383 0.425 0.421 0.414 0.391 0.424 0.405 0.428 0.414 0.407 0.407]\n",
      "Binary Predictions: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Targets:            [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "Precision: 0.2947\n",
      "Recall: 0.5385\n",
      "F1 Score: 0.3810\n",
      "Training Loss: 1.4931, Validation Loss: 1.4831\n",
      "----------------------------------------\n",
      "Epoch 6/10\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.503 0.501 0.499 0.511 0.484 0.529 0.507 0.505 0.516 0.498 0.485 0.487\n",
      " 0.503 0.491 0.491 0.515]\n",
      "Binary Predictions: [1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 1.]\n",
      "Targets:            [0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.513 0.488 0.501 0.518 0.51  0.522 0.506 0.505 0.512 0.505 0.523 0.513\n",
      " 0.535 0.505 0.512 0.52 ]\n",
      "Binary Predictions: [1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Targets:            [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.52  0.506 0.514 0.528 0.496 0.528 0.495 0.51  0.514 0.514 0.51  0.509\n",
      " 0.514 0.503 0.513 0.503]\n",
      "Binary Predictions: [1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Targets:            [1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.518 0.514 0.513 0.528 0.544 0.55  0.533 0.532 0.521 0.526 0.55  0.516\n",
      " 0.519 0.53  0.55  0.526]\n",
      "Binary Predictions: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Targets:            [0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.508 0.533 0.518 0.51  0.491 0.515 0.508 0.493 0.51  0.508 0.503 0.491\n",
      " 0.491 0.531 0.496 0.534]\n",
      "Binary Predictions: [1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1.]\n",
      "Targets:            [0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.548 0.509 0.523 0.55  0.544 0.53  0.549 0.565 0.544 0.552 0.584 0.572\n",
      " 0.522 0.546 0.55  0.558]\n",
      "Binary Predictions: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Targets:            [0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.479 0.476 0.476 0.473 0.474 0.477 0.462 0.422 0.458 0.474 0.473 0.465\n",
      " 0.479 0.473 0.463 0.458]\n",
      "Binary Predictions: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Targets:            [0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.488 0.506 0.503 0.471 0.484 0.498 0.488 0.482 0.488 0.496 0.506 0.493\n",
      " 0.5   0.495 0.479 0.481]\n",
      "Binary Predictions: [0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "Targets:            [1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.514 0.501 0.521 0.503 0.497 0.455 0.498 0.502 0.489 0.534 0.524 0.528\n",
      " 0.519 0.483 0.451 0.536]\n",
      "Binary Predictions: [1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1.]\n",
      "Targets:            [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.593 0.609 0.62  0.569 0.583 0.599 0.594 0.598 0.562 0.586 0.593 0.592\n",
      " 0.576 0.574 0.576 0.593]\n",
      "Binary Predictions: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Targets:            [1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.456 0.469 0.445 0.489 0.468 0.473 0.477 0.482 0.467 0.448 0.454 0.457\n",
      " 0.459 0.464 0.468 0.456]\n",
      "Binary Predictions: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Targets:            [1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.436 0.441 0.457 0.454 0.448 0.448 0.454 0.439 0.453 0.441 0.433 0.428\n",
      " 0.45  0.451 0.431 0.456]\n",
      "Binary Predictions: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Targets:            [0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.528 0.514 0.514 0.515 0.527 0.46  0.515 0.535 0.515 0.529 0.517]\n",
      "Binary Predictions: [1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1.]\n",
      "Targets:            [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Precision: 0.2333\n",
      "Recall: 0.5385\n",
      "F1 Score: 0.3256\n",
      "Training Loss: 1.4943, Validation Loss: 1.4941\n",
      "----------------------------------------\n",
      "Epoch 7/10\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.522 0.544 0.547 0.515 0.558 0.546 0.533 0.509 0.53  0.544 0.541 0.528\n",
      " 0.54  0.513 0.51  0.519]\n",
      "Binary Predictions: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Targets:            [1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.497 0.49  0.494 0.463 0.485 0.489 0.476 0.464 0.502 0.52  0.488 0.47\n",
      " 0.475 0.47  0.487 0.482]\n",
      "Binary Predictions: [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      "Targets:            [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.616 0.556 0.563 0.558 0.562 0.536 0.552 0.553 0.545 0.591 0.541 0.564\n",
      " 0.582 0.547 0.539 0.592]\n",
      "Binary Predictions: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Targets:            [1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.425 0.451 0.44  0.439 0.445 0.443 0.477 0.435 0.439 0.434 0.441 0.437\n",
      " 0.439 0.419 0.454 0.423]\n",
      "Binary Predictions: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Targets:            [1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.546 0.507 0.506 0.5   0.543 0.513 0.539 0.518 0.502 0.509 0.522 0.506\n",
      " 0.521 0.513 0.524 0.515]\n",
      "Binary Predictions: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Targets:            [0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.414 0.434 0.425 0.443 0.479 0.465 0.414 0.425 0.444 0.417 0.465 0.448\n",
      " 0.458 0.445 0.423 0.418]\n",
      "Binary Predictions: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Targets:            [0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.517 0.512 0.518 0.537 0.498 0.502 0.513 0.515 0.518 0.499 0.504 0.516\n",
      " 0.521 0.514 0.515 0.51 ]\n",
      "Binary Predictions: [1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1.]\n",
      "Targets:            [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.515 0.538 0.523 0.536 0.527 0.531 0.524 0.524 0.534 0.532 0.526 0.531\n",
      " 0.542 0.537 0.526 0.525]\n",
      "Binary Predictions: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Targets:            [1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.591 0.577 0.58  0.58  0.596 0.577 0.565 0.567 0.573 0.58  0.583 0.61\n",
      " 0.605 0.612 0.587 0.58 ]\n",
      "Binary Predictions: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Targets:            [0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.495 0.491 0.498 0.49  0.481 0.488 0.498 0.504 0.47  0.515 0.473 0.476\n",
      " 0.502 0.499 0.479 0.49 ]\n",
      "Binary Predictions: [0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0.]\n",
      "Targets:            [0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.479 0.472 0.488 0.435 0.433 0.47  0.412 0.461 0.484 0.428 0.478 0.456\n",
      " 0.47  0.474 0.455 0.467]\n",
      "Binary Predictions: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Targets:            [1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.507 0.512 0.537 0.544 0.517 0.517 0.48  0.514 0.534 0.506 0.516 0.509\n",
      " 0.524 0.515 0.511 0.492]\n",
      "Binary Predictions: [1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
      "Targets:            [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.508 0.538 0.52  0.494 0.514 0.508 0.526 0.524 0.533 0.525 0.496]\n",
      "Binary Predictions: [1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0.]\n",
      "Targets:            [0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "Precision: 0.2705\n",
      "Recall: 0.6346\n",
      "F1 Score: 0.3793\n",
      "Training Loss: 1.4915, Validation Loss: 1.4883\n",
      "----------------------------------------\n",
      "Epoch 8/10\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.551 0.559 0.554 0.561 0.535 0.567 0.551 0.541 0.536 0.572 0.545 0.534\n",
      " 0.553 0.555 0.529 0.558]\n",
      "Binary Predictions: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Targets:            [0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.587 0.565 0.583 0.581 0.56  0.584 0.586 0.57  0.593 0.611 0.569 0.555\n",
      " 0.58  0.57  0.557 0.591]\n",
      "Binary Predictions: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Targets:            [0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.537 0.519 0.556 0.534 0.51  0.536 0.546 0.515 0.542 0.555 0.576 0.517\n",
      " 0.547 0.538 0.558 0.547]\n",
      "Binary Predictions: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Targets:            [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 1.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.422 0.404 0.427 0.448 0.438 0.427 0.414 0.438 0.416 0.417 0.431 0.435\n",
      " 0.41  0.438 0.425 0.431]\n",
      "Binary Predictions: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Targets:            [0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.551 0.525 0.568 0.56  0.554 0.556 0.559 0.547 0.537 0.517 0.526 0.528\n",
      " 0.553 0.571 0.588 0.542]\n",
      "Binary Predictions: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Targets:            [0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.526 0.528 0.519 0.512 0.524 0.51  0.513 0.527 0.508 0.507 0.517 0.51\n",
      " 0.507 0.538 0.534 0.497]\n",
      "Binary Predictions: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.]\n",
      "Targets:            [1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.501 0.484 0.498 0.507 0.495 0.491 0.492 0.48  0.514 0.47  0.49  0.508\n",
      " 0.497 0.5   0.492 0.483]\n",
      "Binary Predictions: [1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0.]\n",
      "Targets:            [0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.573 0.566 0.57  0.562 0.581 0.552 0.593 0.541 0.576 0.565 0.587 0.584\n",
      " 0.581 0.561 0.57  0.578]\n",
      "Binary Predictions: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Targets:            [1. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.534 0.492 0.531 0.506 0.505 0.544 0.519 0.519 0.504 0.509 0.504 0.549\n",
      " 0.519 0.52  0.534 0.533]\n",
      "Binary Predictions: [1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Targets:            [0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.449 0.42  0.444 0.424 0.419 0.401 0.436 0.408 0.449 0.443 0.445 0.425\n",
      " 0.439 0.404 0.447 0.443]\n",
      "Binary Predictions: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Targets:            [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.462 0.463 0.438 0.468 0.451 0.456 0.469 0.419 0.423 0.445 0.472 0.44\n",
      " 0.457 0.454 0.461 0.459]\n",
      "Binary Predictions: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Targets:            [0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.666 0.625 0.638 0.629 0.657 0.676 0.658 0.654 0.635 0.649 0.64  0.672\n",
      " 0.646 0.651 0.663 0.663]\n",
      "Binary Predictions: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Targets:            [1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.496 0.467 0.465 0.476 0.49  0.468 0.48  0.488 0.488 0.461 0.497]\n",
      "Binary Predictions: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Targets:            [1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0.]\n",
      "Precision: 0.2824\n",
      "Recall: 0.7115\n",
      "F1 Score: 0.4044\n",
      "Training Loss: 1.4940, Validation Loss: 1.4821\n",
      "----------------------------------------\n",
      "Epoch 9/10\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.466 0.449 0.451 0.434 0.473 0.414 0.431 0.469 0.444 0.451 0.452 0.443\n",
      " 0.458 0.448 0.439 0.44 ]\n",
      "Binary Predictions: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Targets:            [0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.531 0.505 0.532 0.519 0.499 0.506 0.51  0.503 0.53  0.517 0.517 0.499\n",
      " 0.521 0.508 0.501 0.532]\n",
      "Binary Predictions: [1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.]\n",
      "Targets:            [0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.384 0.35  0.387 0.365 0.361 0.351 0.356 0.373 0.374 0.389 0.394 0.376\n",
      " 0.382 0.374 0.386 0.358]\n",
      "Binary Predictions: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Targets:            [0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.513 0.479 0.513 0.494 0.508 0.489 0.474 0.472 0.504 0.486 0.483 0.512\n",
      " 0.481 0.482 0.486 0.5  ]\n",
      "Binary Predictions: [1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1.]\n",
      "Targets:            [0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.558 0.536 0.541 0.519 0.493 0.522 0.542 0.512 0.524 0.544 0.515 0.514\n",
      " 0.529 0.537 0.499 0.538]\n",
      "Binary Predictions: [1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1.]\n",
      "Targets:            [0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.532 0.549 0.527 0.549 0.521 0.569 0.515 0.539 0.524 0.515 0.526 0.528\n",
      " 0.534 0.497 0.527 0.529]\n",
      "Binary Predictions: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.]\n",
      "Targets:            [0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.503 0.479 0.489 0.481 0.471 0.488 0.518 0.485 0.487 0.481 0.458 0.49\n",
      " 0.487 0.465 0.481 0.477]\n",
      "Binary Predictions: [1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Targets:            [0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.5   0.498 0.491 0.499 0.491 0.502 0.504 0.503 0.48  0.467 0.469 0.522\n",
      " 0.494 0.488 0.501 0.478]\n",
      "Binary Predictions: [1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0.]\n",
      "Targets:            [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.427 0.449 0.442 0.492 0.479 0.447 0.433 0.461 0.472 0.449 0.444 0.435\n",
      " 0.437 0.45  0.465 0.44 ]\n",
      "Binary Predictions: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Targets:            [0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.582 0.603 0.567 0.556 0.588 0.58  0.594 0.587 0.607 0.548 0.56  0.577\n",
      " 0.574 0.609 0.581 0.585]\n",
      "Binary Predictions: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Targets:            [0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.535 0.529 0.566 0.514 0.546 0.518 0.579 0.521 0.55  0.541 0.546 0.573\n",
      " 0.557 0.538 0.563 0.563]\n",
      "Binary Predictions: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Targets:            [0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.589 0.588 0.593 0.577 0.591 0.592 0.56  0.562 0.595 0.567 0.603 0.585\n",
      " 0.586 0.553 0.565 0.609]\n",
      "Binary Predictions: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Targets:            [1. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.533 0.509 0.479 0.463 0.496 0.536 0.504 0.537 0.521 0.523 0.522]\n",
      "Binary Predictions: [1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1.]\n",
      "Targets:            [0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1.]\n",
      "Precision: 0.2743\n",
      "Recall: 0.5962\n",
      "F1 Score: 0.3758\n",
      "Training Loss: 1.5000, Validation Loss: 1.4944\n",
      "----------------------------------------\n",
      "Epoch 10/10\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.427 0.411 0.412 0.422 0.426 0.423 0.444 0.41  0.414 0.419 0.388 0.419\n",
      " 0.448 0.427 0.444 0.443]\n",
      "Binary Predictions: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Targets:            [0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.601 0.6   0.584 0.615 0.598 0.596 0.618 0.597 0.596 0.575 0.603 0.635\n",
      " 0.606 0.595 0.611 0.639]\n",
      "Binary Predictions: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Targets:            [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.403 0.426 0.425 0.442 0.431 0.441 0.416 0.44  0.406 0.427 0.417 0.414\n",
      " 0.437 0.421 0.404 0.417]\n",
      "Binary Predictions: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Targets:            [0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.481 0.45  0.476 0.494 0.483 0.472 0.448 0.489 0.468 0.503 0.51  0.457\n",
      " 0.466 0.477 0.474 0.477]\n",
      "Binary Predictions: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.]\n",
      "Targets:            [1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.506 0.535 0.545 0.531 0.553 0.526 0.525 0.564 0.52  0.539 0.538 0.537\n",
      " 0.538 0.519 0.532 0.509]\n",
      "Binary Predictions: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Targets:            [1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.478 0.477 0.463 0.454 0.504 0.466 0.464 0.48  0.464 0.463 0.443 0.473\n",
      " 0.454 0.463 0.462 0.456]\n",
      "Binary Predictions: [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Targets:            [0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.624 0.596 0.618 0.619 0.597 0.614 0.636 0.593 0.582 0.632 0.577 0.607\n",
      " 0.626 0.609 0.623 0.668]\n",
      "Binary Predictions: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Targets:            [1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.513 0.491 0.503 0.466 0.518 0.513 0.542 0.484 0.497 0.471 0.497 0.516\n",
      " 0.472 0.51  0.503 0.502]\n",
      "Binary Predictions: [1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1.]\n",
      "Targets:            [1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.375 0.395 0.375 0.38  0.396 0.409 0.385 0.387 0.401 0.417 0.41  0.407\n",
      " 0.417 0.37  0.39  0.402]\n",
      "Binary Predictions: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Targets:            [0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.437 0.444 0.456 0.464 0.449 0.442 0.458 0.452 0.448 0.426 0.441 0.421\n",
      " 0.449 0.434 0.441 0.425]\n",
      "Binary Predictions: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Targets:            [0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.381 0.359 0.334 0.385 0.357 0.358 0.377 0.371 0.36  0.373 0.348 0.38\n",
      " 0.332 0.381 0.362 0.353]\n",
      "Binary Predictions: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Targets:            [0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.461 0.462 0.455 0.453 0.464 0.464 0.448 0.454 0.478 0.448 0.471 0.472\n",
      " 0.482 0.486 0.459 0.484]\n",
      "Binary Predictions: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Targets:            [0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1.]\n",
      "--------------- Eval ---------------\n",
      "Predictions (raw):  [0.514 0.52  0.52  0.534 0.518 0.506 0.517 0.531 0.484 0.509 0.512]\n",
      "Binary Predictions: [1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.]\n",
      "Targets:            [0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0.]\n",
      "Precision: 0.2714\n",
      "Recall: 0.3654\n",
      "F1 Score: 0.3115\n",
      "Training Loss: 1.4883, Validation Loss: 1.4876\n",
      "----------------------------------------\n",
      "Testing the model on the test set...\n",
      "--------------- Test ---------------\n",
      "Predictions (raw):  [0.478 0.461 0.454 0.488 0.473 0.498 0.437 0.449 0.479 0.46  0.467 0.437\n",
      " 0.453 0.455 0.456 0.399]\n",
      "Binary Predictions: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Targets:            [1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "--------------- Test ---------------\n",
      "Predictions (raw):  [0.546 0.577 0.527 0.582 0.555 0.546 0.56  0.587 0.574 0.556 0.552 0.577\n",
      " 0.537 0.565 0.574 0.573]\n",
      "Binary Predictions: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Targets:            [0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0.]\n",
      "--------------- Test ---------------\n",
      "Predictions (raw):  [0.449 0.46  0.451 0.447 0.449 0.465 0.437 0.455 0.439 0.432 0.454 0.466\n",
      " 0.446 0.449 0.436 0.456]\n",
      "Binary Predictions: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Targets:            [0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1.]\n",
      "--------------- Test ---------------\n",
      "Predictions (raw):  [0.425 0.431 0.406 0.432 0.405 0.401 0.41  0.414 0.442 0.388 0.432 0.401\n",
      " 0.419 0.381 0.391 0.371]\n",
      "Binary Predictions: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Targets:            [0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "--------------- Test ---------------\n",
      "Predictions (raw):  [0.481 0.449 0.447 0.439 0.429 0.449 0.447 0.452 0.446 0.434 0.454 0.457\n",
      " 0.468 0.428 0.44  0.447]\n",
      "Binary Predictions: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Targets:            [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0.]\n",
      "--------------- Test ---------------\n",
      "Predictions (raw):  [0.489 0.47  0.481 0.496 0.47  0.47  0.491 0.465 0.457 0.486 0.461 0.452\n",
      " 0.5   0.468 0.491 0.482]\n",
      "Binary Predictions: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "Targets:            [0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "--------------- Test ---------------\n",
      "Predictions (raw):  [0.546 0.548 0.554 0.532 0.545 0.563 0.567 0.555 0.57  0.555 0.558 0.557\n",
      " 0.542 0.547 0.55  0.546]\n",
      "Binary Predictions: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Targets:            [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1.]\n",
      "--------------- Test ---------------\n",
      "Predictions (raw):  [0.553 0.537 0.553 0.541 0.551 0.56  0.551 0.528 0.56  0.551 0.548 0.547\n",
      " 0.512 0.541 0.545 0.538]\n",
      "Binary Predictions: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Targets:            [0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.]\n",
      "--------------- Test ---------------\n",
      "Predictions (raw):  [0.399 0.375 0.388 0.388 0.371 0.424 0.365 0.382 0.384 0.36  0.372 0.383\n",
      " 0.392 0.375 0.363 0.374]\n",
      "Binary Predictions: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Targets:            [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.]\n",
      "--------------- Test ---------------\n",
      "Predictions (raw):  [0.519 0.517 0.516 0.514 0.493 0.516 0.49  0.538 0.518 0.524 0.497 0.532\n",
      " 0.524 0.521 0.555 0.495]\n",
      "Binary Predictions: [1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0.]\n",
      "Targets:            [0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "--------------- Test ---------------\n",
      "Predictions (raw):  [0.577 0.594 0.558 0.574 0.586 0.594 0.593 0.552 0.559 0.548 0.531 0.566\n",
      " 0.577 0.565 0.576 0.585]\n",
      "Binary Predictions: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Targets:            [0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1.]\n",
      "--------------- Test ---------------\n",
      "Predictions (raw):  [0.373 0.383 0.367 0.393 0.385 0.385 0.332 0.375 0.378 0.378 0.373 0.376\n",
      " 0.369 0.377 0.365 0.328]\n",
      "Binary Predictions: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Targets:            [0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1.]\n",
      "--------------- Test ---------------\n",
      "Predictions (raw):  [0.536 0.511 0.555 0.529 0.542 0.548 0.528 0.575 0.519 0.522 0.52 ]\n",
      "Binary Predictions: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Targets:            [0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 1.]\n",
      "Test Precision: 0.2500\n",
      "Test Recall: 0.4314\n",
      "Test F1 Score: 0.3165\n",
      "Test Loss: 1.4898\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    torch.manual_seed(42)\n",
    "\n",
    "    # Initialize the SMCA model A\n",
    "    model = SMCAModel(768, 768, device).to(device)  # Dimension for d_out_kq and d_out_v\n",
    "\n",
    "    # Determine the output dimensions\n",
    "    output_dim = 768\n",
    "\n",
    "    # Own DenseLayer or FinalClassifier\n",
    "    dense_layer = DenseLayer(output_dim*2).to(device)\n",
    "    # dense_layer = FinalClassifier(output_dim*2).to(device) \n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.grad is None:\n",
    "            print(\"model:\", \"No gradient for:\", name)\n",
    "    \n",
    "    for name, param in dense_layer.named_parameters():\n",
    "        if param.grad is None:\n",
    "            print(\"classifier:\", \"No gradient for:\", name)\n",
    "            \n",
    "    optimizer = get_optimizer(list(model.parameters()) + list(dense_layer.parameters()), learning_rate)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"-\" * 40)\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "\n",
    "        # Ensure you have a dataloader that yields inputs and targets\n",
    "        train_loss = train_model(model=model, dense_layer=dense_layer, dataloader=train_dataloader, criterion=criterion, optimizer=optimizer, device=device)\n",
    "\n",
    "        # Validate step\n",
    "        val_loss, precision, recall, f1_score = evaluate_model(model=model, dense_layer=dense_layer, dataloader=val_dataloader, criterion=criterion, device=device)\n",
    "\n",
    "        print(f\"Training Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "    # Testing the model\n",
    "    print(\"-\" * 40)\n",
    "    print(\"Testing the model on the test set...\")\n",
    "    test_loss, test_precision, test_recall, test_f1_score = test_model(model=model, dense_layer=dense_layer, dataloader=test_dataloader, criterion=criterion, device=device)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
